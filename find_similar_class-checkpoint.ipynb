{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEWkBMJpNvd_",
    "outputId": "e010c54f-38c1-4abd-c7e4-d29e7e531432"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(original_x_train, original_y_train), (original_x_test, original_y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DG5AhMOLjbeb"
   },
   "outputs": [],
   "source": [
    "original_x_train = original_x_train / 255.0\n",
    "original_x_test = original_x_test / 255.0\n",
    "\n",
    "original_y_train = keras.utils.to_categorical(original_y_train)\n",
    "original_y_test = keras.utils.to_categorical(original_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJRl4tKVolc",
    "outputId": "6acbf001-2b2a-4654-f644-3bacf4a641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 5ms/step - loss: 1.8046 - accuracy: 0.3282 - val_loss: 1.4257 - val_accuracy: 0.4850\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.4652 - accuracy: 0.4747 - val_loss: 1.2860 - val_accuracy: 0.5361\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.3417 - accuracy: 0.5234 - val_loss: 1.1906 - val_accuracy: 0.5749\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2509 - accuracy: 0.5570 - val_loss: 1.0799 - val_accuracy: 0.6085\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1839 - accuracy: 0.5815 - val_loss: 1.0267 - val_accuracy: 0.6384\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1428 - accuracy: 0.5985 - val_loss: 1.0079 - val_accuracy: 0.6505\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1031 - accuracy: 0.6157 - val_loss: 0.9532 - val_accuracy: 0.6616\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0659 - accuracy: 0.6272 - val_loss: 0.9517 - val_accuracy: 0.6622\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0452 - accuracy: 0.6365 - val_loss: 0.9288 - val_accuracy: 0.6692\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0154 - accuracy: 0.6481 - val_loss: 0.8744 - val_accuracy: 0.6921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.Flatten())\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Dense(64, activation='relu'))\n",
    "original_model.add(layers.Dropout(0.5))\n",
    "original_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_0 = original_model.fit(original_x_train, original_y_train, epochs= 10, batch_size= 64, validation_data=(original_x_test, original_y_test))\n",
    "# loss: 0.9075 - accuracy: 0.6951 - val_loss: 0.8743 - val_accuracy: 0.7026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvzfjR4SWu6i",
    "outputId": "a168ca0a-a8f4-4c05-8e59-18fa0d285a26",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "[0, 24, 47, 14, 18, 4, 8, 6, 83, 24]\n",
      "[27, 0, 1, 6, 8, 2, 16, 2, 34, 70]\n",
      "[91, 7, 0, 73, 127, 54, 89, 12, 19, 5]\n",
      "[21, 9, 80, 0, 81, 141, 106, 18, 32, 13]\n",
      "[28, 5, 78, 57, 0, 21, 75, 50, 10, 4]\n",
      "[16, 2, 71, 241, 65, 0, 38, 34, 7, 5]\n",
      "[12, 5, 48, 57, 46, 11, 0, 2, 6, 2]\n",
      "[24, 1, 42, 40, 106, 79, 19, 0, 4, 8]\n",
      "[82, 28, 8, 13, 11, 1, 5, 3, 0, 21]\n",
      "[39, 87, 5, 18, 11, 1, 15, 8, 32, 0]\n"
     ]
    }
   ],
   "source": [
    "# 잘못예측한 데이터 찾는 코드\n",
    "# original_label, predict_label\n",
    "wrong_predict = []\n",
    "wrong_predict_cnt = 0\n",
    "class_length = 10\n",
    "\n",
    "model_predict = original_model.predict(original_x_test)\n",
    "\n",
    "for i in range(len(original_y_test)):\n",
    "  predict_idx, original_idx = 0, 0\n",
    "  for j in range(1,10):\n",
    "    if model_predict[i][j] > model_predict[i][predict_idx]:\n",
    "      predict_idx = j\n",
    "    if original_y_test[i][j] > original_y_test[i][original_idx]:\n",
    "      original_idx = j\n",
    "\n",
    "  if predict_idx != original_idx:\n",
    "    wrong_predict.append([original_idx, predict_idx])\n",
    "\n",
    "similar_wrong_predict_count = [[0 for j in range(class_length)] for i in range(class_length)]\n",
    "for i in range(len(wrong_predict)):\n",
    "  similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] = similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] + 1 \n",
    "\n",
    "for i in range(class_length):\n",
    "  print(similar_wrong_predict_count[i])\n",
    "\n",
    "# result\n",
    "# [0, 27, 28, 8, 5, 1, 7, 8, 59, 34]\n",
    "# [16, 0, 0, 6, 1, 3, 3, 1, 18, 51]\n",
    "# [101, 9, 0, 36, 93, 69, 60, 29, 18, 14]\n",
    "# [45, 22, 73, 0, 58, 196, 88, 38, 28, 30]\n",
    "# [40, 4, 71, 39, 0, 26, 66, 94, 11, 3]\n",
    "# [20, 7, 47, 146, 48, 0, 24, 65, 10, 11]\n",
    "# [12, 7, 48, 41, 33, 17, 0, 7, 13, 10]\n",
    "# [23, 2, 32, 23, 36, 50, 5, 0, 4, 15]\n",
    "# [78, 39, 4, 5, 3, 4, 4, 5, 0, 19]\n",
    "# [31, 128, 5, 6, 4, 3, 3, 10, 21, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PXIQquThxGkf"
   },
   "outputs": [],
   "source": [
    "# 가장 큰 값 top 3의 index를 가져와야 함 (cur_idx 제외)\n",
    "def getTopN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  top_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(top_idx) == n:\n",
    "      break;\n",
    "    max_num = -1\n",
    "    max_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if max_num < tmp[j]:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                max_num = tmp[j]\n",
    "                max_idx = j\n",
    "    \n",
    "    if max_idx != -1:\n",
    "      top_idx.append(max_idx)\n",
    "      visited.append(max_idx)\n",
    "  return top_idx\n",
    "\n",
    "# 가장 작은 값 bottom 3의 index를 가져와야 함  (cur_idx 제외)\n",
    "def getBottomN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  bottom_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(bottom_idx) == n:\n",
    "      break;\n",
    "    min_num = 1e9\n",
    "    min_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if tmp[j] < min_num:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                min_num = tmp[j]\n",
    "                min_idx = j\n",
    "    \n",
    "    if min_idx != -1:\n",
    "      bottom_idx.append(min_idx)\n",
    "      visited.append(min_idx)\n",
    "  return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xw4-dk8EBhqV"
   },
   "outputs": [],
   "source": [
    "# cifar10 데이터 가져오는 함수\n",
    "def getCifar10Data():\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train / 255.0\n",
    "  x_test = x_test / 255.0\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# a, b, c로 다시 라벨링\n",
    "def reLabel(y_train, y_test, a, b, c):\n",
    "  for i in range(len(y_train)):\n",
    "    if y_train[i] == a or y_train[i] == b or y_train[i] == c:\n",
    "      y_train[i] = 1\n",
    "    else:\n",
    "      y_train[i] = 0    \n",
    "  \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == a or y_test[i] == b or y_test[i] == c:\n",
    "      y_test[i] = 1\n",
    "    else:\n",
    "      y_test[i] = 0\n",
    "  \n",
    "  return y_train, y_test\n",
    "\n",
    "(model1_x_train, model1_y_train), (model1_x_test, model1_y_test) = getCifar10Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4bb4bjAnNxa3"
   },
   "outputs": [],
   "source": [
    "# model 만드는 함수 \n",
    "def makeModel():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Bxau2L_U9toH"
   },
   "outputs": [],
   "source": [
    "# # 모델의 결과가 true인 predict index 반환함수\n",
    "# def get_TP_FP(y_test, predict, target_idx):\n",
    "#     TP = []\n",
    "#     FP = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 1:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TP.append(i)\n",
    "#             else:\n",
    "#                 FP.append(i)\n",
    "#     return TP, FP\n",
    "\n",
    "# # 모델의 결과가 false인 predict index 반환함수\n",
    "# def get_TN_FN(y_test, predict, target_idx):\n",
    "#     TN = []\n",
    "#     FN = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 0:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TN.append(i)\n",
    "#             else:\n",
    "#                 FN.append(i)\n",
    "#     return TN, FN\n",
    "\n",
    "def get_TP_FP_TN_FN(y_test, predict, target_idx):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "                break\n",
    "        # True로 나왔을 때\n",
    "        if predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        # False로 나왔을 때\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "            \n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_model_TP_FP_TN_FN(first_predict, second_predict, y_test, target_idx):\n",
    "    TP, FP, TN, FN = [],[],[],[]\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "        if first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 0:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "    return TP, FP, TN, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MmmbZyZwFa-",
    "outputId": "6e61ca8b-9629-45f9-d032-a2e072f6c2ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 2, 0]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4675 - accuracy: 0.7893 - val_loss: 0.3673 - val_accuracy: 0.8433\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3746 - accuracy: 0.8445 - val_loss: 0.3371 - val_accuracy: 0.8556\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3433 - accuracy: 0.8587 - val_loss: 0.3360 - val_accuracy: 0.8577\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3222 - accuracy: 0.8675 - val_loss: 0.3028 - val_accuracy: 0.8717\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3033 - accuracy: 0.8754 - val_loss: 0.2884 - val_accuracy: 0.8808\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2910 - accuracy: 0.8809 - val_loss: 0.2885 - val_accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2767 - accuracy: 0.8876 - val_loss: 0.2831 - val_accuracy: 0.8841\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2654 - accuracy: 0.8920 - val_loss: 0.2786 - val_accuracy: 0.8858\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2589 - accuracy: 0.8954 - val_loss: 0.2760 - val_accuracy: 0.8873\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2487 - accuracy: 0.8986 - val_loss: 0.2643 - val_accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.4959 - accuracy: 0.7305 - val_loss: 0.4456 - val_accuracy: 0.7528\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4365 - accuracy: 0.7804 - val_loss: 0.4105 - val_accuracy: 0.7946\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4049 - accuracy: 0.8014 - val_loss: 0.3883 - val_accuracy: 0.8065\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3813 - accuracy: 0.8197 - val_loss: 0.3656 - val_accuracy: 0.8233\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3609 - accuracy: 0.8298 - val_loss: 0.3664 - val_accuracy: 0.8216\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3440 - accuracy: 0.8410 - val_loss: 0.3476 - val_accuracy: 0.8356\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3281 - accuracy: 0.8501 - val_loss: 0.3212 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3165 - accuracy: 0.8555 - val_loss: 0.3266 - val_accuracy: 0.8470\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3062 - accuracy: 0.8594 - val_loss: 0.3166 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2957 - accuracy: 0.8664 - val_loss: 0.2959 - val_accuracy: 0.8604\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "1 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[9, 8, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3555 - accuracy: 0.8412 - val_loss: 0.2704 - val_accuracy: 0.8880\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2578 - accuracy: 0.8938 - val_loss: 0.2145 - val_accuracy: 0.9113\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2182 - accuracy: 0.9150 - val_loss: 0.1807 - val_accuracy: 0.9304\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1880 - accuracy: 0.9274 - val_loss: 0.1655 - val_accuracy: 0.9350\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1682 - accuracy: 0.9360 - val_loss: 0.1829 - val_accuracy: 0.9336\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1337 - val_accuracy: 0.9488\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1423 - accuracy: 0.9461 - val_loss: 0.1247 - val_accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1309 - accuracy: 0.9505 - val_loss: 0.1329 - val_accuracy: 0.9512\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1264 - accuracy: 0.9525 - val_loss: 0.1643 - val_accuracy: 0.9384\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1160 - accuracy: 0.9578 - val_loss: 0.1389 - val_accuracy: 0.9531\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[2, 5, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.5056 - accuracy: 0.7403 - val_loss: 0.4174 - val_accuracy: 0.7942\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4285 - accuracy: 0.7922 - val_loss: 0.3971 - val_accuracy: 0.8087\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4004 - accuracy: 0.8075 - val_loss: 0.3855 - val_accuracy: 0.8159\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3822 - accuracy: 0.8197 - val_loss: 0.3711 - val_accuracy: 0.8247\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3623 - accuracy: 0.8309 - val_loss: 0.3523 - val_accuracy: 0.8363\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3484 - accuracy: 0.8388 - val_loss: 0.3321 - val_accuracy: 0.8496\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3357 - accuracy: 0.8463 - val_loss: 0.3354 - val_accuracy: 0.8511\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3238 - accuracy: 0.8537 - val_loss: 0.3227 - val_accuracy: 0.8527\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3138 - accuracy: 0.8607 - val_loss: 0.3176 - val_accuracy: 0.8534\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3026 - accuracy: 0.8639 - val_loss: 0.3101 - val_accuracy: 0.8591\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "2 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 0, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.5204 - accuracy: 0.7504 - val_loss: 0.4346 - val_accuracy: 0.8059\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4294 - accuracy: 0.8082 - val_loss: 0.4019 - val_accuracy: 0.8332\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3924 - accuracy: 0.8282 - val_loss: 0.3632 - val_accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3660 - accuracy: 0.8418 - val_loss: 0.3472 - val_accuracy: 0.8498\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3468 - accuracy: 0.8495 - val_loss: 0.4035 - val_accuracy: 0.8137\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3307 - accuracy: 0.8588 - val_loss: 0.3240 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3139 - accuracy: 0.8671 - val_loss: 0.3282 - val_accuracy: 0.8539\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3008 - accuracy: 0.8730 - val_loss: 0.3422 - val_accuracy: 0.8508\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2915 - accuracy: 0.8778 - val_loss: 0.3140 - val_accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2808 - accuracy: 0.8817 - val_loss: 0.3196 - val_accuracy: 0.8641\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4467 - accuracy: 0.7992 - val_loss: 0.3396 - val_accuracy: 0.8542\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3244 - accuracy: 0.8673 - val_loss: 0.2825 - val_accuracy: 0.8812\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2934 - accuracy: 0.8818 - val_loss: 0.2645 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2667 - accuracy: 0.8933 - val_loss: 0.2602 - val_accuracy: 0.8914\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2483 - accuracy: 0.9039 - val_loss: 0.2350 - val_accuracy: 0.9049\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2341 - accuracy: 0.9080 - val_loss: 0.2255 - val_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2210 - accuracy: 0.9135 - val_loss: 0.2143 - val_accuracy: 0.9148\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2103 - accuracy: 0.9191 - val_loss: 0.2057 - val_accuracy: 0.9188\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1998 - accuracy: 0.9229 - val_loss: 0.2274 - val_accuracy: 0.9092\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1949 - accuracy: 0.9247 - val_loss: 0.2011 - val_accuracy: 0.9211\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "3 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[5, 6, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4609 - accuracy: 0.7630 - val_loss: 0.4450 - val_accuracy: 0.7797\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3811 - accuracy: 0.8257 - val_loss: 0.3709 - val_accuracy: 0.8317\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3505 - accuracy: 0.8440 - val_loss: 0.3461 - val_accuracy: 0.8394\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3315 - accuracy: 0.8540 - val_loss: 0.3215 - val_accuracy: 0.8593\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3164 - accuracy: 0.8613 - val_loss: 0.3090 - val_accuracy: 0.8629\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3029 - accuracy: 0.8680 - val_loss: 0.3152 - val_accuracy: 0.8561\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2895 - accuracy: 0.8736 - val_loss: 0.2875 - val_accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2789 - accuracy: 0.8804 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2687 - accuracy: 0.8852 - val_loss: 0.2904 - val_accuracy: 0.8731\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2607 - accuracy: 0.8888 - val_loss: 0.2752 - val_accuracy: 0.8832\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4634 - accuracy: 0.7870 - val_loss: 0.3705 - val_accuracy: 0.8447\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3343 - accuracy: 0.8634 - val_loss: 0.2971 - val_accuracy: 0.8753\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2956 - accuracy: 0.8808 - val_loss: 0.2892 - val_accuracy: 0.8800\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2751 - accuracy: 0.8902 - val_loss: 0.2564 - val_accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2588 - accuracy: 0.8985 - val_loss: 0.2428 - val_accuracy: 0.9004\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2439 - accuracy: 0.9033 - val_loss: 0.2344 - val_accuracy: 0.9058\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2317 - accuracy: 0.9106 - val_loss: 0.2322 - val_accuracy: 0.9109\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2217 - accuracy: 0.9133 - val_loss: 0.2218 - val_accuracy: 0.9147\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2104 - accuracy: 0.9194 - val_loss: 0.2165 - val_accuracy: 0.9178\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2046 - accuracy: 0.9223 - val_loss: 0.2092 - val_accuracy: 0.9157\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "4 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[2, 6, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4927 - accuracy: 0.7694 - val_loss: 0.4201 - val_accuracy: 0.8170\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4162 - accuracy: 0.8117 - val_loss: 0.3664 - val_accuracy: 0.8330\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3773 - accuracy: 0.8319 - val_loss: 0.3543 - val_accuracy: 0.8426\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3557 - accuracy: 0.8406 - val_loss: 0.3863 - val_accuracy: 0.8351\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3382 - accuracy: 0.8521 - val_loss: 0.3255 - val_accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3220 - accuracy: 0.8604 - val_loss: 0.3158 - val_accuracy: 0.8606\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3091 - accuracy: 0.8671 - val_loss: 0.3641 - val_accuracy: 0.8397\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2973 - accuracy: 0.8722 - val_loss: 0.2946 - val_accuracy: 0.8706\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2858 - accuracy: 0.8770 - val_loss: 0.3206 - val_accuracy: 0.8640\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2767 - accuracy: 0.8830 - val_loss: 0.3016 - val_accuracy: 0.8707\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3747 - accuracy: 0.8282 - val_loss: 0.2431 - val_accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2464 - accuracy: 0.8995 - val_loss: 0.2043 - val_accuracy: 0.9193\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2095 - accuracy: 0.9162 - val_loss: 0.1674 - val_accuracy: 0.9348\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1773 - accuracy: 0.9332 - val_loss: 0.1634 - val_accuracy: 0.9317\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1599 - accuracy: 0.9394 - val_loss: 0.1400 - val_accuracy: 0.9458\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1457 - accuracy: 0.9451 - val_loss: 0.1468 - val_accuracy: 0.9420\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1371 - accuracy: 0.9480 - val_loss: 0.1579 - val_accuracy: 0.9402\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1246 - accuracy: 0.9534 - val_loss: 0.1238 - val_accuracy: 0.9519\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1197 - accuracy: 0.9548 - val_loss: 0.1311 - val_accuracy: 0.9515\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1140 - accuracy: 0.9571 - val_loss: 0.1254 - val_accuracy: 0.9509\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "5 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 2, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.4918 - accuracy: 0.7515 - val_loss: 0.4059 - val_accuracy: 0.8104\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4049 - accuracy: 0.8117 - val_loss: 0.3643 - val_accuracy: 0.8366\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3740 - accuracy: 0.8302 - val_loss: 0.3470 - val_accuracy: 0.8407\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3577 - accuracy: 0.8401 - val_loss: 0.3555 - val_accuracy: 0.8387\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3399 - accuracy: 0.8505 - val_loss: 0.3387 - val_accuracy: 0.8487\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3264 - accuracy: 0.8560 - val_loss: 0.3296 - val_accuracy: 0.8492\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3160 - accuracy: 0.8611 - val_loss: 0.3110 - val_accuracy: 0.8647\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3100 - accuracy: 0.8652 - val_loss: 0.3174 - val_accuracy: 0.8561\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3015 - accuracy: 0.8699 - val_loss: 0.3280 - val_accuracy: 0.8575\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2896 - accuracy: 0.8752 - val_loss: 0.2991 - val_accuracy: 0.8703\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3511 - accuracy: 0.8437 - val_loss: 0.2584 - val_accuracy: 0.8791\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2449 - accuracy: 0.9006 - val_loss: 0.2140 - val_accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2045 - accuracy: 0.9199 - val_loss: 0.1622 - val_accuracy: 0.9352\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1752 - accuracy: 0.9332 - val_loss: 0.1544 - val_accuracy: 0.9399\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1571 - accuracy: 0.9392 - val_loss: 0.1456 - val_accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1462 - accuracy: 0.9448 - val_loss: 0.1355 - val_accuracy: 0.9473\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1328 - accuracy: 0.9509 - val_loss: 0.1448 - val_accuracy: 0.9439\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1226 - accuracy: 0.9546 - val_loss: 0.1259 - val_accuracy: 0.9514\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1170 - accuracy: 0.9572 - val_loss: 0.1254 - val_accuracy: 0.9502\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1093 - accuracy: 0.9583 - val_loss: 0.1258 - val_accuracy: 0.9489\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "6 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 2, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5026 - accuracy: 0.7429 - val_loss: 0.4431 - val_accuracy: 0.7799\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4277 - accuracy: 0.7915 - val_loss: 0.4344 - val_accuracy: 0.7888\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3959 - accuracy: 0.8118 - val_loss: 0.3723 - val_accuracy: 0.8199\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3778 - accuracy: 0.8230 - val_loss: 0.3561 - val_accuracy: 0.8338\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3665 - accuracy: 0.8299 - val_loss: 0.4061 - val_accuracy: 0.8072\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3528 - accuracy: 0.8370 - val_loss: 0.4165 - val_accuracy: 0.8122\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3404 - accuracy: 0.8411 - val_loss: 0.3631 - val_accuracy: 0.8321\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3314 - accuracy: 0.8492 - val_loss: 0.3279 - val_accuracy: 0.8445\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3218 - accuracy: 0.8529 - val_loss: 0.3262 - val_accuracy: 0.8482\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3139 - accuracy: 0.8558 - val_loss: 0.3161 - val_accuracy: 0.8539\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[7, 9, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4577 - accuracy: 0.7887 - val_loss: 0.3382 - val_accuracy: 0.8578\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3328 - accuracy: 0.8640 - val_loss: 0.2932 - val_accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2945 - accuracy: 0.8810 - val_loss: 0.2681 - val_accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2720 - accuracy: 0.8914 - val_loss: 0.2646 - val_accuracy: 0.8922\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2521 - accuracy: 0.9001 - val_loss: 0.2442 - val_accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2368 - accuracy: 0.9073 - val_loss: 0.2226 - val_accuracy: 0.9106\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2218 - accuracy: 0.9137 - val_loss: 0.2245 - val_accuracy: 0.9084\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2102 - accuracy: 0.9174 - val_loss: 0.2089 - val_accuracy: 0.9156\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1989 - accuracy: 0.9229 - val_loss: 0.2057 - val_accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1929 - accuracy: 0.9239 - val_loss: 0.2123 - val_accuracy: 0.9177\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "7 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 5, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4851 - accuracy: 0.7511 - val_loss: 0.4053 - val_accuracy: 0.7992\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3963 - accuracy: 0.8154 - val_loss: 0.3603 - val_accuracy: 0.8254\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3561 - accuracy: 0.8397 - val_loss: 0.3233 - val_accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3272 - accuracy: 0.8537 - val_loss: 0.3268 - val_accuracy: 0.8475\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3109 - accuracy: 0.8609 - val_loss: 0.3020 - val_accuracy: 0.8581\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2979 - accuracy: 0.8662 - val_loss: 0.3078 - val_accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2862 - accuracy: 0.8752 - val_loss: 0.2736 - val_accuracy: 0.8765\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2713 - accuracy: 0.8802 - val_loss: 0.2692 - val_accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2637 - accuracy: 0.8842 - val_loss: 0.2641 - val_accuracy: 0.8823\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2558 - accuracy: 0.8883 - val_loss: 0.2665 - val_accuracy: 0.8791\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 8, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3680 - accuracy: 0.8349 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2647 - accuracy: 0.8913 - val_loss: 0.2369 - val_accuracy: 0.9039\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2281 - accuracy: 0.9089 - val_loss: 0.1870 - val_accuracy: 0.9229\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1931 - accuracy: 0.9238 - val_loss: 0.1599 - val_accuracy: 0.9386\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1756 - accuracy: 0.9319 - val_loss: 0.1929 - val_accuracy: 0.9276\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1540 - accuracy: 0.9411 - val_loss: 0.1635 - val_accuracy: 0.9356\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1417 - accuracy: 0.9457 - val_loss: 0.1398 - val_accuracy: 0.9479\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1363 - accuracy: 0.9489 - val_loss: 0.1324 - val_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1237 - accuracy: 0.9534 - val_loss: 0.1363 - val_accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1176 - accuracy: 0.9554 - val_loss: 0.1204 - val_accuracy: 0.9542\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "8 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[0, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.3592 - accuracy: 0.8411 - val_loss: 0.2778 - val_accuracy: 0.8819\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2795 - accuracy: 0.8852 - val_loss: 0.2536 - val_accuracy: 0.8934\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2512 - accuracy: 0.8976 - val_loss: 0.2488 - val_accuracy: 0.8962\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2322 - accuracy: 0.9064 - val_loss: 0.2155 - val_accuracy: 0.9178\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2133 - accuracy: 0.9166 - val_loss: 0.2057 - val_accuracy: 0.9175\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2009 - accuracy: 0.9213 - val_loss: 0.1900 - val_accuracy: 0.9264\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1913 - accuracy: 0.9244 - val_loss: 0.1900 - val_accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1809 - accuracy: 0.9292 - val_loss: 0.1839 - val_accuracy: 0.9268\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1718 - accuracy: 0.9328 - val_loss: 0.1766 - val_accuracy: 0.9335\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1650 - accuracy: 0.9359 - val_loss: 0.1761 - val_accuracy: 0.9351\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4997 - accuracy: 0.7242 - val_loss: 0.4498 - val_accuracy: 0.7675\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4293 - accuracy: 0.7832 - val_loss: 0.3957 - val_accuracy: 0.8023\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4029 - accuracy: 0.8042 - val_loss: 0.3672 - val_accuracy: 0.8197\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3819 - accuracy: 0.8182 - val_loss: 0.3562 - val_accuracy: 0.8317\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3646 - accuracy: 0.8276 - val_loss: 0.3381 - val_accuracy: 0.8419\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3495 - accuracy: 0.8367 - val_loss: 0.3439 - val_accuracy: 0.8398\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3343 - accuracy: 0.8458 - val_loss: 0.3338 - val_accuracy: 0.8379\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3241 - accuracy: 0.8495 - val_loss: 0.3093 - val_accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3160 - accuracy: 0.8556 - val_loss: 0.3307 - val_accuracy: 0.8433\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3039 - accuracy: 0.8622 - val_loss: 0.3055 - val_accuracy: 0.8602\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "9 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[1, 0, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4246 - accuracy: 0.7966 - val_loss: 0.3738 - val_accuracy: 0.8124\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3256 - accuracy: 0.8568 - val_loss: 0.2805 - val_accuracy: 0.8788\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2755 - accuracy: 0.8860 - val_loss: 0.2323 - val_accuracy: 0.8993\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2434 - accuracy: 0.9024 - val_loss: 0.2281 - val_accuracy: 0.9023\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2187 - accuracy: 0.9121 - val_loss: 0.2249 - val_accuracy: 0.9029\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2034 - accuracy: 0.9200 - val_loss: 0.2030 - val_accuracy: 0.9175\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1947 - accuracy: 0.9242 - val_loss: 0.2035 - val_accuracy: 0.9155\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1829 - accuracy: 0.9278 - val_loss: 0.1861 - val_accuracy: 0.9217\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1742 - accuracy: 0.9316 - val_loss: 0.1881 - val_accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1631 - accuracy: 0.9349 - val_loss: 0.1746 - val_accuracy: 0.9297\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 2, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5070 - accuracy: 0.7356 - val_loss: 0.4748 - val_accuracy: 0.7769\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4391 - accuracy: 0.7869 - val_loss: 0.4120 - val_accuracy: 0.8122\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4046 - accuracy: 0.8055 - val_loss: 0.3661 - val_accuracy: 0.8271\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3817 - accuracy: 0.8215 - val_loss: 0.3571 - val_accuracy: 0.8335\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3638 - accuracy: 0.8311 - val_loss: 0.3362 - val_accuracy: 0.8460\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3483 - accuracy: 0.8400 - val_loss: 0.3393 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3352 - accuracy: 0.8464 - val_loss: 0.3237 - val_accuracy: 0.8501\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3260 - accuracy: 0.8519 - val_loss: 0.3275 - val_accuracy: 0.8547\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3168 - accuracy: 0.8580 - val_loss: 0.3190 - val_accuracy: 0.8527\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3056 - accuracy: 0.8635 - val_loss: 0.3440 - val_accuracy: 0.8507\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 0~9 클래스 \n",
    "# 0클래스 결과값을 봤을 때, true-false모델을 통과한 0번 클래스가 772개인데 나머지 클래스들이 어디서 데이터가 누수됐는지 분석해보기\n",
    "\n",
    "class_accuracy = []\n",
    "first_TP_FP_TN_FN = []\n",
    "second_TP_FP_TN_FN = []\n",
    "model_result_predict = []\n",
    "\n",
    "for i in range(0, class_length):\n",
    "    print(i, \"번째 클래스\")\n",
    "    # 첫번째 모델 -> 가장 유사한 클래스끼리 묶은 라벨\n",
    "    print(\"[model1] : 가장 유사한 클래스끼리 묶은 라벨\")\n",
    "    (x_train, y_train), (x_test, y_test) = getCifar10Data()\n",
    "    temp = getTopN(similar_wrong_predict_count[i], 2, i)\n",
    "    # 현재 클래스 index 추가 \n",
    "    temp.append(i)\n",
    "    print(temp)\n",
    "    (y_train, y_test) = reLabel(y_train, y_test, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model1 = makeModel()\n",
    "    model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model1.fit(x_train, y_train, epochs= 10, batch_size = 64, validation_data=(x_test, y_test))\n",
    "    first_predict = model1.predict(x_test)\n",
    "#     first_TP_FP.append(get_TP_FP(original_y_test, first_predict, i))\n",
    "#     first_TN_FN.append(get_TN_FN(original_y_test, first_predict, i))\n",
    "    first_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, first_predict, i))\n",
    "    \n",
    "    \n",
    "    # 두번째 모델 -> 가장 유사하지않은 클래스끼리 묶은 라벨\n",
    "    print(\"[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\")\n",
    "    (x_train2, y_train2), (x_test2, y_test2) = getCifar10Data()\n",
    "    temp = getBottomN(similar_wrong_predict_count[i], 3, i)\n",
    "    print(temp)\n",
    "\n",
    "    (y_train2, y_test2) = reLabel(y_train2, y_test2, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model2 = makeModel()\n",
    "    model2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model2.fit(x_train2, y_train2, epochs= 10, batch_size = 64, validation_data=(x_test2, y_test2))\n",
    "    second_predict = model2.predict(x_test2)\n",
    "#     second_TP_FP.append(get_TP_FP(original_y_test, second_predict, i))\n",
    "#     second_TN_FN.append(get_TN_FN(original_y_test, second_predict, i))\n",
    "    second_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, second_predict, i))\n",
    "    \n",
    "    # 모델의 TP FP TN FN\n",
    "    model_result_predict.append(get_result_model_TP_FP_TN_FN(first_predict, second_predict, original_y_test, i))\n",
    "    \n",
    "    # TODO: 마지막에 예를들어 클래스 0에 대해서 마지막에 클래스 0만 true로 리라벨링해서 한 번더 걸러주고 정학도 보기\n",
    "    \n",
    "    # 첫번째 모델에서 True 두번째 모델에서 False가 나온 모델\n",
    "#     class_accuracy.append(getRealTrueRatio(first_predict, second_predict, original_y_test,i))  \n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 :  0\n",
      "첫번째 모델에서 TP:  886\n",
      "첫번째 모델에서 FP:  1832\n",
      "첫번째 모델에서 TN:  7168\n",
      "첫번째 모델에서 FN:  114\n",
      "두번째 모델에서 TP:  17\n",
      "두번째 모델에서 FP:  2931\n",
      "두번째 모델에서 TN:  6069\n",
      "두번째 모델에서 FN:  983\n",
      "모델 결과 TP:  881\n",
      "모델 결과 FP:  1753\n",
      "모델 결과 TN:  7247\n",
      "모델 결과 FN:  119\n",
      "precision:  0.3344722854973424\n",
      "accuracy:  0.8128\n",
      "\n",
      "클래스 :  1\n",
      "첫번째 모델에서 TP:  936\n",
      "첫번째 모델에서 FP:  1803\n",
      "첫번째 모델에서 TN:  7197\n",
      "첫번째 모델에서 FN:  64\n",
      "두번째 모델에서 TP:  5\n",
      "두번째 모델에서 FP:  2642\n",
      "두번째 모델에서 TN:  6358\n",
      "두번째 모델에서 FN:  995\n",
      "모델 결과 TP:  934\n",
      "모델 결과 FP:  1796\n",
      "모델 결과 TN:  7204\n",
      "모델 결과 FN:  66\n",
      "precision:  0.34212454212454213\n",
      "accuracy:  0.8138\n",
      "\n",
      "클래스 :  2\n",
      "첫번째 모델에서 TP:  783\n",
      "첫번째 모델에서 FP:  2448\n",
      "첫번째 모델에서 TN:  6552\n",
      "첫번째 모델에서 FN:  217\n",
      "두번째 모델에서 TP:  41\n",
      "두번째 모델에서 FP:  2956\n",
      "두번째 모델에서 TN:  6044\n",
      "두번째 모델에서 FN:  959\n",
      "모델 결과 TP:  762\n",
      "모델 결과 FP:  2210\n",
      "모델 결과 TN:  6790\n",
      "모델 결과 FN:  238\n",
      "precision:  0.25639300134589504\n",
      "accuracy:  0.7552\n",
      "\n",
      "클래스 :  3\n",
      "첫번째 모델에서 TP:  718\n",
      "첫번째 모델에서 FP:  2148\n",
      "첫번째 모델에서 TN:  6852\n",
      "첫번째 모델에서 FN:  282\n",
      "두번째 모델에서 TP:  24\n",
      "두번째 모델에서 FP:  2505\n",
      "두번째 모델에서 TN:  6495\n",
      "두번째 모델에서 FN:  976\n",
      "모델 결과 TP:  707\n",
      "모델 결과 FP:  2100\n",
      "모델 결과 TN:  6900\n",
      "모델 결과 FN:  293\n",
      "precision:  0.2518703241895262\n",
      "accuracy:  0.7607\n",
      "\n",
      "클래스 :  4\n",
      "첫번째 모델에서 TP:  851\n",
      "첫번째 모델에서 FP:  2574\n",
      "첫번째 모델에서 TN:  6426\n",
      "첫번째 모델에서 FN:  149\n",
      "두번째 모델에서 TP:  10\n",
      "두번째 모델에서 FP:  3089\n",
      "두번째 모델에서 TN:  5911\n",
      "두번째 모델에서 FN:  990\n",
      "모델 결과 TP:  849\n",
      "모델 결과 FP:  2494\n",
      "모델 결과 TN:  6506\n",
      "모델 결과 FN:  151\n",
      "precision:  0.2539635058330841\n",
      "accuracy:  0.7355\n",
      "\n",
      "클래스 :  5\n",
      "첫번째 모델에서 TP:  828\n",
      "첫번째 모델에서 FP:  1953\n",
      "첫번째 모델에서 TN:  7047\n",
      "첫번째 모델에서 FN:  172\n",
      "두번째 모델에서 TP:  30\n",
      "두번째 모델에서 FP:  3195\n",
      "두번째 모델에서 TN:  5805\n",
      "두번째 모델에서 FN:  970\n",
      "모델 결과 TP:  809\n",
      "모델 결과 FP:  1890\n",
      "모델 결과 TN:  7110\n",
      "모델 결과 FN:  191\n",
      "precision:  0.299740644683216\n",
      "accuracy:  0.7919\n",
      "\n",
      "클래스 :  6\n",
      "첫번째 모델에서 TP:  878\n",
      "첫번째 모델에서 FP:  1783\n",
      "첫번째 모델에서 TN:  7217\n",
      "첫번째 모델에서 FN:  122\n",
      "두번째 모델에서 TP:  15\n",
      "두번째 모델에서 FP:  3072\n",
      "두번째 모델에서 TN:  5928\n",
      "두번째 모델에서 FN:  985\n",
      "모델 결과 TP:  873\n",
      "모델 결과 FP:  1715\n",
      "모델 결과 TN:  7285\n",
      "모델 결과 FN:  127\n",
      "precision:  0.3373261205564142\n",
      "accuracy:  0.8158\n",
      "\n",
      "클래스 :  7\n",
      "첫번째 모델에서 TP:  860\n",
      "첫번째 모델에서 FP:  1997\n",
      "첫번째 모델에서 TN:  7003\n",
      "첫번째 모델에서 FN:  140\n",
      "두번째 모델에서 TP:  11\n",
      "두번째 모델에서 FP:  2971\n",
      "두번째 모델에서 TN:  6029\n",
      "두번째 모델에서 FN:  989\n",
      "모델 결과 TP:  854\n",
      "모델 결과 FP:  1978\n",
      "모델 결과 TN:  7022\n",
      "모델 결과 FN:  146\n",
      "precision:  0.3015536723163842\n",
      "accuracy:  0.7876\n",
      "\n",
      "클래스 :  8\n",
      "첫번째 모델에서 TP:  910\n",
      "첫번째 모델에서 FP:  2025\n",
      "첫번째 모델에서 TN:  6975\n",
      "첫번째 모델에서 FN:  90\n",
      "두번째 모델에서 TP:  9\n",
      "두번째 모델에서 FP:  2565\n",
      "두번째 모델에서 TN:  6435\n",
      "두번째 모델에서 FN:  991\n",
      "모델 결과 TP:  909\n",
      "모델 결과 FP:  2012\n",
      "모델 결과 TN:  6988\n",
      "모델 결과 FN:  91\n",
      "precision:  0.3111947963026361\n",
      "accuracy:  0.7897\n",
      "\n",
      "클래스 :  9\n",
      "첫번째 모델에서 TP:  884\n",
      "첫번째 모델에서 FP:  1815\n",
      "첫번째 모델에서 TN:  7185\n",
      "첫번째 모델에서 FN:  116\n",
      "두번째 모델에서 TP:  15\n",
      "두번째 모델에서 FP:  2184\n",
      "두번째 모델에서 TN:  6816\n",
      "두번째 모델에서 FN:  985\n",
      "모델 결과 TP:  879\n",
      "모델 결과 FP:  1756\n",
      "모델 결과 TN:  7244\n",
      "모델 결과 FN:  121\n",
      "precision:  0.3335863377609108\n",
      "accuracy:  0.8123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"클래스 : \",i)\n",
    "    print(\"첫번째 모델에서 TP: \", len(first_TP_FP_TN_FN[i][0]))\n",
    "    print(\"첫번째 모델에서 FP: \", len(first_TP_FP_TN_FN[i][1]))\n",
    "    print(\"첫번째 모델에서 TN: \", len(first_TP_FP_TN_FN[i][2]))\n",
    "    print(\"첫번째 모델에서 FN: \", len(first_TP_FP_TN_FN[i][3]))\n",
    "\n",
    "    print(\"두번째 모델에서 TP: \", len(second_TP_FP_TN_FN[i][0]))\n",
    "    print(\"두번째 모델에서 FP: \", len(second_TP_FP_TN_FN[i][1]))\n",
    "    print(\"두번째 모델에서 TN: \", len(second_TP_FP_TN_FN[i][2]))\n",
    "    print(\"두번째 모델에서 FN: \", len(second_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"모델 결과 TP: \", len(model_result_predict[i][0]))\n",
    "    print(\"모델 결과 FP: \", len(model_result_predict[i][1]))\n",
    "    print(\"모델 결과 TN: \", len(model_result_predict[i][2]))\n",
    "    print(\"모델 결과 FN: \", len(model_result_predict[i][3]))\n",
    "    \n",
    "    # precision = TP / (TP + FP)\n",
    "    print(\"precision: \", (len(model_result_predict[i][0]) / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]))))\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy: \", ((len(model_result_predict[i][0]) + len(model_result_predict[i][2]))\n",
    "                               / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3]))))\n",
    "    print(\"\")\n",
    "\n",
    "    #     print(\"true-false를 통과한 개수 : \", 1000 - (len(first_false[i]) + len(second_true[i])) )\n",
    "#     print(\"precision: \", len(first_TP_TN[i][0])/(len(first_TP_TN[i][0]) + len(second_FP_FN[i][0])))\n",
    "#     print(\"accuracy: \", (len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]))\n",
    "#           /len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]) + len(second_FP_FN[0][i]) + len(second_FP_FN[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
