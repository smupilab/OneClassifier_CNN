{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEWkBMJpNvd_",
    "outputId": "e010c54f-38c1-4abd-c7e4-d29e7e531432"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(original_x_train, original_y_train), (original_x_test, original_y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DG5AhMOLjbeb"
   },
   "outputs": [],
   "source": [
    "original_x_train = original_x_train / 255.0\n",
    "original_x_test = original_x_test / 255.0\n",
    "\n",
    "original_y_train = keras.utils.to_categorical(original_y_train)\n",
    "original_y_test = keras.utils.to_categorical(original_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJRl4tKVolc",
    "outputId": "6acbf001-2b2a-4654-f644-3bacf4a641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 8s 5ms/step - loss: 1.7815 - accuracy: 0.3364 - val_loss: 1.4439 - val_accuracy: 0.4837\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.4542 - accuracy: 0.4762 - val_loss: 1.2580 - val_accuracy: 0.5478\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.3379 - accuracy: 0.5272 - val_loss: 1.1967 - val_accuracy: 0.5825\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2662 - accuracy: 0.5545 - val_loss: 1.0849 - val_accuracy: 0.6262\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2045 - accuracy: 0.5797 - val_loss: 1.0848 - val_accuracy: 0.6088\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1635 - accuracy: 0.5954 - val_loss: 0.9982 - val_accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1242 - accuracy: 0.6071 - val_loss: 1.0020 - val_accuracy: 0.6518\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0983 - accuracy: 0.6150 - val_loss: 0.9458 - val_accuracy: 0.6710\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0669 - accuracy: 0.6303 - val_loss: 0.9258 - val_accuracy: 0.6785\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0431 - accuracy: 0.6375 - val_loss: 0.8904 - val_accuracy: 0.6896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.Flatten())\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Dense(64, activation='relu'))\n",
    "original_model.add(layers.Dropout(0.5))\n",
    "original_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_0 = original_model.fit(original_x_train, original_y_train, epochs= 10, batch_size= 64, validation_data=(original_x_test, original_y_test))\n",
    "# loss: 0.9075 - accuracy: 0.6951 - val_loss: 0.8743 - val_accuracy: 0.7026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvzfjR4SWu6i",
    "outputId": "a168ca0a-a8f4-4c05-8e59-18fa0d285a26",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "[0, 17, 31, 22, 28, 6, 12, 11, 90, 29]\n",
      "[19, 0, 3, 8, 6, 3, 18, 2, 41, 75]\n",
      "[87, 7, 0, 100, 196, 84, 112, 24, 15, 10]\n",
      "[17, 4, 31, 0, 82, 167, 125, 30, 26, 16]\n",
      "[24, 3, 17, 61, 0, 17, 77, 63, 12, 2]\n",
      "[13, 5, 17, 235, 82, 0, 32, 43, 10, 4]\n",
      "[4, 2, 16, 64, 50, 4, 0, 5, 9, 5]\n",
      "[18, 1, 13, 58, 85, 88, 14, 0, 5, 15]\n",
      "[80, 21, 2, 12, 8, 5, 7, 2, 0, 24]\n",
      "[27, 77, 6, 23, 10, 4, 18, 7, 44, 0]\n"
     ]
    }
   ],
   "source": [
    "# 잘못예측한 데이터 찾는 코드\n",
    "# original_label, predict_label\n",
    "wrong_predict = []\n",
    "wrong_predict_cnt = 0\n",
    "class_length = 10\n",
    "\n",
    "model_predict = original_model.predict(original_x_test)\n",
    "\n",
    "for i in range(len(original_y_test)):\n",
    "  predict_idx, original_idx = 0, 0\n",
    "  for j in range(1,10):\n",
    "    if model_predict[i][j] > model_predict[i][predict_idx]:\n",
    "      predict_idx = j\n",
    "    if original_y_test[i][j] > original_y_test[i][original_idx]:\n",
    "      original_idx = j\n",
    "\n",
    "  if predict_idx != original_idx:\n",
    "    wrong_predict.append([original_idx, predict_idx])\n",
    "\n",
    "similar_wrong_predict_count = [[0 for j in range(class_length)] for i in range(class_length)]\n",
    "for i in range(len(wrong_predict)):\n",
    "  similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] = similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] + 1 \n",
    "\n",
    "for i in range(class_length):\n",
    "  print(similar_wrong_predict_count[i])\n",
    "\n",
    "# result\n",
    "# [0, 27, 28, 8, 5, 1, 7, 8, 59, 34]\n",
    "# [16, 0, 0, 6, 1, 3, 3, 1, 18, 51]\n",
    "# [101, 9, 0, 36, 93, 69, 60, 29, 18, 14]\n",
    "# [45, 22, 73, 0, 58, 196, 88, 38, 28, 30]\n",
    "# [40, 4, 71, 39, 0, 26, 66, 94, 11, 3]\n",
    "# [20, 7, 47, 146, 48, 0, 24, 65, 10, 11]\n",
    "# [12, 7, 48, 41, 33, 17, 0, 7, 13, 10]\n",
    "# [23, 2, 32, 23, 36, 50, 5, 0, 4, 15]\n",
    "# [78, 39, 4, 5, 3, 4, 4, 5, 0, 19]\n",
    "# [31, 128, 5, 6, 4, 3, 3, 10, 21, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PXIQquThxGkf"
   },
   "outputs": [],
   "source": [
    "# 가장 큰 값 top 3의 index를 가져와야 함 (cur_idx 제외)\n",
    "def getTopN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  top_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(top_idx) == n:\n",
    "      break;\n",
    "    max_num = -1\n",
    "    max_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if max_num < tmp[j]:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                max_num = tmp[j]\n",
    "                max_idx = j\n",
    "    \n",
    "    if max_idx != -1:\n",
    "      top_idx.append(max_idx)\n",
    "      visited.append(max_idx)\n",
    "  return top_idx\n",
    "\n",
    "# 가장 작은 값 bottom 3의 index를 가져와야 함  (cur_idx 제외)\n",
    "def getBottomN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  bottom_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(bottom_idx) == n:\n",
    "      break;\n",
    "    min_num = 1e9\n",
    "    min_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if tmp[j] < min_num:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                min_num = tmp[j]\n",
    "                min_idx = j\n",
    "    \n",
    "    if min_idx != -1:\n",
    "      bottom_idx.append(min_idx)\n",
    "      visited.append(min_idx)\n",
    "  return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xw4-dk8EBhqV"
   },
   "outputs": [],
   "source": [
    "# cifar10 데이터 가져오는 함수\n",
    "def getCifar10Data():\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train / 255.0\n",
    "  x_test = x_test / 255.0\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# a, b, c로 다시 라벨링\n",
    "def reLabel(y_train, y_test, a, b, c):\n",
    "  for i in range(len(y_train)):\n",
    "    if y_train[i] == a or y_train[i] == b or y_train[i] == c:\n",
    "      y_train[i] = 1\n",
    "    else:\n",
    "      y_train[i] = 0    \n",
    "  \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == a or y_test[i] == b or y_test[i] == c:\n",
    "      y_test[i] = 1\n",
    "    else:\n",
    "      y_test[i] = 0\n",
    "  \n",
    "  return y_train, y_test\n",
    "\n",
    "(model1_x_train, model1_y_train), (model1_x_test, model1_y_test) = getCifar10Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4bb4bjAnNxa3"
   },
   "outputs": [],
   "source": [
    "# model 만드는 함수 \n",
    "def makeModel():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Bxau2L_U9toH"
   },
   "outputs": [],
   "source": [
    "# # 모델의 결과가 true인 predict index 반환함수\n",
    "# def get_TP_FP(y_test, predict, target_idx):\n",
    "#     TP = []\n",
    "#     FP = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 1:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TP.append(i)\n",
    "#             else:\n",
    "#                 FP.append(i)\n",
    "#     return TP, FP\n",
    "\n",
    "# # 모델의 결과가 false인 predict index 반환함수\n",
    "# def get_TN_FN(y_test, predict, target_idx):\n",
    "#     TN = []\n",
    "#     FN = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 0:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TN.append(i)\n",
    "#             else:\n",
    "#                 FN.append(i)\n",
    "#     return TN, FN\n",
    "\n",
    "def get_TP_FP_TN_FN(y_test, predict, target_idx):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "                break\n",
    "        # True로 나왔을 때\n",
    "        if predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        # False로 나왔을 때\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "            \n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_model_TP_FP_TN_FN(first_predict, second_predict, y_test, target_idx):\n",
    "    TP, FP, TN, FN = [],[],[],[]\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "        if first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 0:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        elif first_predict[i].argmax(axis = -1) == 0 and second_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "        elif first_predict[i].argmax(axis = -1) == 0 and second_predict[i].argmax(axis = -1) == 0:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        elif first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "    return TP, FP, TN, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MmmbZyZwFa-",
    "outputId": "6e61ca8b-9629-45f9-d032-a2e072f6c2ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 2, 0]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4677 - accuracy: 0.7925 - val_loss: 0.3750 - val_accuracy: 0.8391\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3746 - accuracy: 0.8452 - val_loss: 0.3270 - val_accuracy: 0.8627\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3402 - accuracy: 0.8593 - val_loss: 0.3099 - val_accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3171 - accuracy: 0.8715 - val_loss: 0.3267 - val_accuracy: 0.8727\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2977 - accuracy: 0.8782 - val_loss: 0.2901 - val_accuracy: 0.8782\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2801 - accuracy: 0.8873 - val_loss: 0.2758 - val_accuracy: 0.8882\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2719 - accuracy: 0.8920 - val_loss: 0.2754 - val_accuracy: 0.8873\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2619 - accuracy: 0.8954 - val_loss: 0.2580 - val_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2515 - accuracy: 0.8999 - val_loss: 0.2646 - val_accuracy: 0.8946\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2427 - accuracy: 0.9040 - val_loss: 0.2539 - val_accuracy: 0.8979\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4893 - accuracy: 0.7361 - val_loss: 0.4282 - val_accuracy: 0.7807\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4289 - accuracy: 0.7854 - val_loss: 0.4000 - val_accuracy: 0.7995\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4034 - accuracy: 0.8022 - val_loss: 0.3717 - val_accuracy: 0.8231\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3824 - accuracy: 0.8178 - val_loss: 0.4212 - val_accuracy: 0.7908\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3658 - accuracy: 0.8273 - val_loss: 0.3635 - val_accuracy: 0.8266\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3524 - accuracy: 0.8331 - val_loss: 0.3349 - val_accuracy: 0.8385\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3388 - accuracy: 0.8425 - val_loss: 0.3205 - val_accuracy: 0.8505\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3301 - accuracy: 0.8475 - val_loss: 0.3269 - val_accuracy: 0.8521\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3182 - accuracy: 0.8533 - val_loss: 0.3102 - val_accuracy: 0.8550\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3088 - accuracy: 0.8588 - val_loss: 0.3165 - val_accuracy: 0.8532\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "1 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[9, 8, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3600 - accuracy: 0.8377 - val_loss: 0.2872 - val_accuracy: 0.8804\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2718 - accuracy: 0.8884 - val_loss: 0.2546 - val_accuracy: 0.8863\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2293 - accuracy: 0.9087 - val_loss: 0.2224 - val_accuracy: 0.9106\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1991 - accuracy: 0.9221 - val_loss: 0.2144 - val_accuracy: 0.9095\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1743 - accuracy: 0.9338 - val_loss: 0.1617 - val_accuracy: 0.9357\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1620 - accuracy: 0.9381 - val_loss: 0.1483 - val_accuracy: 0.9457\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1459 - accuracy: 0.9459 - val_loss: 0.1556 - val_accuracy: 0.9374\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1335 - accuracy: 0.9488 - val_loss: 0.1260 - val_accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1261 - accuracy: 0.9531 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1170 - accuracy: 0.9561 - val_loss: 0.1208 - val_accuracy: 0.9557\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[7, 2, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.5045 - accuracy: 0.7363 - val_loss: 0.4209 - val_accuracy: 0.7930\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4295 - accuracy: 0.7906 - val_loss: 0.3900 - val_accuracy: 0.8176\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3983 - accuracy: 0.8103 - val_loss: 0.3839 - val_accuracy: 0.8243\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3745 - accuracy: 0.8250 - val_loss: 0.3602 - val_accuracy: 0.8317\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3616 - accuracy: 0.8328 - val_loss: 0.3373 - val_accuracy: 0.8484\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3465 - accuracy: 0.8429 - val_loss: 0.3383 - val_accuracy: 0.8453\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3299 - accuracy: 0.8502 - val_loss: 0.3434 - val_accuracy: 0.8416\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3221 - accuracy: 0.8533 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3085 - accuracy: 0.8619 - val_loss: 0.3072 - val_accuracy: 0.8613\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3036 - accuracy: 0.8646 - val_loss: 0.3037 - val_accuracy: 0.8614\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "2 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 6, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4859 - accuracy: 0.7659 - val_loss: 0.4076 - val_accuracy: 0.8072\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4104 - accuracy: 0.8103 - val_loss: 0.4384 - val_accuracy: 0.7867\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3796 - accuracy: 0.8286 - val_loss: 0.3452 - val_accuracy: 0.8473\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3580 - accuracy: 0.8408 - val_loss: 0.3409 - val_accuracy: 0.8463\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3406 - accuracy: 0.8507 - val_loss: 0.3530 - val_accuracy: 0.8490\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3284 - accuracy: 0.8568 - val_loss: 0.3154 - val_accuracy: 0.8619\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3129 - accuracy: 0.8640 - val_loss: 0.3142 - val_accuracy: 0.8621\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3002 - accuracy: 0.8696 - val_loss: 0.2977 - val_accuracy: 0.8719\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2909 - accuracy: 0.8750 - val_loss: 0.3223 - val_accuracy: 0.8599\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2846 - accuracy: 0.8776 - val_loss: 0.2874 - val_accuracy: 0.8791\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3567 - accuracy: 0.8424 - val_loss: 0.2720 - val_accuracy: 0.8867\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2591 - accuracy: 0.8936 - val_loss: 0.2253 - val_accuracy: 0.9110\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2237 - accuracy: 0.9124 - val_loss: 0.2062 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1959 - accuracy: 0.9223 - val_loss: 0.1648 - val_accuracy: 0.9348\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1699 - accuracy: 0.9349 - val_loss: 0.1861 - val_accuracy: 0.9342\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9411 - val_loss: 0.1473 - val_accuracy: 0.9455\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1421 - accuracy: 0.9459 - val_loss: 0.1449 - val_accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1337 - accuracy: 0.9497 - val_loss: 0.1330 - val_accuracy: 0.9481\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1245 - accuracy: 0.9533 - val_loss: 0.1288 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1173 - accuracy: 0.9550 - val_loss: 0.1308 - val_accuracy: 0.9519\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "3 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[5, 6, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4555 - accuracy: 0.7676 - val_loss: 0.3850 - val_accuracy: 0.8170\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3718 - accuracy: 0.8295 - val_loss: 0.3504 - val_accuracy: 0.8426\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3424 - accuracy: 0.8468 - val_loss: 0.3458 - val_accuracy: 0.8411\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3204 - accuracy: 0.8577 - val_loss: 0.3133 - val_accuracy: 0.8569\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3038 - accuracy: 0.8676 - val_loss: 0.3011 - val_accuracy: 0.8686\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2884 - accuracy: 0.8741 - val_loss: 0.2881 - val_accuracy: 0.8722\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2775 - accuracy: 0.8802 - val_loss: 0.3104 - val_accuracy: 0.8653\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2679 - accuracy: 0.8852 - val_loss: 0.2656 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2609 - accuracy: 0.8896 - val_loss: 0.2822 - val_accuracy: 0.8784\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2502 - accuracy: 0.8939 - val_loss: 0.2781 - val_accuracy: 0.8741\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 0]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4165 - accuracy: 0.7995 - val_loss: 0.3519 - val_accuracy: 0.8343\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3112 - accuracy: 0.8645 - val_loss: 0.2555 - val_accuracy: 0.8859\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2634 - accuracy: 0.8927 - val_loss: 0.2212 - val_accuracy: 0.9110\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2340 - accuracy: 0.9068 - val_loss: 0.2086 - val_accuracy: 0.9116\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2105 - accuracy: 0.9158 - val_loss: 0.2153 - val_accuracy: 0.9117\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1986 - accuracy: 0.9216 - val_loss: 0.1844 - val_accuracy: 0.9265\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1895 - accuracy: 0.9255 - val_loss: 0.1846 - val_accuracy: 0.9251\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1758 - accuracy: 0.9316 - val_loss: 0.1783 - val_accuracy: 0.9266\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1690 - accuracy: 0.9345 - val_loss: 0.1711 - val_accuracy: 0.9307\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1605 - accuracy: 0.9379 - val_loss: 0.1670 - val_accuracy: 0.9347\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "4 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[6, 7, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4861 - accuracy: 0.7590 - val_loss: 0.4300 - val_accuracy: 0.8046\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4108 - accuracy: 0.8098 - val_loss: 0.3547 - val_accuracy: 0.8431\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3669 - accuracy: 0.8353 - val_loss: 0.3378 - val_accuracy: 0.8460\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3423 - accuracy: 0.8491 - val_loss: 0.3081 - val_accuracy: 0.8624\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3229 - accuracy: 0.8599 - val_loss: 0.3157 - val_accuracy: 0.8559\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3080 - accuracy: 0.8666 - val_loss: 0.2947 - val_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2940 - accuracy: 0.8743 - val_loss: 0.2792 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2857 - accuracy: 0.8776 - val_loss: 0.2767 - val_accuracy: 0.8822\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2745 - accuracy: 0.8838 - val_loss: 0.2871 - val_accuracy: 0.8796\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2668 - accuracy: 0.8863 - val_loss: 0.2706 - val_accuracy: 0.8828\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3468 - accuracy: 0.8481 - val_loss: 0.2593 - val_accuracy: 0.8879\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2540 - accuracy: 0.8968 - val_loss: 0.2177 - val_accuracy: 0.9094\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2115 - accuracy: 0.9152 - val_loss: 0.1696 - val_accuracy: 0.9318\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1796 - accuracy: 0.9315 - val_loss: 0.1796 - val_accuracy: 0.9278\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1621 - accuracy: 0.9389 - val_loss: 0.1538 - val_accuracy: 0.9342\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1471 - accuracy: 0.9443 - val_loss: 0.1317 - val_accuracy: 0.9496\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1358 - accuracy: 0.9491 - val_loss: 0.1404 - val_accuracy: 0.9469\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1257 - accuracy: 0.9519 - val_loss: 0.1256 - val_accuracy: 0.9517\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1171 - accuracy: 0.9559 - val_loss: 0.1315 - val_accuracy: 0.9538\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1112 - accuracy: 0.9583 - val_loss: 0.1569 - val_accuracy: 0.9327\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "5 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 4, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.4951 - accuracy: 0.7437 - val_loss: 0.4262 - val_accuracy: 0.7880\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4391 - accuracy: 0.7838 - val_loss: 0.4168 - val_accuracy: 0.7945\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4126 - accuracy: 0.8010 - val_loss: 0.4548 - val_accuracy: 0.7899\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3963 - accuracy: 0.8105 - val_loss: 0.4069 - val_accuracy: 0.7950\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3828 - accuracy: 0.8214 - val_loss: 0.3755 - val_accuracy: 0.8208\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3693 - accuracy: 0.8284 - val_loss: 0.3657 - val_accuracy: 0.8295\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3558 - accuracy: 0.8368 - val_loss: 0.3446 - val_accuracy: 0.8456\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3451 - accuracy: 0.8425 - val_loss: 0.3498 - val_accuracy: 0.8387\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3341 - accuracy: 0.8493 - val_loss: 0.3317 - val_accuracy: 0.8493\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3225 - accuracy: 0.8562 - val_loss: 0.3236 - val_accuracy: 0.8540\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3529 - accuracy: 0.8451 - val_loss: 0.2565 - val_accuracy: 0.8919\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2600 - accuracy: 0.8945 - val_loss: 0.2114 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2210 - accuracy: 0.9127 - val_loss: 0.2042 - val_accuracy: 0.9155\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1970 - accuracy: 0.9249 - val_loss: 0.1589 - val_accuracy: 0.9369\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1724 - accuracy: 0.9330 - val_loss: 0.1526 - val_accuracy: 0.9402\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1562 - accuracy: 0.9405 - val_loss: 0.1543 - val_accuracy: 0.9368\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1399 - accuracy: 0.9466 - val_loss: 0.1326 - val_accuracy: 0.9477\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1313 - accuracy: 0.9510 - val_loss: 0.1387 - val_accuracy: 0.9490\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1237 - accuracy: 0.9543 - val_loss: 0.1240 - val_accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1141 - accuracy: 0.9565 - val_loss: 0.1634 - val_accuracy: 0.9450\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "6 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 4, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4908 - accuracy: 0.7572 - val_loss: 0.4591 - val_accuracy: 0.7868\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4399 - accuracy: 0.7876 - val_loss: 0.4153 - val_accuracy: 0.7957\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.3916 - val_accuracy: 0.8112\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.4489 - val_accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3771 - accuracy: 0.8263 - val_loss: 0.4003 - val_accuracy: 0.8240\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3597 - accuracy: 0.8351 - val_loss: 0.3516 - val_accuracy: 0.8447\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3451 - accuracy: 0.8418 - val_loss: 0.3259 - val_accuracy: 0.8524\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3327 - accuracy: 0.8501 - val_loss: 0.3239 - val_accuracy: 0.8538\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3252 - accuracy: 0.8536 - val_loss: 0.3196 - val_accuracy: 0.8580\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3162 - accuracy: 0.8574 - val_loss: 0.3252 - val_accuracy: 0.8631\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 0, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5628 - accuracy: 0.7181 - val_loss: 0.5238 - val_accuracy: 0.7563\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.5012 - accuracy: 0.7645 - val_loss: 0.4719 - val_accuracy: 0.7720\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4526 - accuracy: 0.7939 - val_loss: 0.4097 - val_accuracy: 0.8170\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4199 - accuracy: 0.8136 - val_loss: 0.4340 - val_accuracy: 0.8113\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3989 - accuracy: 0.8227 - val_loss: 0.3809 - val_accuracy: 0.8289\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3792 - accuracy: 0.8338 - val_loss: 0.3633 - val_accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3618 - accuracy: 0.8443 - val_loss: 0.3509 - val_accuracy: 0.8463\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3503 - accuracy: 0.8500 - val_loss: 0.3560 - val_accuracy: 0.8486\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3365 - accuracy: 0.8542 - val_loss: 0.3700 - val_accuracy: 0.8468\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3326 - accuracy: 0.8588 - val_loss: 0.3658 - val_accuracy: 0.8440\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "7 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[5, 4, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4729 - accuracy: 0.7590 - val_loss: 0.4084 - val_accuracy: 0.8102\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3938 - accuracy: 0.8127 - val_loss: 0.3579 - val_accuracy: 0.8289\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3529 - accuracy: 0.8384 - val_loss: 0.3163 - val_accuracy: 0.8576\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3262 - accuracy: 0.8521 - val_loss: 0.3013 - val_accuracy: 0.8657\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3085 - accuracy: 0.8605 - val_loss: 0.3119 - val_accuracy: 0.8573\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2976 - accuracy: 0.8677 - val_loss: 0.2745 - val_accuracy: 0.8755\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2826 - accuracy: 0.8765 - val_loss: 0.2675 - val_accuracy: 0.8797\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2728 - accuracy: 0.8804 - val_loss: 0.2751 - val_accuracy: 0.8721\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2612 - accuracy: 0.8857 - val_loss: 0.2767 - val_accuracy: 0.8715\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2558 - accuracy: 0.8899 - val_loss: 0.2674 - val_accuracy: 0.8832\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 8, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5324 - accuracy: 0.7394 - val_loss: 0.4821 - val_accuracy: 0.7820\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4562 - accuracy: 0.7956 - val_loss: 0.4143 - val_accuracy: 0.8140\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4012 - accuracy: 0.8264 - val_loss: 0.3720 - val_accuracy: 0.8429\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3640 - accuracy: 0.8438 - val_loss: 0.3429 - val_accuracy: 0.8506\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3384 - accuracy: 0.8589 - val_loss: 0.3447 - val_accuracy: 0.8530\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3232 - accuracy: 0.8658 - val_loss: 0.3182 - val_accuracy: 0.8683\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3068 - accuracy: 0.8733 - val_loss: 0.3151 - val_accuracy: 0.8685\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2946 - accuracy: 0.8785 - val_loss: 0.3311 - val_accuracy: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2860 - accuracy: 0.8836 - val_loss: 0.3199 - val_accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2736 - accuracy: 0.8899 - val_loss: 0.2915 - val_accuracy: 0.8791\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "8 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[0, 9, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4070 - accuracy: 0.8129 - val_loss: 0.3448 - val_accuracy: 0.8402\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3217 - accuracy: 0.8622 - val_loss: 0.2926 - val_accuracy: 0.8712\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2817 - accuracy: 0.8829 - val_loss: 0.2941 - val_accuracy: 0.8707\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2568 - accuracy: 0.8957 - val_loss: 0.2382 - val_accuracy: 0.9034\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2380 - accuracy: 0.9051 - val_loss: 0.2108 - val_accuracy: 0.9166\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2177 - accuracy: 0.9133 - val_loss: 0.1972 - val_accuracy: 0.9211\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2065 - accuracy: 0.9195 - val_loss: 0.2368 - val_accuracy: 0.9083\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1918 - accuracy: 0.9242 - val_loss: 0.1876 - val_accuracy: 0.9273\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1844 - accuracy: 0.9277 - val_loss: 0.1878 - val_accuracy: 0.9293\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1746 - accuracy: 0.9316 - val_loss: 0.1841 - val_accuracy: 0.9295\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[2, 7, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.5078 - accuracy: 0.7407 - val_loss: 0.4462 - val_accuracy: 0.7811\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4363 - accuracy: 0.7876 - val_loss: 0.4080 - val_accuracy: 0.8006\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4142 - accuracy: 0.8044 - val_loss: 0.4334 - val_accuracy: 0.7937\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3871 - accuracy: 0.8155 - val_loss: 0.3576 - val_accuracy: 0.8305\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3695 - accuracy: 0.8285 - val_loss: 0.3595 - val_accuracy: 0.8305\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3523 - accuracy: 0.8386 - val_loss: 0.3279 - val_accuracy: 0.8502\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3387 - accuracy: 0.8428 - val_loss: 0.3377 - val_accuracy: 0.8493\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3257 - accuracy: 0.8520 - val_loss: 0.3234 - val_accuracy: 0.8528\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3167 - accuracy: 0.8566 - val_loss: 0.3128 - val_accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3075 - accuracy: 0.8615 - val_loss: 0.3011 - val_accuracy: 0.8648\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "9 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[1, 8, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3682 - accuracy: 0.8359 - val_loss: 0.2544 - val_accuracy: 0.8901\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2686 - accuracy: 0.8907 - val_loss: 0.2306 - val_accuracy: 0.9020\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2343 - accuracy: 0.9073 - val_loss: 0.2161 - val_accuracy: 0.9090\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1969 - accuracy: 0.9230 - val_loss: 0.2404 - val_accuracy: 0.9178\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1724 - accuracy: 0.9340 - val_loss: 0.1671 - val_accuracy: 0.9327\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1597 - accuracy: 0.9390 - val_loss: 0.1585 - val_accuracy: 0.9396\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1474 - accuracy: 0.9445 - val_loss: 0.1376 - val_accuracy: 0.9467\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1360 - accuracy: 0.9482 - val_loss: 0.1319 - val_accuracy: 0.9476\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1283 - accuracy: 0.9519 - val_loss: 0.1283 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1198 - accuracy: 0.9553 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 2, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5038 - accuracy: 0.7412 - val_loss: 0.4309 - val_accuracy: 0.7945\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4323 - accuracy: 0.7905 - val_loss: 0.3860 - val_accuracy: 0.8115\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3989 - accuracy: 0.8082 - val_loss: 0.3734 - val_accuracy: 0.8249\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3760 - accuracy: 0.8247 - val_loss: 0.3483 - val_accuracy: 0.8425\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3544 - accuracy: 0.8361 - val_loss: 0.3481 - val_accuracy: 0.8361\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3407 - accuracy: 0.8442 - val_loss: 0.3164 - val_accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3288 - accuracy: 0.8508 - val_loss: 0.3175 - val_accuracy: 0.8564\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3146 - accuracy: 0.8588 - val_loss: 0.3155 - val_accuracy: 0.8540\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3055 - accuracy: 0.8623 - val_loss: 0.2978 - val_accuracy: 0.8665\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2952 - accuracy: 0.8688 - val_loss: 0.2979 - val_accuracy: 0.8655\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 0~9 클래스 \n",
    "# 0클래스 결과값을 봤을 때, true-false모델을 통과한 0번 클래스가 772개인데 나머지 클래스들이 어디서 데이터가 누수됐는지 분석해보기\n",
    "\n",
    "class_accuracy = []\n",
    "first_TP_FP_TN_FN = []\n",
    "second_TP_FP_TN_FN = []\n",
    "model_result_predict = []\n",
    "\n",
    "for i in range(0, class_length):\n",
    "    print(i, \"번째 클래스\")\n",
    "    # 첫번째 모델 -> 가장 유사한 클래스끼리 묶은 라벨\n",
    "    print(\"[model1] : 가장 유사한 클래스끼리 묶은 라벨\")\n",
    "    (x_train, y_train), (x_test, y_test) = getCifar10Data()\n",
    "    temp = getTopN(similar_wrong_predict_count[i], 2, i)\n",
    "    # 현재 클래스 index 추가 \n",
    "    temp.append(i)\n",
    "    print(temp)\n",
    "    (y_train, y_test) = reLabel(y_train, y_test, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model1 = makeModel()\n",
    "    model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model1.fit(x_train, y_train, epochs= 10, batch_size = 64, validation_data=(x_test, y_test))\n",
    "    first_predict = model1.predict(x_test)\n",
    "#     first_TP_FP.append(get_TP_FP(original_y_test, first_predict, i))\n",
    "#     first_TN_FN.append(get_TN_FN(original_y_test, first_predict, i))\n",
    "    first_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, first_predict, i))\n",
    "    \n",
    "    \n",
    "    # 두번째 모델 -> 가장 유사하지않은 클래스끼리 묶은 라벨\n",
    "    print(\"[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\")\n",
    "    (x_train2, y_train2), (x_test2, y_test2) = getCifar10Data()\n",
    "    temp = getBottomN(similar_wrong_predict_count[i], 3, i)\n",
    "    print(temp)\n",
    "\n",
    "    (y_train2, y_test2) = reLabel(y_train2, y_test2, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model2 = makeModel()\n",
    "    model2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model2.fit(x_train2, y_train2, epochs= 10, batch_size = 64, validation_data=(x_test2, y_test2))\n",
    "    second_predict = model2.predict(x_test2)\n",
    "#     second_TP_FP.append(get_TP_FP(original_y_test, second_predict, i))\n",
    "#     second_TN_FN.append(get_TN_FN(original_y_test, second_predict, i))\n",
    "    second_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, second_predict, i))\n",
    "    \n",
    "    # 모델의 TP FP TN FN\n",
    "    model_result_predict.append(get_result_model_TP_FP_TN_FN(first_predict, second_predict, original_y_test, i))\n",
    "    \n",
    "    \n",
    "    # 첫번째 모델에서 True 두번째 모델에서 False가 나온 모델\n",
    "#     class_accuracy.append(getRealTrueRatio(first_predict, second_predict, original_y_test,i))  \n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 :  0\n",
      "첫번째 모델에서 TP:  848\n",
      "첫번째 모델에서 FP:  1921\n",
      "첫번째 모델에서 TN:  7079\n",
      "첫번째 모델에서 FN:  152\n",
      "두번째 모델에서 TP:  26\n",
      "두번째 모델에서 FP:  3262\n",
      "두번째 모델에서 TN:  5738\n",
      "두번째 모델에서 FN:  974\n",
      "모델 결과 TP:  974\n",
      "모델 결과 FP:  5738\n",
      "모델 결과 TN:  3262\n",
      "모델 결과 FN:  26\n",
      "precision:  0.14511323003575685\n",
      "accuracy:  0.4236\n",
      "\n",
      "클래스 :  1\n",
      "첫번째 모델에서 TP:  945\n",
      "첫번째 모델에서 FP:  1990\n",
      "첫번째 모델에서 TN:  7010\n",
      "첫번째 모델에서 FN:  55\n",
      "두번째 모델에서 TP:  7\n",
      "두번째 모델에서 FP:  2775\n",
      "두번째 모델에서 TN:  6225\n",
      "두번째 모델에서 FN:  993\n",
      "모델 결과 TP:  993\n",
      "모델 결과 FP:  6225\n",
      "모델 결과 TN:  2775\n",
      "모델 결과 FN:  7\n",
      "precision:  0.13757273482959267\n",
      "accuracy:  0.3768\n",
      "\n",
      "클래스 :  2\n",
      "첫번째 모델에서 TP:  720\n",
      "첫번째 모델에서 FP:  2309\n",
      "첫번째 모델에서 TN:  6691\n",
      "첫번째 모델에서 FN:  280\n",
      "두번째 모델에서 TP:  25\n",
      "두번째 모델에서 FP:  3080\n",
      "두번째 모델에서 TN:  5920\n",
      "두번째 모델에서 FN:  975\n",
      "모델 결과 TP:  975\n",
      "모델 결과 FP:  5920\n",
      "모델 결과 TN:  3080\n",
      "모델 결과 FN:  25\n",
      "precision:  0.1414068165337201\n",
      "accuracy:  0.4055\n",
      "\n",
      "클래스 :  3\n",
      "첫번째 모델에서 TP:  832\n",
      "첫번째 모델에서 FP:  2675\n",
      "첫번째 모델에서 TN:  6325\n",
      "첫번째 모델에서 FN:  168\n",
      "두번째 모델에서 TP:  29\n",
      "두번째 모델에서 FP:  2800\n",
      "두번째 모델에서 TN:  6200\n",
      "두번째 모델에서 FN:  971\n",
      "모델 결과 TP:  971\n",
      "모델 결과 FP:  6200\n",
      "모델 결과 TN:  2800\n",
      "모델 결과 FN:  29\n",
      "precision:  0.1354064983963185\n",
      "accuracy:  0.3771\n",
      "\n",
      "클래스 :  4\n",
      "첫번째 모델에서 TP:  819\n",
      "첫번째 모델에서 FP:  2239\n",
      "첫번째 모델에서 TN:  6761\n",
      "첫번째 모델에서 FN:  181\n",
      "두번째 모델에서 TP:  32\n",
      "두번째 모델에서 FP:  3415\n",
      "두번째 모델에서 TN:  5585\n",
      "두번째 모델에서 FN:  968\n",
      "모델 결과 TP:  968\n",
      "모델 결과 FP:  5585\n",
      "모델 결과 TN:  3415\n",
      "모델 결과 FN:  32\n",
      "precision:  0.14771860216694643\n",
      "accuracy:  0.4383\n",
      "\n",
      "클래스 :  5\n",
      "첫번째 모델에서 TP:  862\n",
      "첫번째 모델에서 FP:  2284\n",
      "첫번째 모델에서 TN:  6716\n",
      "첫번째 모델에서 FN:  138\n",
      "두번째 모델에서 TP:  28\n",
      "두번째 모델에서 FP:  3276\n",
      "두번째 모델에서 TN:  5724\n",
      "두번째 모델에서 FN:  972\n",
      "모델 결과 TP:  972\n",
      "모델 결과 FP:  5724\n",
      "모델 결과 TN:  3276\n",
      "모델 결과 FN:  28\n",
      "precision:  0.14516129032258066\n",
      "accuracy:  0.4248\n",
      "\n",
      "클래스 :  6\n",
      "첫번째 모델에서 TP:  922\n",
      "첫번째 모델에서 FP:  2229\n",
      "첫번째 모델에서 TN:  6771\n",
      "첫번째 모델에서 FN:  78\n",
      "두번째 모델에서 TP:  6\n",
      "두번째 모델에서 FP:  1854\n",
      "두번째 모델에서 TN:  7146\n",
      "두번째 모델에서 FN:  994\n",
      "모델 결과 TP:  994\n",
      "모델 결과 FP:  7146\n",
      "모델 결과 TN:  1854\n",
      "모델 결과 FN:  6\n",
      "precision:  0.12211302211302211\n",
      "accuracy:  0.2848\n",
      "\n",
      "클래스 :  7\n",
      "첫번째 모델에서 TP:  899\n",
      "첫번째 모델에서 FP:  2171\n",
      "첫번째 모델에서 TN:  6829\n",
      "첫번째 모델에서 FN:  101\n",
      "두번째 모델에서 TP:  15\n",
      "두번째 모델에서 FP:  2690\n",
      "두번째 모델에서 TN:  6310\n",
      "두번째 모델에서 FN:  985\n",
      "모델 결과 TP:  985\n",
      "모델 결과 FP:  6310\n",
      "모델 결과 TN:  2690\n",
      "모델 결과 FN:  15\n",
      "precision:  0.13502398903358465\n",
      "accuracy:  0.3675\n",
      "\n",
      "클래스 :  8\n",
      "첫번째 모델에서 TP:  903\n",
      "첫번째 모델에서 FP:  2040\n",
      "첫번째 모델에서 TN:  6960\n",
      "첫번째 모델에서 FN:  97\n",
      "두번째 모델에서 TP:  10\n",
      "두번째 모델에서 FP:  2806\n",
      "두번째 모델에서 TN:  6194\n",
      "두번째 모델에서 FN:  990\n",
      "모델 결과 TP:  990\n",
      "모델 결과 FP:  6194\n",
      "모델 결과 TN:  2806\n",
      "모델 결과 FN:  10\n",
      "precision:  0.13780623608017817\n",
      "accuracy:  0.3796\n",
      "\n",
      "클래스 :  9\n",
      "첫번째 모델에서 TP:  899\n",
      "첫번째 모델에서 FP:  1969\n",
      "첫번째 모델에서 TN:  7031\n",
      "첫번째 모델에서 FN:  101\n",
      "두번째 모델에서 TP:  9\n",
      "두번째 모델에서 FP:  2752\n",
      "두번째 모델에서 TN:  6248\n",
      "두번째 모델에서 FN:  991\n",
      "모델 결과 TP:  991\n",
      "모델 결과 FP:  6248\n",
      "모델 결과 TN:  2752\n",
      "모델 결과 FN:  9\n",
      "precision:  0.13689736151402127\n",
      "accuracy:  0.3743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"클래스 : \",i)\n",
    "    print(\"첫번째 모델에서 TP: \", len(first_TP_FP_TN_FN[i][0]))\n",
    "    print(\"첫번째 모델에서 FP: \", len(first_TP_FP_TN_FN[i][1]))\n",
    "    print(\"첫번째 모델에서 TN: \", len(first_TP_FP_TN_FN[i][2]))\n",
    "    print(\"첫번째 모델에서 FN: \", len(first_TP_FP_TN_FN[i][3]))\n",
    "\n",
    "    print(\"두번째 모델에서 TP: \", len(second_TP_FP_TN_FN[i][0]))\n",
    "    print(\"두번째 모델에서 FP: \", len(second_TP_FP_TN_FN[i][1]))\n",
    "    print(\"두번째 모델에서 TN: \", len(second_TP_FP_TN_FN[i][2]))\n",
    "    print(\"두번째 모델에서 FN: \", len(second_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"모델 결과 TP: \", len(model_result_predict[i][0]))\n",
    "    print(\"모델 결과 FP: \", len(model_result_predict[i][1]))\n",
    "    print(\"모델 결과 TN: \", len(model_result_predict[i][2]))\n",
    "    print(\"모델 결과 FN: \", len(model_result_predict[i][3]))\n",
    "    \n",
    "    # precision = TP / (TP + FP)\n",
    "    print(\"precision: \", (len(model_result_predict[i][0]) / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]))))\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy: \", ((len(model_result_predict[i][0]) + len(model_result_predict[i][2]))\n",
    "                               / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3]))))\n",
    "    print(\"\")\n",
    "\n",
    "    #     print(\"true-false를 통과한 개수 : \", 1000 - (len(first_false[i]) + len(second_true[i])) )\n",
    "#     print(\"precision: \", len(first_TP_TN[i][0])/(len(first_TP_TN[i][0]) + len(second_FP_FN[i][0])))\n",
    "#     print(\"accuracy: \", (len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]))\n",
    "#           /len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]) + len(second_FP_FN[0][i]) + len(second_FP_FN[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
