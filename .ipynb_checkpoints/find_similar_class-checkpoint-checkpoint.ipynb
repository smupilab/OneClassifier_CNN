{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEWkBMJpNvd_",
    "outputId": "e010c54f-38c1-4abd-c7e4-d29e7e531432"
   },
   "outputs": [],
   "source": [
    "# import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(original_x_train, original_y_train), (original_x_test, original_y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DG5AhMOLjbeb"
   },
   "outputs": [],
   "source": [
    "original_x_train = original_x_train / 255.0\n",
    "original_x_test = original_x_test / 255.0\n",
    "\n",
    "original_y_train = keras.utils.to_categorical(original_y_train)\n",
    "original_y_test = keras.utils.to_categorical(original_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJRl4tKVolc",
    "outputId": "6acbf001-2b2a-4654-f644-3bacf4a641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 10s 6ms/step - loss: 1.8170 - accuracy: 0.3202 - val_loss: 1.4741 - val_accuracy: 0.4634\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.4823 - accuracy: 0.4604 - val_loss: 1.2617 - val_accuracy: 0.5474\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.3459 - accuracy: 0.5178 - val_loss: 1.1456 - val_accuracy: 0.5916\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2580 - accuracy: 0.5550 - val_loss: 1.0938 - val_accuracy: 0.6122\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1942 - accuracy: 0.5782 - val_loss: 1.0260 - val_accuracy: 0.6375\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.1421 - accuracy: 0.6009 - val_loss: 0.9526 - val_accuracy: 0.6698\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.1098 - accuracy: 0.6124 - val_loss: 0.9743 - val_accuracy: 0.6572\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0718 - accuracy: 0.6255 - val_loss: 0.9276 - val_accuracy: 0.6799\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0470 - accuracy: 0.6375 - val_loss: 0.8904 - val_accuracy: 0.6848\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0221 - accuracy: 0.6462 - val_loss: 0.9367 - val_accuracy: 0.6672\n"
     ]
    }
   ],
   "source": [
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.Flatten())\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Dense(64, activation='relu'))\n",
    "original_model.add(layers.Dropout(0.5))\n",
    "original_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_0 = original_model.fit(original_x_train, original_y_train, epochs= 10, batch_size= 64, validation_data=(original_x_test, original_y_test))\n",
    "# loss: 0.9075 - accuracy: 0.6951 - val_loss: 0.8743 - val_accuracy: 0.7026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 17s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/59851961/how-to-calculate-confidence-score-of-a-neural-network-prediction\n",
    "model_predict = original_model.predict(original_x_test, batch_size = 1)\n",
    "# model_predict = np.where(model_predict > 0.5, 1, 0).squeeze().item()\n",
    "# np.where(model_predict > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvzfjR4SWu6i",
    "outputId": "a168ca0a-a8f4-4c05-8e59-18fa0d285a26",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[0, 18, 102, 12, 33, 1, 9, 10, 111, 23]\n",
      "[17, 0, 3, 6, 17, 1, 25, 2, 42, 42]\n",
      "[32, 5, 0, 56, 235, 33, 90, 14, 21, 4]\n",
      "[11, 7, 89, 0, 154, 80, 179, 12, 25, 11]\n",
      "[11, 1, 49, 28, 0, 4, 77, 34, 13, 2]\n",
      "[7, 2, 81, 297, 124, 0, 69, 31, 12, 3]\n",
      "[0, 1, 44, 31, 76, 2, 0, 4, 6, 0]\n",
      "[11, 5, 46, 55, 196, 36, 19, 0, 7, 11]\n",
      "[46, 20, 16, 12, 15, 1, 9, 3, 0, 16]\n",
      "[21, 106, 10, 19, 17, 3, 20, 8, 59, 0]\n"
     ]
    }
   ],
   "source": [
    "# 잘못예측한 데이터 찾는 코드\n",
    "# original_label, predict_label\n",
    "wrong_predict = []\n",
    "wrong_predict_cnt = 0\n",
    "class_length = 10\n",
    "\n",
    "model_predict = original_model.predict(original_x_test)\n",
    "\n",
    "for i in range(len(original_y_test)):\n",
    "    predict_idx, original_idx = 0, 0\n",
    "    for j in range(1,10):\n",
    "        if model_predict[i][j] > model_predict[i][predict_idx]:\n",
    "            predict_idx = j\n",
    "        if original_y_test[i][j] > original_y_test[i][original_idx]:\n",
    "            original_idx = j\n",
    "\n",
    "    if predict_idx != original_idx:\n",
    "        wrong_predict.append([original_idx, predict_idx])\n",
    "\n",
    "similar_wrong_predict_count = [[0 for j in range(class_length)] for i in range(class_length)]\n",
    "for i in range(len(wrong_predict)):\n",
    "    similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] = similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] + 1 \n",
    "\n",
    "for i in range(class_length):\n",
    "    print(similar_wrong_predict_count[i])\n",
    "\n",
    "# result\n",
    "# [0, 27, 28, 8, 5, 1, 7, 8, 59, 34]\n",
    "# [16, 0, 0, 6, 1, 3, 3, 1, 18, 51]\n",
    "# [101, 9, 0, 36, 93, 69, 60, 29, 18, 14]\n",
    "# [45, 22, 73, 0, 58, 196, 88, 38, 28, 30]\n",
    "# [40, 4, 71, 39, 0, 26, 66, 94, 11, 3]\n",
    "# [20, 7, 47, 146, 48, 0, 24, 65, 10, 11]\n",
    "# [12, 7, 48, 41, 33, 17, 0, 7, 13, 10]\n",
    "# [23, 2, 32, 23, 36, 50, 5, 0, 4, 15]\n",
    "# [78, 39, 4, 5, 3, 4, 4, 5, 0, 19]\n",
    "# [31, 128, 5, 6, 4, 3, 3, 10, 21, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PXIQquThxGkf"
   },
   "outputs": [],
   "source": [
    "# 가장 큰 값 top 3의 index를 가져와야 함 (cur_idx 제외)\n",
    "def getTopN(target_list, n, cur_idx):\n",
    "    tmp = target_list.copy()\n",
    "    visited = []\n",
    "    top_idx = []\n",
    "    for i in range(0,10):\n",
    "        if len(top_idx) == n:\n",
    "            break;\n",
    "        max_num = -1\n",
    "        max_idx = -1\n",
    "        for j in range(0,10):\n",
    "            if max_num < tmp[j]:\n",
    "                if j == cur_idx:\n",
    "                    continue\n",
    "                if j in visited:\n",
    "                    continue\n",
    "                else:  \n",
    "                    max_num = tmp[j]\n",
    "                    max_idx = j\n",
    "    \n",
    "        if max_idx != -1:\n",
    "            top_idx.append(max_idx)\n",
    "            visited.append(max_idx)\n",
    "    return top_idx\n",
    "\n",
    "# 가장 작은 값 bottom 3의 index를 가져와야 함  (cur_idx 제외)\n",
    "def getBottomN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  bottom_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(bottom_idx) == n:\n",
    "      break;\n",
    "    min_num = 1e9\n",
    "    min_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if tmp[j] < min_num:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                min_num = tmp[j]\n",
    "                min_idx = j\n",
    "    \n",
    "    if min_idx != -1:\n",
    "      bottom_idx.append(min_idx)\n",
    "      visited.append(min_idx)\n",
    "  return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xw4-dk8EBhqV"
   },
   "outputs": [],
   "source": [
    "# cifar10 데이터 가져오는 함수\n",
    "def getCifar10Data():\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train / 255.0\n",
    "  x_test = x_test / 255.0\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# a, b, c로 다시 라벨링\n",
    "def reLabel(y_train, y_test, a, b, c):\n",
    "  for i in range(len(y_train)):\n",
    "    if y_train[i] == a or y_train[i] == b or y_train[i] == c:\n",
    "      y_train[i] = 1\n",
    "    else:\n",
    "      y_train[i] = 0    \n",
    "  \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == a or y_test[i] == b or y_test[i] == c:\n",
    "      y_test[i] = 1\n",
    "    else:\n",
    "      y_test[i] = 0\n",
    "  \n",
    "  return y_train, y_test\n",
    "\n",
    "(model1_x_train, model1_y_train), (model1_x_test, model1_y_test) = getCifar10Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4bb4bjAnNxa3"
   },
   "outputs": [],
   "source": [
    "# model 만드는 함수 \n",
    "def makeModel():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Bxau2L_U9toH"
   },
   "outputs": [],
   "source": [
    "def get_TP_FP_TN_FN(y_test, predict, target_idx):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "                break\n",
    "        # True로 나왔을 때\n",
    "        if predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        # False로 나왔을 때\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "            \n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_model_TP_FP_TN_FN(first_predict, second_predict, third_predict, y_test, target_idx):\n",
    "    TP, FP, TN, FN = [],[],[],[]\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "        if first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 0 and third_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "    return TP, FP, TN, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MmmbZyZwFa-",
    "outputId": "6e61ca8b-9629-45f9-d032-a2e072f6c2ad",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 2, 0]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4599 - accuracy: 0.7975 - val_loss: 0.3793 - val_accuracy: 0.8411\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3887 - accuracy: 0.8362 - val_loss: 0.3564 - val_accuracy: 0.8494\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3621 - accuracy: 0.8476 - val_loss: 0.3373 - val_accuracy: 0.8598\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3472 - accuracy: 0.8565 - val_loss: 0.3174 - val_accuracy: 0.8699\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3316 - accuracy: 0.8620 - val_loss: 0.3123 - val_accuracy: 0.8686\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3200 - accuracy: 0.8671 - val_loss: 0.3248 - val_accuracy: 0.8646\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3104 - accuracy: 0.8710 - val_loss: 0.2929 - val_accuracy: 0.8757\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3007 - accuracy: 0.8755 - val_loss: 0.2878 - val_accuracy: 0.8786\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2916 - accuracy: 0.8810 - val_loss: 0.2808 - val_accuracy: 0.8828\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2870 - accuracy: 0.8810 - val_loss: 0.2800 - val_accuracy: 0.8856\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 6, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4866 - accuracy: 0.7376 - val_loss: 0.4190 - val_accuracy: 0.7874\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4278 - accuracy: 0.7864 - val_loss: 0.3880 - val_accuracy: 0.8092\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4051 - accuracy: 0.8013 - val_loss: 0.3831 - val_accuracy: 0.8130\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3866 - accuracy: 0.8135 - val_loss: 0.3712 - val_accuracy: 0.8247\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3736 - accuracy: 0.8210 - val_loss: 0.3656 - val_accuracy: 0.8245\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3618 - accuracy: 0.8265 - val_loss: 0.3489 - val_accuracy: 0.8353\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3529 - accuracy: 0.8319 - val_loss: 0.3382 - val_accuracy: 0.8409\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3467 - accuracy: 0.8378 - val_loss: 0.3354 - val_accuracy: 0.8452\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3379 - accuracy: 0.8414 - val_loss: 0.3350 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3318 - accuracy: 0.8468 - val_loss: 0.3426 - val_accuracy: 0.8338\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2586 - accuracy: 0.9053 - val_loss: 0.2055 - val_accuracy: 0.9181\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2142 - accuracy: 0.9189 - val_loss: 0.2183 - val_accuracy: 0.9060\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1901 - accuracy: 0.9291 - val_loss: 0.1671 - val_accuracy: 0.9346\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1760 - accuracy: 0.9335 - val_loss: 0.1605 - val_accuracy: 0.9378\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1650 - accuracy: 0.9382 - val_loss: 0.1701 - val_accuracy: 0.9342\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1582 - accuracy: 0.9411 - val_loss: 0.1415 - val_accuracy: 0.9477\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1508 - accuracy: 0.9428 - val_loss: 0.1343 - val_accuracy: 0.9493\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1445 - accuracy: 0.9444 - val_loss: 0.1398 - val_accuracy: 0.9454\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1386 - accuracy: 0.9464 - val_loss: 0.1286 - val_accuracy: 0.9543\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1324 - accuracy: 0.9491 - val_loss: 0.1337 - val_accuracy: 0.9490\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "1 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 9, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3545 - accuracy: 0.8410 - val_loss: 0.2811 - val_accuracy: 0.8812\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2679 - accuracy: 0.8887 - val_loss: 0.2403 - val_accuracy: 0.8985\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2412 - accuracy: 0.9027 - val_loss: 0.2075 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2185 - accuracy: 0.9124 - val_loss: 0.1886 - val_accuracy: 0.9224\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2044 - accuracy: 0.9188 - val_loss: 0.2084 - val_accuracy: 0.9186\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1934 - accuracy: 0.9234 - val_loss: 0.1718 - val_accuracy: 0.9338\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1845 - accuracy: 0.9280 - val_loss: 0.1625 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1773 - accuracy: 0.9309 - val_loss: 0.1580 - val_accuracy: 0.9406\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1722 - accuracy: 0.9334 - val_loss: 0.1773 - val_accuracy: 0.9337\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1657 - accuracy: 0.9361 - val_loss: 0.1497 - val_accuracy: 0.9424\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5046 - accuracy: 0.7458 - val_loss: 0.4433 - val_accuracy: 0.7746\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4418 - accuracy: 0.7843 - val_loss: 0.4044 - val_accuracy: 0.8071\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4131 - accuracy: 0.8017 - val_loss: 0.3806 - val_accuracy: 0.8136\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3959 - accuracy: 0.8124 - val_loss: 0.3632 - val_accuracy: 0.8276\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3846 - accuracy: 0.8185 - val_loss: 0.3521 - val_accuracy: 0.8335\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3757 - accuracy: 0.8249 - val_loss: 0.3555 - val_accuracy: 0.8353\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3630 - accuracy: 0.8285 - val_loss: 0.3460 - val_accuracy: 0.8376\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3544 - accuracy: 0.8355 - val_loss: 0.3435 - val_accuracy: 0.8415\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3477 - accuracy: 0.8406 - val_loss: 0.3270 - val_accuracy: 0.8509\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3422 - accuracy: 0.8432 - val_loss: 0.3461 - val_accuracy: 0.8419\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2242 - accuracy: 0.9161 - val_loss: 0.2191 - val_accuracy: 0.9181\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1636 - accuracy: 0.9379 - val_loss: 0.1338 - val_accuracy: 0.9476\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1454 - accuracy: 0.9456 - val_loss: 0.1297 - val_accuracy: 0.9521\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1282 - accuracy: 0.9528 - val_loss: 0.1181 - val_accuracy: 0.9566\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1189 - accuracy: 0.9564 - val_loss: 0.1018 - val_accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1118 - accuracy: 0.9591 - val_loss: 0.0933 - val_accuracy: 0.9674\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1026 - accuracy: 0.9617 - val_loss: 0.0916 - val_accuracy: 0.9666\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0977 - accuracy: 0.9644 - val_loss: 0.0894 - val_accuracy: 0.9681\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.0903 - val_accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0898 - accuracy: 0.9678 - val_loss: 0.0834 - val_accuracy: 0.9715\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "2 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 6, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4693 - accuracy: 0.7794 - val_loss: 0.4242 - val_accuracy: 0.8180\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4069 - accuracy: 0.8134 - val_loss: 0.4188 - val_accuracy: 0.8087\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3837 - accuracy: 0.8246 - val_loss: 0.3685 - val_accuracy: 0.8356\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3619 - accuracy: 0.8373 - val_loss: 0.4162 - val_accuracy: 0.8012\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3467 - accuracy: 0.8456 - val_loss: 0.3756 - val_accuracy: 0.8343\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3368 - accuracy: 0.8498 - val_loss: 0.3500 - val_accuracy: 0.8389\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3238 - accuracy: 0.8576 - val_loss: 0.3145 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3171 - accuracy: 0.8618 - val_loss: 0.3004 - val_accuracy: 0.8669\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3100 - accuracy: 0.8638 - val_loss: 0.3240 - val_accuracy: 0.8621\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3019 - accuracy: 0.8671 - val_loss: 0.3586 - val_accuracy: 0.8365\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4589 - accuracy: 0.7907 - val_loss: 0.3498 - val_accuracy: 0.8473\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3487 - accuracy: 0.8539 - val_loss: 0.3096 - val_accuracy: 0.8686\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3139 - accuracy: 0.8700 - val_loss: 0.2927 - val_accuracy: 0.8781\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2904 - accuracy: 0.8815 - val_loss: 0.2584 - val_accuracy: 0.8909\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2738 - accuracy: 0.8887 - val_loss: 0.2522 - val_accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2657 - accuracy: 0.8947 - val_loss: 0.2422 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2516 - accuracy: 0.8990 - val_loss: 0.2347 - val_accuracy: 0.9056\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2457 - accuracy: 0.9020 - val_loss: 0.2220 - val_accuracy: 0.9109\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2386 - accuracy: 0.9052 - val_loss: 0.2277 - val_accuracy: 0.9081\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2351 - accuracy: 0.9062 - val_loss: 0.2191 - val_accuracy: 0.9119\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3110 - accuracy: 0.8995 - val_loss: 0.2799 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2805 - accuracy: 0.9000 - val_loss: 0.2546 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2596 - accuracy: 0.9029 - val_loss: 0.2424 - val_accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2433 - accuracy: 0.9082 - val_loss: 0.2398 - val_accuracy: 0.9119\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2327 - accuracy: 0.9126 - val_loss: 0.2195 - val_accuracy: 0.9173\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2257 - accuracy: 0.9155 - val_loss: 0.2112 - val_accuracy: 0.9173\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2210 - accuracy: 0.9170 - val_loss: 0.2079 - val_accuracy: 0.9223\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2151 - accuracy: 0.9200 - val_loss: 0.2032 - val_accuracy: 0.9218\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2116 - accuracy: 0.9203 - val_loss: 0.1983 - val_accuracy: 0.9259\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2066 - accuracy: 0.9223 - val_loss: 0.1994 - val_accuracy: 0.9247\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "3 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[6, 4, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4761 - accuracy: 0.7644 - val_loss: 0.4363 - val_accuracy: 0.7970\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4322 - accuracy: 0.7942 - val_loss: 0.4746 - val_accuracy: 0.7728\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4087 - accuracy: 0.8054 - val_loss: 0.3740 - val_accuracy: 0.8250\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3932 - accuracy: 0.8158 - val_loss: 0.3660 - val_accuracy: 0.8297\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3808 - accuracy: 0.8211 - val_loss: 0.4135 - val_accuracy: 0.7997\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3719 - accuracy: 0.8279 - val_loss: 0.3830 - val_accuracy: 0.8267\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3615 - accuracy: 0.8315 - val_loss: 0.3593 - val_accuracy: 0.8336\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3519 - accuracy: 0.8359 - val_loss: 0.3502 - val_accuracy: 0.8377\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3469 - accuracy: 0.8417 - val_loss: 0.3554 - val_accuracy: 0.8357\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3421 - accuracy: 0.8420 - val_loss: 0.3767 - val_accuracy: 0.8266\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 0, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3997 - accuracy: 0.8077 - val_loss: 0.3216 - val_accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3220 - accuracy: 0.8552 - val_loss: 0.3885 - val_accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2862 - accuracy: 0.8785 - val_loss: 0.2622 - val_accuracy: 0.8882\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2684 - accuracy: 0.8899 - val_loss: 0.2380 - val_accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2519 - accuracy: 0.8966 - val_loss: 0.2154 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2383 - accuracy: 0.9019 - val_loss: 0.2092 - val_accuracy: 0.9153\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2259 - accuracy: 0.9082 - val_loss: 0.2456 - val_accuracy: 0.8982\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2186 - accuracy: 0.9114 - val_loss: 0.1981 - val_accuracy: 0.9221\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2070 - accuracy: 0.9161 - val_loss: 0.2646 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2040 - accuracy: 0.9180 - val_loss: 0.2487 - val_accuracy: 0.8950\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2984 - accuracy: 0.8996 - val_loss: 0.2734 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2683 - accuracy: 0.8999 - val_loss: 0.2567 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2571 - accuracy: 0.9000 - val_loss: 0.2548 - val_accuracy: 0.9006\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2501 - accuracy: 0.9006 - val_loss: 0.2447 - val_accuracy: 0.9033\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2438 - accuracy: 0.9024 - val_loss: 0.2386 - val_accuracy: 0.9049\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2382 - accuracy: 0.9028 - val_loss: 0.2325 - val_accuracy: 0.9051\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2353 - accuracy: 0.9044 - val_loss: 0.2428 - val_accuracy: 0.9083\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2305 - accuracy: 0.9065 - val_loss: 0.2350 - val_accuracy: 0.9050\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2251 - accuracy: 0.9086 - val_loss: 0.2357 - val_accuracy: 0.9094\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2234 - accuracy: 0.9096 - val_loss: 0.2219 - val_accuracy: 0.9129\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "4 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[6, 2, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 6ms/step - loss: 0.4702 - accuracy: 0.7792 - val_loss: 0.4117 - val_accuracy: 0.8111\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4116 - accuracy: 0.8107 - val_loss: 0.3695 - val_accuracy: 0.8310\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3844 - accuracy: 0.8262 - val_loss: 0.3637 - val_accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3643 - accuracy: 0.8364 - val_loss: 0.3361 - val_accuracy: 0.8526\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3527 - accuracy: 0.8441 - val_loss: 0.3262 - val_accuracy: 0.8549\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3379 - accuracy: 0.8489 - val_loss: 0.3307 - val_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3286 - accuracy: 0.8551 - val_loss: 0.3115 - val_accuracy: 0.8662\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3230 - accuracy: 0.8579 - val_loss: 0.3047 - val_accuracy: 0.8702\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3140 - accuracy: 0.8638 - val_loss: 0.3334 - val_accuracy: 0.8557\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3053 - accuracy: 0.8657 - val_loss: 0.3302 - val_accuracy: 0.8578\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4869 - accuracy: 0.7756 - val_loss: 0.4320 - val_accuracy: 0.8089\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4052 - accuracy: 0.8239 - val_loss: 0.4035 - val_accuracy: 0.8253\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3725 - accuracy: 0.8425 - val_loss: 0.3334 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3467 - accuracy: 0.8545 - val_loss: 0.3288 - val_accuracy: 0.8608\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3286 - accuracy: 0.8624 - val_loss: 0.3329 - val_accuracy: 0.8641\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3140 - accuracy: 0.8682 - val_loss: 0.2959 - val_accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3063 - accuracy: 0.8730 - val_loss: 0.2782 - val_accuracy: 0.8871\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2958 - accuracy: 0.8776 - val_loss: 0.2779 - val_accuracy: 0.8820\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2870 - accuracy: 0.8807 - val_loss: 0.2818 - val_accuracy: 0.8821\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2774 - accuracy: 0.8841 - val_loss: 0.2719 - val_accuracy: 0.8852\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2917 - accuracy: 0.8998 - val_loss: 0.2724 - val_accuracy: 0.8999\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2597 - accuracy: 0.9024 - val_loss: 0.2626 - val_accuracy: 0.9064\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2435 - accuracy: 0.9076 - val_loss: 0.2251 - val_accuracy: 0.9147\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2294 - accuracy: 0.9114 - val_loss: 0.2378 - val_accuracy: 0.9140\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2191 - accuracy: 0.9141 - val_loss: 0.2118 - val_accuracy: 0.9155\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2072 - accuracy: 0.9189 - val_loss: 0.1929 - val_accuracy: 0.9228\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2020 - accuracy: 0.9206 - val_loss: 0.1884 - val_accuracy: 0.9307\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1928 - accuracy: 0.9239 - val_loss: 0.1999 - val_accuracy: 0.9204\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1882 - accuracy: 0.9252 - val_loss: 0.1831 - val_accuracy: 0.9296\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1826 - accuracy: 0.9286 - val_loss: 0.1698 - val_accuracy: 0.9317\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "5 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 4, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4837 - accuracy: 0.7536 - val_loss: 0.4196 - val_accuracy: 0.7938\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4328 - accuracy: 0.7863 - val_loss: 0.4011 - val_accuracy: 0.8077\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4088 - accuracy: 0.7987 - val_loss: 0.3838 - val_accuracy: 0.8163\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3929 - accuracy: 0.8086 - val_loss: 0.3814 - val_accuracy: 0.8195\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3808 - accuracy: 0.8180 - val_loss: 0.3659 - val_accuracy: 0.8288\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3718 - accuracy: 0.8258 - val_loss: 0.3588 - val_accuracy: 0.8356\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3592 - accuracy: 0.8313 - val_loss: 0.3327 - val_accuracy: 0.8480\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3498 - accuracy: 0.8379 - val_loss: 0.3343 - val_accuracy: 0.8489\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3434 - accuracy: 0.8423 - val_loss: 0.3253 - val_accuracy: 0.8501\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3336 - accuracy: 0.8479 - val_loss: 0.3193 - val_accuracy: 0.8569\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 0]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4115 - accuracy: 0.8016 - val_loss: 0.3180 - val_accuracy: 0.8504\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3242 - accuracy: 0.8546 - val_loss: 0.2722 - val_accuracy: 0.8819\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2905 - accuracy: 0.8757 - val_loss: 0.2632 - val_accuracy: 0.8810\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2705 - accuracy: 0.8875 - val_loss: 0.2446 - val_accuracy: 0.8953\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2555 - accuracy: 0.8939 - val_loss: 0.2129 - val_accuracy: 0.9120\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2408 - accuracy: 0.9026 - val_loss: 0.2246 - val_accuracy: 0.9094\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2307 - accuracy: 0.9055 - val_loss: 0.2170 - val_accuracy: 0.9124\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2232 - accuracy: 0.9085 - val_loss: 0.2155 - val_accuracy: 0.9095\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2161 - accuracy: 0.9130 - val_loss: 0.2050 - val_accuracy: 0.9165\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2102 - accuracy: 0.9136 - val_loss: 0.1908 - val_accuracy: 0.9222\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2727 - accuracy: 0.9008 - val_loss: 0.2411 - val_accuracy: 0.9112\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2378 - accuracy: 0.9097 - val_loss: 0.2219 - val_accuracy: 0.9162\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2232 - accuracy: 0.9144 - val_loss: 0.2041 - val_accuracy: 0.9226\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2134 - accuracy: 0.9185 - val_loss: 0.1918 - val_accuracy: 0.9247\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2059 - accuracy: 0.9206 - val_loss: 0.1881 - val_accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1998 - accuracy: 0.9233 - val_loss: 0.1835 - val_accuracy: 0.9304\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1918 - accuracy: 0.9259 - val_loss: 0.1818 - val_accuracy: 0.9303\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1857 - accuracy: 0.9288 - val_loss: 0.1906 - val_accuracy: 0.9295\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1812 - accuracy: 0.9309 - val_loss: 0.1763 - val_accuracy: 0.9329\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1771 - accuracy: 0.9309 - val_loss: 0.1789 - val_accuracy: 0.9313\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "6 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 2, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4668 - accuracy: 0.7816 - val_loss: 0.4123 - val_accuracy: 0.8093\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4071 - accuracy: 0.8128 - val_loss: 0.3875 - val_accuracy: 0.8319\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3798 - accuracy: 0.8272 - val_loss: 0.3462 - val_accuracy: 0.8469\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3578 - accuracy: 0.8407 - val_loss: 0.3461 - val_accuracy: 0.8456\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3465 - accuracy: 0.8461 - val_loss: 0.3484 - val_accuracy: 0.8429\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3334 - accuracy: 0.8524 - val_loss: 0.3235 - val_accuracy: 0.8597\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3258 - accuracy: 0.8572 - val_loss: 0.3185 - val_accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3163 - accuracy: 0.8618 - val_loss: 0.3140 - val_accuracy: 0.8657\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3104 - accuracy: 0.8648 - val_loss: 0.3251 - val_accuracy: 0.8562\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3023 - accuracy: 0.8681 - val_loss: 0.3019 - val_accuracy: 0.8662\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[0, 9, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4084 - accuracy: 0.8033 - val_loss: 0.3123 - val_accuracy: 0.8555\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3234 - accuracy: 0.8550 - val_loss: 0.2992 - val_accuracy: 0.8739\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2938 - accuracy: 0.8747 - val_loss: 0.2698 - val_accuracy: 0.8898\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2725 - accuracy: 0.8853 - val_loss: 0.2342 - val_accuracy: 0.9038\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2572 - accuracy: 0.8924 - val_loss: 0.2225 - val_accuracy: 0.9117\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2435 - accuracy: 0.9003 - val_loss: 0.2251 - val_accuracy: 0.9050\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2311 - accuracy: 0.9059 - val_loss: 0.2182 - val_accuracy: 0.9128\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2195 - accuracy: 0.9120 - val_loss: 0.2281 - val_accuracy: 0.9069\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2137 - accuracy: 0.9124 - val_loss: 0.1944 - val_accuracy: 0.9231\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2040 - accuracy: 0.9186 - val_loss: 0.2042 - val_accuracy: 0.9194\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2476 - accuracy: 0.9039 - val_loss: 0.1885 - val_accuracy: 0.9235\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1939 - accuracy: 0.9263 - val_loss: 0.1643 - val_accuracy: 0.9368\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1674 - accuracy: 0.9370 - val_loss: 0.1379 - val_accuracy: 0.9465\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1599 - accuracy: 0.9403 - val_loss: 0.1514 - val_accuracy: 0.9443\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1480 - accuracy: 0.9438 - val_loss: 0.1902 - val_accuracy: 0.9229\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1452 - accuracy: 0.9451 - val_loss: 0.1276 - val_accuracy: 0.9517\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1377 - accuracy: 0.9484 - val_loss: 0.1342 - val_accuracy: 0.9511\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1344 - accuracy: 0.9492 - val_loss: 0.1812 - val_accuracy: 0.9279\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1281 - accuracy: 0.9517 - val_loss: 0.1254 - val_accuracy: 0.9555\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1261 - accuracy: 0.9528 - val_loss: 0.1226 - val_accuracy: 0.9522\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "7 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 3, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5036 - accuracy: 0.7344 - val_loss: 0.4638 - val_accuracy: 0.7597\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4424 - accuracy: 0.7754 - val_loss: 0.4055 - val_accuracy: 0.8038\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4166 - accuracy: 0.7963 - val_loss: 0.3989 - val_accuracy: 0.8157\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3997 - accuracy: 0.8056 - val_loss: 0.3706 - val_accuracy: 0.8242\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3844 - accuracy: 0.8163 - val_loss: 0.3699 - val_accuracy: 0.8262\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3691 - accuracy: 0.8251 - val_loss: 0.3436 - val_accuracy: 0.8377\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3624 - accuracy: 0.8273 - val_loss: 0.3472 - val_accuracy: 0.8345\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3517 - accuracy: 0.8343 - val_loss: 0.3407 - val_accuracy: 0.8446\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3474 - accuracy: 0.8371 - val_loss: 0.3334 - val_accuracy: 0.8451\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3369 - accuracy: 0.8445 - val_loss: 0.3183 - val_accuracy: 0.8529\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 8, 0]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3588 - accuracy: 0.8422 - val_loss: 0.3048 - val_accuracy: 0.8690\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3001 - accuracy: 0.8721 - val_loss: 0.2692 - val_accuracy: 0.8880\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2781 - accuracy: 0.8835 - val_loss: 0.2535 - val_accuracy: 0.8964\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2617 - accuracy: 0.8903 - val_loss: 0.2466 - val_accuracy: 0.9013\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2482 - accuracy: 0.8980 - val_loss: 0.2464 - val_accuracy: 0.8938\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2379 - accuracy: 0.9030 - val_loss: 0.2248 - val_accuracy: 0.9094\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2299 - accuracy: 0.9088 - val_loss: 0.2394 - val_accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2191 - accuracy: 0.9120 - val_loss: 0.2217 - val_accuracy: 0.9104\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2175 - accuracy: 0.9143 - val_loss: 0.2008 - val_accuracy: 0.9189\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2077 - accuracy: 0.9166 - val_loss: 0.2138 - val_accuracy: 0.9170\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2641 - accuracy: 0.9090 - val_loss: 0.1935 - val_accuracy: 0.9308\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1987 - accuracy: 0.9301 - val_loss: 0.1768 - val_accuracy: 0.9357\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1766 - accuracy: 0.9378 - val_loss: 0.1629 - val_accuracy: 0.9406\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1662 - accuracy: 0.9408 - val_loss: 0.1488 - val_accuracy: 0.9445\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1547 - accuracy: 0.9445 - val_loss: 0.1569 - val_accuracy: 0.9433\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1464 - accuracy: 0.9477 - val_loss: 0.1395 - val_accuracy: 0.9473\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1405 - accuracy: 0.9498 - val_loss: 0.1329 - val_accuracy: 0.9503\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1340 - accuracy: 0.9519 - val_loss: 0.1315 - val_accuracy: 0.9521\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1301 - accuracy: 0.9543 - val_loss: 0.1244 - val_accuracy: 0.9553\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1283 - accuracy: 0.9540 - val_loss: 0.1357 - val_accuracy: 0.9493\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "8 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[0, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3698 - accuracy: 0.8366 - val_loss: 0.2927 - val_accuracy: 0.8711\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2981 - accuracy: 0.8746 - val_loss: 0.2548 - val_accuracy: 0.8905\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2714 - accuracy: 0.8867 - val_loss: 0.2497 - val_accuracy: 0.8956\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2590 - accuracy: 0.8943 - val_loss: 0.2267 - val_accuracy: 0.9079\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2451 - accuracy: 0.8996 - val_loss: 0.2243 - val_accuracy: 0.9082\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2347 - accuracy: 0.9044 - val_loss: 0.2407 - val_accuracy: 0.9011\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2292 - accuracy: 0.9074 - val_loss: 0.2045 - val_accuracy: 0.9173\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2156 - accuracy: 0.9143 - val_loss: 0.2020 - val_accuracy: 0.9189\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2100 - accuracy: 0.9159 - val_loss: 0.2052 - val_accuracy: 0.9171\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2052 - accuracy: 0.9176 - val_loss: 0.1993 - val_accuracy: 0.9203\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4900 - accuracy: 0.7421 - val_loss: 0.4635 - val_accuracy: 0.7493\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4272 - accuracy: 0.7851 - val_loss: 0.4273 - val_accuracy: 0.7800\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4138 - accuracy: 0.7966 - val_loss: 0.3855 - val_accuracy: 0.8132\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3934 - accuracy: 0.8119 - val_loss: 0.3673 - val_accuracy: 0.8255\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3778 - accuracy: 0.8212 - val_loss: 0.3600 - val_accuracy: 0.8277\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3666 - accuracy: 0.8257 - val_loss: 0.3435 - val_accuracy: 0.8391\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3585 - accuracy: 0.8325 - val_loss: 0.3411 - val_accuracy: 0.8416\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3457 - accuracy: 0.8391 - val_loss: 0.3272 - val_accuracy: 0.8493\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3392 - accuracy: 0.8408 - val_loss: 0.3315 - val_accuracy: 0.8493\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3337 - accuracy: 0.8457 - val_loss: 0.3184 - val_accuracy: 0.8527\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2297 - accuracy: 0.9114 - val_loss: 0.1916 - val_accuracy: 0.9255\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1700 - accuracy: 0.9361 - val_loss: 0.1607 - val_accuracy: 0.9465\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1470 - accuracy: 0.9440 - val_loss: 0.1635 - val_accuracy: 0.9393\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1363 - accuracy: 0.9497 - val_loss: 0.1237 - val_accuracy: 0.9531\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1284 - accuracy: 0.9524 - val_loss: 0.1277 - val_accuracy: 0.9532\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1240 - accuracy: 0.9536 - val_loss: 0.1107 - val_accuracy: 0.9605\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1149 - accuracy: 0.9567 - val_loss: 0.1101 - val_accuracy: 0.9576\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1100 - accuracy: 0.9586 - val_loss: 0.1054 - val_accuracy: 0.9596\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1057 - accuracy: 0.9601 - val_loss: 0.1047 - val_accuracy: 0.9638\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1011 - accuracy: 0.9625 - val_loss: 0.1028 - val_accuracy: 0.9624\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "9 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[1, 8, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3525 - accuracy: 0.8429 - val_loss: 0.2544 - val_accuracy: 0.8944\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2667 - accuracy: 0.8889 - val_loss: 0.2194 - val_accuracy: 0.9102\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2414 - accuracy: 0.9015 - val_loss: 0.1941 - val_accuracy: 0.9198\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2200 - accuracy: 0.9111 - val_loss: 0.1889 - val_accuracy: 0.9231\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2027 - accuracy: 0.9200 - val_loss: 0.2017 - val_accuracy: 0.9191\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1929 - accuracy: 0.9239 - val_loss: 0.1710 - val_accuracy: 0.9326\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1822 - accuracy: 0.9291 - val_loss: 0.1536 - val_accuracy: 0.9395\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1704 - accuracy: 0.9338 - val_loss: 0.1578 - val_accuracy: 0.9372\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1635 - accuracy: 0.9367 - val_loss: 0.1443 - val_accuracy: 0.9444\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1573 - accuracy: 0.9386 - val_loss: 0.1456 - val_accuracy: 0.9423\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 6ms/step - loss: 0.5010 - accuracy: 0.7467 - val_loss: 0.4150 - val_accuracy: 0.7954\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.4191 - val_accuracy: 0.8107\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4080 - accuracy: 0.8053 - val_loss: 0.3705 - val_accuracy: 0.8254\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3913 - accuracy: 0.8161 - val_loss: 0.3680 - val_accuracy: 0.8318\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3820 - accuracy: 0.8209 - val_loss: 0.3773 - val_accuracy: 0.8142\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3673 - accuracy: 0.8280 - val_loss: 0.3454 - val_accuracy: 0.8379\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3600 - accuracy: 0.8323 - val_loss: 0.3406 - val_accuracy: 0.8382\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3530 - accuracy: 0.8366 - val_loss: 0.3269 - val_accuracy: 0.8468\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3461 - accuracy: 0.8383 - val_loss: 0.3209 - val_accuracy: 0.8508\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3388 - accuracy: 0.8451 - val_loss: 0.3218 - val_accuracy: 0.8553\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2546 - accuracy: 0.9034 - val_loss: 0.1926 - val_accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1964 - accuracy: 0.9241 - val_loss: 0.1635 - val_accuracy: 0.9341\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1667 - accuracy: 0.9358 - val_loss: 0.1484 - val_accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1539 - accuracy: 0.9431 - val_loss: 0.1442 - val_accuracy: 0.9461\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1453 - accuracy: 0.9453 - val_loss: 0.1286 - val_accuracy: 0.9550\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1335 - accuracy: 0.9509 - val_loss: 0.1155 - val_accuracy: 0.9560\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1282 - accuracy: 0.9526 - val_loss: 0.1123 - val_accuracy: 0.9573\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1206 - accuracy: 0.9567 - val_loss: 0.1089 - val_accuracy: 0.9598\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1171 - accuracy: 0.9569 - val_loss: 0.1010 - val_accuracy: 0.9622\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1147 - accuracy: 0.9582 - val_loss: 0.1000 - val_accuracy: 0.9621\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "class_accuracy = []\n",
    "first_predict_list = []\n",
    "first_TP_FP_TN_FN = []\n",
    "second_predict_list = []\n",
    "second_TP_FP_TN_FN = []\n",
    "third_predict_list = []\n",
    "third_TP_FP_TN_FN = []\n",
    "model_result_predict = []\n",
    "\n",
    "for i in range(0, class_length):\n",
    "    print(i, \"번째 클래스\")\n",
    "    \n",
    "    # model 1 -> 가장 유사한 클래스끼리 묶은 라벨\n",
    "    print(\"[model1] : 가장 유사한 클래스끼리 묶은 라벨\")\n",
    "    (x_train, y_train), (x_test, y_test) = getCifar10Data()\n",
    "    temp = getTopN(similar_wrong_predict_count[i], 2, i)\n",
    "    # 현재 클래스 index 추가 \n",
    "    temp.append(i)\n",
    "    print(temp)\n",
    "    (y_train, y_test) = reLabel(y_train, y_test, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model1 = makeModel()\n",
    "    model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model1.fit(x_train, y_train, epochs= 10, batch_size = 64, validation_data=(x_test, y_test))\n",
    "    \n",
    "    first_predict = model1.predict(x_test)\n",
    "    first_predict_list.append(first_predict)\n",
    "    first_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, first_predict, i))\n",
    "    \n",
    "    # model 2 -> 가장 유사하지않은 클래스끼리 묶은 라벨\n",
    "    print(\"[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\")\n",
    "    (x_train2, y_train2), (x_test2, y_test2) = getCifar10Data()\n",
    "    temp = getBottomN(similar_wrong_predict_count[i], 3, i)\n",
    "    print(temp)\n",
    "\n",
    "    (y_train2, y_test2) = reLabel(y_train2, y_test2, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model2 = makeModel()\n",
    "    model2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model2.fit(x_train2, y_train2, epochs= 10, batch_size = 64, validation_data=(x_test2, y_test2))\n",
    "    \n",
    "    second_predict = model2.predict(x_test2)\n",
    "    second_predict_list.append(second_predict)\n",
    "    second_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, second_predict, i))\n",
    "    \n",
    "    # model 3 -> 클래스 하나만 True로 라벨링한 모델\n",
    "    (x_train3, y_train3), (x_test3, y_test3) = getCifar10Data()\n",
    "    (y_train3, y_test3) = reLabel(y_train3, y_test3, i, i, i)\n",
    "    \n",
    "    model3 = makeModel()\n",
    "    model3.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model3.fit(x_train3, y_train3, epochs= 10, batch_size = 64, validation_data=(x_test3, y_test3))\n",
    "    third_predict = model3.predict(x_test3)\n",
    "    third_predict_list.append(third_predict)\n",
    "    \n",
    "#     # model 3 ->  0~9 multi class claasifacation 모델\n",
    "#     (x_train3, y_train3), (x_test3, y_test3) = getCifar10Data()\n",
    "    \n",
    "#     model3 = makeModel()\n",
    "#     model3.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "#     model3.fit(x_train3, y_train3, epochs= 10, batch_size = 64, validation_data=(x_test3, y_test3))\n",
    "\n",
    "#     third_predict = model3.predict(x_test3)\n",
    "#     third_predict_list.append(third_predict)\n",
    "    \n",
    "    third_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, third_predict, i))\n",
    "\n",
    "    # 모델의 TP FP TN FN\n",
    "    model_result_predict.append(get_result_model_TP_FP_TN_FN(first_predict, second_predict, third_predict, original_y_test, i))\n",
    "\n",
    "    # 첫번째 모델에서 True 두번째 모델에서 False가 나온 모델\n",
    "#     class_accuracy.append(getRealTrueRatio(first_predict, second_predict, original_y_test,i))  \n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000, 2)\n",
      "0 번째 클래스\n",
      "model 1\n",
      "0.6976188\n",
      "0.3023812\n",
      "model 2\n",
      "0.6412067\n",
      "0.35879332\n",
      "model 3\n",
      "0.9134618\n",
      "0.08653823\n",
      "=====================\n",
      "1 번째 클래스\n",
      "model 1\n",
      "0.69939846\n",
      "0.30060157\n",
      "model 2\n",
      "0.6961147\n",
      "0.30388525\n",
      "model 3\n",
      "0.90700877\n",
      "0.09299127\n",
      "=====================\n",
      "2 번째 클래스\n",
      "model 1\n",
      "0.6630336\n",
      "0.33696648\n",
      "model 2\n",
      "0.69965744\n",
      "0.30034256\n",
      "model 3\n",
      "0.9037743\n",
      "0.096225634\n",
      "=====================\n",
      "3 번째 클래스\n",
      "model 1\n",
      "0.64635473\n",
      "0.3536453\n",
      "model 2\n",
      "0.71786654\n",
      "0.2821334\n",
      "model 3\n",
      "0.902222\n",
      "0.09777804\n",
      "=====================\n",
      "4 번째 클래스\n",
      "model 1\n",
      "0.64217454\n",
      "0.35782555\n",
      "model 2\n",
      "0.72342116\n",
      "0.2765788\n",
      "model 3\n",
      "0.9016916\n",
      "0.09830833\n",
      "=====================\n",
      "5 번째 클래스\n",
      "model 1\n",
      "0.64957917\n",
      "0.35042092\n",
      "model 2\n",
      "0.72050476\n",
      "0.27949524\n",
      "model 3\n",
      "0.903944\n",
      "0.096056\n",
      "=====================\n",
      "6 번째 클래스\n",
      "model 1\n",
      "0.650668\n",
      "0.34933203\n",
      "model 2\n",
      "0.72027344\n",
      "0.27972654\n",
      "model 3\n",
      "0.90006846\n",
      "0.099931516\n",
      "=====================\n",
      "7 번째 클래스\n",
      "model 1\n",
      "0.65522724\n",
      "0.34477282\n",
      "model 2\n",
      "0.7151045\n",
      "0.2848955\n",
      "model 3\n",
      "0.90230477\n",
      "0.0976952\n",
      "=====================\n",
      "8 번째 클래스\n",
      "model 1\n",
      "0.6624852\n",
      "0.3375149\n",
      "model 2\n",
      "0.7121996\n",
      "0.2878003\n",
      "model 3\n",
      "0.90063244\n",
      "0.09936756\n",
      "=====================\n",
      "9 번째 클래스\n",
      "model 1\n",
      "0.6634658\n",
      "0.33653426\n",
      "model 2\n",
      "0.7112275\n",
      "0.2887725\n",
      "model 3\n",
      "0.8999833\n",
      "0.10001679\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(third_predict_list))\n",
    "first_true_list = []\n",
    "first_false_list = []\n",
    "second_true_list = []\n",
    "second_false_list = []\n",
    "third_true_list = []\n",
    "third_false_list = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(i, \"번째 클래스\")\n",
    "    for j in range(0,10000):        \n",
    "        for k in range(0,2):\n",
    "            if k == 0:\n",
    "                first_true_list.append(first_predict_list[i][j][k])\n",
    "                second_true_list.append(second_predict_list[i][j][k])\n",
    "                third_true_list.append(third_predict_list[i][j][k])\n",
    "            else:\n",
    "                first_false_list.append(first_predict_list[i][j][k])\n",
    "                second_false_list.append(second_predict_list[i][j][k])\n",
    "                third_false_list.append(third_predict_list[i][j][k])\n",
    "    print(\"model 1\")\n",
    "    print(np.mean(first_true_list))\n",
    "    print(np.mean(first_false_list))\n",
    "    print(\"model 2\")\n",
    "    print(np.mean(second_true_list))\n",
    "    print(np.mean(second_false_list))\n",
    "    print(\"model 3\")\n",
    "    print(np.mean(third_true_list))\n",
    "    print(np.mean(third_false_list))\n",
    "    print(\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 :  0\n",
      "첫번째 모델에서 TP:  861\n",
      "첫번째 모델에서 FP:  1771\n",
      "첫번째 모델에서 TN:  7229\n",
      "첫번째 모델에서 FN:  139\n",
      "두번째 모델에서 TP:  34\n",
      "두번째 모델에서 FP:  3522\n",
      "두번째 모델에서 TN:  5478\n",
      "두번째 모델에서 FN:  966\n",
      "세번째 모델에서 TP:  559\n",
      "세번째 모델에서 FP:  69\n",
      "세번째 모델에서 TN:  8931\n",
      "세번째 모델에서 FN:  441\n",
      "모델 결과 TP:  530\n",
      "모델 결과 FP:  57\n",
      "모델 결과 TN:  8943\n",
      "모델 결과 FN:  470\n",
      "precision:  0.9028960817717206\n",
      "accuracy:  0.9473\n",
      "\n",
      "클래스 :  1\n",
      "첫번째 모델에서 TP:  928\n",
      "첫번째 모델에서 FP:  1994\n",
      "첫번째 모델에서 TN:  7006\n",
      "첫번째 모델에서 FN:  72\n",
      "두번째 모델에서 TP:  7\n",
      "두번째 모델에서 FP:  2168\n",
      "두번째 모델에서 TN:  6832\n",
      "두번째 모델에서 FN:  993\n",
      "세번째 모델에서 TP:  820\n",
      "세번째 모델에서 FP:  105\n",
      "세번째 모델에서 TN:  8895\n",
      "세번째 모델에서 FN:  180\n",
      "모델 결과 TP:  789\n",
      "모델 결과 FP:  92\n",
      "모델 결과 TN:  8908\n",
      "모델 결과 FN:  211\n",
      "precision:  0.8955732122587968\n",
      "accuracy:  0.9697\n",
      "\n",
      "클래스 :  2\n",
      "첫번째 모델에서 TP:  808\n",
      "첫번째 모델에서 FP:  3101\n",
      "첫번째 모델에서 TN:  5899\n",
      "첫번째 모델에서 FN:  192\n",
      "두번째 모델에서 TP:  29\n",
      "두번째 모델에서 FP:  2692\n",
      "두번째 모델에서 TN:  6308\n",
      "두번째 모델에서 FN:  971\n",
      "세번째 모델에서 TP:  350\n",
      "세번째 모델에서 FP:  103\n",
      "세번째 모델에서 TN:  8897\n",
      "세번째 모델에서 FN:  650\n",
      "모델 결과 TP:  330\n",
      "모델 결과 FP:  87\n",
      "모델 결과 TN:  8913\n",
      "모델 결과 FN:  670\n",
      "precision:  0.7913669064748201\n",
      "accuracy:  0.9243\n",
      "\n",
      "클래스 :  3\n",
      "첫번째 모델에서 TP:  741\n",
      "첫번째 모델에서 FP:  3123\n",
      "첫번째 모델에서 TN:  5877\n",
      "첫번째 모델에서 FN:  259\n",
      "두번째 모델에서 TP:  10\n",
      "두번째 모델에서 FP:  2126\n",
      "두번째 모델에서 TN:  6874\n",
      "두번째 모델에서 FN:  990\n",
      "세번째 모델에서 TP:  231\n",
      "세번째 모델에서 FP:  102\n",
      "세번째 모델에서 TN:  8898\n",
      "세번째 모델에서 FN:  769\n",
      "모델 결과 TP:  217\n",
      "모델 결과 FP:  82\n",
      "모델 결과 TN:  8918\n",
      "모델 결과 FN:  783\n",
      "precision:  0.725752508361204\n",
      "accuracy:  0.9135\n",
      "\n",
      "클래스 :  4\n",
      "첫번째 모델에서 TP:  823\n",
      "첫번째 모델에서 FP:  2671\n",
      "첫번째 모델에서 TN:  6329\n",
      "첫번째 모델에서 FN:  177\n",
      "두번째 모델에서 TP:  4\n",
      "두번째 모델에서 FP:  2160\n",
      "두번째 모델에서 TN:  6840\n",
      "두번째 모델에서 FN:  996\n",
      "세번째 모델에서 TP:  456\n",
      "세번째 모델에서 FP:  139\n",
      "세번째 모델에서 TN:  8861\n",
      "세번째 모델에서 FN:  544\n",
      "모델 결과 TP:  437\n",
      "모델 결과 FP:  114\n",
      "모델 결과 TN:  8886\n",
      "모델 결과 FN:  563\n",
      "precision:  0.7931034482758621\n",
      "accuracy:  0.9323\n",
      "\n",
      "클래스 :  5\n",
      "첫번째 모델에서 TP:  835\n",
      "첫번째 모델에서 FP:  2160\n",
      "첫번째 모델에서 TN:  6840\n",
      "첫번째 모델에서 FN:  165\n",
      "두번째 모델에서 TP:  15\n",
      "두번째 모델에서 FP:  2831\n",
      "두번째 모델에서 TN:  6169\n",
      "두번째 모델에서 FN:  985\n",
      "세번째 모델에서 TP:  370\n",
      "세번째 모델에서 FP:  57\n",
      "세번째 모델에서 TN:  8943\n",
      "세번째 모델에서 FN:  630\n",
      "모델 결과 TP:  359\n",
      "모델 결과 FP:  49\n",
      "모델 결과 TN:  8951\n",
      "모델 결과 FN:  641\n",
      "precision:  0.8799019607843137\n",
      "accuracy:  0.931\n",
      "\n",
      "클래스 :  6\n",
      "첫번째 모델에서 TP:  912\n",
      "첫번째 모델에서 FP:  2298\n",
      "첫번째 모델에서 TN:  6702\n",
      "첫번째 모델에서 FN:  88\n",
      "두번째 모델에서 TP:  8\n",
      "두번째 모델에서 FP:  2698\n",
      "두번째 모델에서 TN:  6302\n",
      "두번째 모델에서 FN:  992\n",
      "세번째 모델에서 TP:  771\n",
      "세번째 모델에서 FP:  249\n",
      "세번째 모델에서 TN:  8751\n",
      "세번째 모델에서 FN:  229\n",
      "모델 결과 TP:  744\n",
      "모델 결과 FP:  204\n",
      "모델 결과 TN:  8796\n",
      "모델 결과 FN:  256\n",
      "precision:  0.7848101265822784\n",
      "accuracy:  0.954\n",
      "\n",
      "클래스 :  7\n",
      "첫번째 모델에서 TP:  860\n",
      "첫번째 모델에서 FP:  1993\n",
      "첫번째 모델에서 TN:  7007\n",
      "첫번째 모델에서 FN:  140\n",
      "두번째 모델에서 TP:  22\n",
      "두번째 모델에서 FP:  3120\n",
      "두번째 모델에서 TN:  5880\n",
      "두번째 모델에서 FN:  978\n",
      "세번째 모델에서 TP:  555\n",
      "세번째 모델에서 FP:  62\n",
      "세번째 모델에서 TN:  8938\n",
      "세번째 모델에서 FN:  445\n",
      "모델 결과 TP:  542\n",
      "모델 결과 FP:  57\n",
      "모델 결과 TN:  8943\n",
      "모델 결과 FN:  458\n",
      "precision:  0.9048414023372288\n",
      "accuracy:  0.9485\n",
      "\n",
      "클래스 :  8\n",
      "첫번째 모델에서 TP:  859\n",
      "첫번째 모델에서 FP:  1914\n",
      "첫번째 모델에서 TN:  7086\n",
      "첫번째 모델에서 FN:  141\n",
      "두번째 모델에서 TP:  12\n",
      "두번째 모델에서 FP:  2849\n",
      "두번째 모델에서 TN:  6151\n",
      "두번째 모델에서 FN:  988\n",
      "세번째 모델에서 TP:  774\n",
      "세번째 모델에서 FP:  150\n",
      "세번째 모델에서 TN:  8850\n",
      "세번째 모델에서 FN:  226\n",
      "모델 결과 TP:  718\n",
      "모델 결과 FP:  126\n",
      "모델 결과 TN:  8874\n",
      "모델 결과 FN:  282\n",
      "precision:  0.8507109004739336\n",
      "accuracy:  0.9592\n",
      "\n",
      "클래스 :  9\n",
      "첫번째 모델에서 TP:  938\n",
      "첫번째 모델에서 FP:  2261\n",
      "첫번째 모델에서 TN:  6739\n",
      "첫번째 모델에서 FN:  62\n",
      "두번째 모델에서 TP:  19\n",
      "두번째 모델에서 FP:  2424\n",
      "두번째 모델에서 TN:  6576\n",
      "두번째 모델에서 FN:  981\n",
      "세번째 모델에서 TP:  760\n",
      "세번째 모델에서 FP:  139\n",
      "세번째 모델에서 TN:  8861\n",
      "세번째 모델에서 FN:  240\n",
      "모델 결과 TP:  741\n",
      "모델 결과 FP:  115\n",
      "모델 결과 TN:  8885\n",
      "모델 결과 FN:  259\n",
      "precision:  0.8656542056074766\n",
      "accuracy:  0.9626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"클래스 : \",i)\n",
    "    print(\"첫번째 모델에서 TP: \", len(first_TP_FP_TN_FN[i][0]))\n",
    "    print(\"첫번째 모델에서 FP: \", len(first_TP_FP_TN_FN[i][1]))\n",
    "    print(\"첫번째 모델에서 TN: \", len(first_TP_FP_TN_FN[i][2]))\n",
    "    print(\"첫번째 모델에서 FN: \", len(first_TP_FP_TN_FN[i][3]))\n",
    "\n",
    "    print(\"두번째 모델에서 TP: \", len(second_TP_FP_TN_FN[i][0]))\n",
    "    print(\"두번째 모델에서 FP: \", len(second_TP_FP_TN_FN[i][1]))\n",
    "    print(\"두번째 모델에서 TN: \", len(second_TP_FP_TN_FN[i][2]))\n",
    "    print(\"두번째 모델에서 FN: \", len(second_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"세번째 모델에서 TP: \", len(third_TP_FP_TN_FN[i][0])) \n",
    "    print(\"세번째 모델에서 FP: \", len(third_TP_FP_TN_FN[i][1]))\n",
    "    print(\"세번째 모델에서 TN: \", len(third_TP_FP_TN_FN[i][2]))\n",
    "    print(\"세번째 모델에서 FN: \", len(third_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"모델 결과 TP: \", len(model_result_predict[i][0]))\n",
    "    print(\"모델 결과 FP: \", len(model_result_predict[i][1]))\n",
    "    print(\"모델 결과 TN: \", len(model_result_predict[i][2]))\n",
    "    print(\"모델 결과 FN: \", len(model_result_predict[i][3]))\n",
    "    \n",
    "    # precision = TP / (TP + FP)\n",
    "    print(\"precision: \", (len(model_result_predict[i][0]) / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]))))\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy: \", ((len(model_result_predict[i][0]) + len(model_result_predict[i][2]))\n",
    "                               / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3]))))\n",
    "    print(\"\")\n",
    "\n",
    "    #     print(\"true-false를 통과한 개수 : \", 1000 - (len(first_false[i]) + len(second_true[i])) )\n",
    "#     print(\"precision: \", len(first_TP_TN[i][0])/(len(first_TP_TN[i][0]) + len(second_FP_FN[i][0])))\n",
    "#     print(\"accuracy: \", (len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]))\n",
    "#           /len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]) + len(second_FP_FN[0][i]) + len(second_FP_FN[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
