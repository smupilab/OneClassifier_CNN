{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEWkBMJpNvd_",
    "outputId": "e010c54f-38c1-4abd-c7e4-d29e7e531432"
   },
   "outputs": [],
   "source": [
    "# import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(original_x_train, original_y_train), (original_x_test, original_y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DG5AhMOLjbeb"
   },
   "outputs": [],
   "source": [
    "original_x_train = original_x_train / 255.0\n",
    "original_x_test = original_x_test / 255.0\n",
    "\n",
    "original_y_train = keras.utils.to_categorical(original_y_train)\n",
    "original_y_test = keras.utils.to_categorical(original_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJRl4tKVolc",
    "outputId": "6acbf001-2b2a-4654-f644-3bacf4a641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 10s 7ms/step - loss: 1.7937 - accuracy: 0.3344 - val_loss: 1.4110 - val_accuracy: 0.4807\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.4751 - accuracy: 0.4708 - val_loss: 1.2718 - val_accuracy: 0.5470\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.3533 - accuracy: 0.5188 - val_loss: 1.1886 - val_accuracy: 0.5807\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.2743 - accuracy: 0.5487 - val_loss: 1.0848 - val_accuracy: 0.6172\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.2152 - accuracy: 0.5728 - val_loss: 1.0533 - val_accuracy: 0.6244\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.1571 - accuracy: 0.5927 - val_loss: 0.9850 - val_accuracy: 0.6508\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.1226 - accuracy: 0.6080 - val_loss: 0.9549 - val_accuracy: 0.6614\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.0924 - accuracy: 0.6194 - val_loss: 0.9662 - val_accuracy: 0.6583\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 1.0644 - accuracy: 0.6301 - val_loss: 0.9098 - val_accuracy: 0.6843\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0334 - accuracy: 0.6399 - val_loss: 0.8903 - val_accuracy: 0.6843\n"
     ]
    }
   ],
   "source": [
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.Flatten())\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Dense(64, activation='relu'))\n",
    "original_model.add(layers.Dropout(0.5))\n",
    "original_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_0 = original_model.fit(original_x_train, original_y_train, epochs= 10, batch_size= 64, validation_data=(original_x_test, original_y_test))\n",
    "# loss: 0.9075 - accuracy: 0.6951 - val_loss: 0.8743 - val_accuracy: 0.7026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/59851961/how-to-calculate-confidence-score-of-a-neural-network-prediction\n",
    "model_predict = original_model.predict(original_x_test, batch_size = 1)\n",
    "# model_predict = np.where(model_predict > 0.5, 1, 0).squeeze().item()\n",
    "# np.where(model_predict > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvzfjR4SWu6i",
    "outputId": "a168ca0a-a8f4-4c05-8e59-18fa0d285a26",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[0, 17, 61, 7, 31, 5, 14, 7, 83, 39]\n",
      "[12, 0, 3, 1, 8, 2, 24, 1, 26, 111]\n",
      "[75, 8, 0, 52, 163, 76, 116, 21, 7, 11]\n",
      "[14, 10, 63, 0, 93, 181, 173, 15, 15, 17]\n",
      "[23, 6, 56, 45, 0, 22, 102, 30, 8, 3]\n",
      "[7, 4, 57, 183, 70, 0, 60, 36, 5, 6]\n",
      "[5, 3, 27, 42, 45, 5, 0, 2, 4, 2]\n",
      "[11, 2, 25, 47, 150, 95, 15, 0, 0, 22]\n",
      "[78, 29, 11, 18, 7, 3, 10, 4, 0, 35]\n",
      "[28, 59, 8, 14, 7, 6, 16, 5, 32, 0]\n"
     ]
    }
   ],
   "source": [
    "# 잘못예측한 데이터 찾는 코드\n",
    "# original_label, predict_label\n",
    "wrong_predict = []\n",
    "wrong_predict_cnt = 0\n",
    "class_length = 10\n",
    "\n",
    "model_predict = original_model.predict(original_x_test)\n",
    "\n",
    "for i in range(len(original_y_test)):\n",
    "    predict_idx, original_idx = 0, 0\n",
    "    for j in range(1,10):\n",
    "        if model_predict[i][j] > model_predict[i][predict_idx]:\n",
    "            predict_idx = j\n",
    "        if original_y_test[i][j] > original_y_test[i][original_idx]:\n",
    "            original_idx = j\n",
    "\n",
    "    if predict_idx != original_idx:\n",
    "        wrong_predict.append([original_idx, predict_idx])\n",
    "\n",
    "similar_wrong_predict_count = [[0 for j in range(class_length)] for i in range(class_length)]\n",
    "for i in range(len(wrong_predict)):\n",
    "    similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] = similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] + 1 \n",
    "\n",
    "for i in range(class_length):\n",
    "    print(similar_wrong_predict_count[i])\n",
    "\n",
    "# result\n",
    "# [0, 27, 28, 8, 5, 1, 7, 8, 59, 34]\n",
    "# [16, 0, 0, 6, 1, 3, 3, 1, 18, 51]\n",
    "# [101, 9, 0, 36, 93, 69, 60, 29, 18, 14]\n",
    "# [45, 22, 73, 0, 58, 196, 88, 38, 28, 30]\n",
    "# [40, 4, 71, 39, 0, 26, 66, 94, 11, 3]\n",
    "# [20, 7, 47, 146, 48, 0, 24, 65, 10, 11]\n",
    "# [12, 7, 48, 41, 33, 17, 0, 7, 13, 10]\n",
    "# [23, 2, 32, 23, 36, 50, 5, 0, 4, 15]\n",
    "# [78, 39, 4, 5, 3, 4, 4, 5, 0, 19]\n",
    "# [31, 128, 5, 6, 4, 3, 3, 10, 21, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PXIQquThxGkf"
   },
   "outputs": [],
   "source": [
    "# 가장 큰 값 top 3의 index를 가져와야 함 (cur_idx 제외)\n",
    "def getTopN(target_list, n, cur_idx):\n",
    "    tmp = target_list.copy()\n",
    "    visited = []\n",
    "    top_idx = []\n",
    "    for i in range(0,10):\n",
    "        if len(top_idx) == n:\n",
    "            break;\n",
    "        max_num = -1\n",
    "        max_idx = -1\n",
    "        for j in range(0,10):\n",
    "            if max_num < tmp[j]:\n",
    "                if j == cur_idx:\n",
    "                    continue\n",
    "                if j in visited:\n",
    "                    continue\n",
    "                else:  \n",
    "                    max_num = tmp[j]\n",
    "                    max_idx = j\n",
    "    \n",
    "        if max_idx != -1:\n",
    "            top_idx.append(max_idx)\n",
    "            visited.append(max_idx)\n",
    "    return top_idx\n",
    "\n",
    "# 가장 작은 값 bottom 3의 index를 가져와야 함  (cur_idx 제외)\n",
    "def getBottomN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  bottom_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(bottom_idx) == n:\n",
    "      break;\n",
    "    min_num = 1e9\n",
    "    min_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if tmp[j] < min_num:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                min_num = tmp[j]\n",
    "                min_idx = j\n",
    "    \n",
    "    if min_idx != -1:\n",
    "      bottom_idx.append(min_idx)\n",
    "      visited.append(min_idx)\n",
    "  return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xw4-dk8EBhqV"
   },
   "outputs": [],
   "source": [
    "# cifar10 데이터 가져오는 함수\n",
    "def getCifar10Data():\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train / 255.0\n",
    "  x_test = x_test / 255.0\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# a, b, c로 다시 라벨링\n",
    "def reLabel(y_train, y_test, a, b, c):\n",
    "  for i in range(len(y_train)):\n",
    "    if y_train[i] == a or y_train[i] == b or y_train[i] == c:\n",
    "      y_train[i] = 1\n",
    "    else:\n",
    "      y_train[i] = 0    \n",
    "  \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == a or y_test[i] == b or y_test[i] == c:\n",
    "      y_test[i] = 1\n",
    "    else:\n",
    "      y_test[i] = 0\n",
    "  \n",
    "  return y_train, y_test\n",
    "\n",
    "(model1_x_train, model1_y_train), (model1_x_test, model1_y_test) = getCifar10Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4bb4bjAnNxa3"
   },
   "outputs": [],
   "source": [
    "# model 만드는 함수 \n",
    "def makeModel():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bxau2L_U9toH"
   },
   "outputs": [],
   "source": [
    "def get_TP_FP_TN_FN(y_test, predict, target_idx):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "                break\n",
    "        # True로 나왔을 때\n",
    "        if predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        # False로 나왔을 때\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "            \n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_model_TP_FP_TN_FN(first_predict, second_predict, third_predict, y_test, target_idx):\n",
    "    TP, FP, TN, FN = [],[],[],[]\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "        if first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 0 and third_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "    return TP, FP, TN, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MmmbZyZwFa-",
    "outputId": "6e61ca8b-9629-45f9-d032-a2e072f6c2ad",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 2, 0]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 7ms/step - loss: 0.4640 - accuracy: 0.7957 - val_loss: 0.3951 - val_accuracy: 0.8295\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3905 - accuracy: 0.8362 - val_loss: 0.3886 - val_accuracy: 0.8260\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3629 - accuracy: 0.8489 - val_loss: 0.3453 - val_accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3475 - accuracy: 0.8562 - val_loss: 0.3234 - val_accuracy: 0.8654\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3351 - accuracy: 0.8611 - val_loss: 0.3102 - val_accuracy: 0.8684\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3228 - accuracy: 0.8664 - val_loss: 0.3036 - val_accuracy: 0.8709\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3134 - accuracy: 0.8703 - val_loss: 0.2943 - val_accuracy: 0.8769\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3035 - accuracy: 0.8760 - val_loss: 0.2952 - val_accuracy: 0.8721\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2952 - accuracy: 0.8787 - val_loss: 0.2766 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2882 - accuracy: 0.8810 - val_loss: 0.2906 - val_accuracy: 0.8820\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 3, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4470 - accuracy: 0.7832 - val_loss: 0.3791 - val_accuracy: 0.8329\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3731 - accuracy: 0.8321 - val_loss: 0.3426 - val_accuracy: 0.8476\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3507 - accuracy: 0.8413 - val_loss: 0.3180 - val_accuracy: 0.8605\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3330 - accuracy: 0.8522 - val_loss: 0.3085 - val_accuracy: 0.8662\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3186 - accuracy: 0.8605 - val_loss: 0.2979 - val_accuracy: 0.8697\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3098 - accuracy: 0.8666 - val_loss: 0.2948 - val_accuracy: 0.8705\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3035 - accuracy: 0.8683 - val_loss: 0.3026 - val_accuracy: 0.8695\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2940 - accuracy: 0.8737 - val_loss: 0.2825 - val_accuracy: 0.8765\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2873 - accuracy: 0.8756 - val_loss: 0.2909 - val_accuracy: 0.8731\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2839 - accuracy: 0.8787 - val_loss: 0.2851 - val_accuracy: 0.8767\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2600 - accuracy: 0.9068 - val_loss: 0.2071 - val_accuracy: 0.9198\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2164 - accuracy: 0.9187 - val_loss: 0.1896 - val_accuracy: 0.9279\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1918 - accuracy: 0.9281 - val_loss: 0.1631 - val_accuracy: 0.9390\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1764 - accuracy: 0.9347 - val_loss: 0.1593 - val_accuracy: 0.9409\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1694 - accuracy: 0.9366 - val_loss: 0.1433 - val_accuracy: 0.9483\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1600 - accuracy: 0.9408 - val_loss: 0.1587 - val_accuracy: 0.9401\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1532 - accuracy: 0.9430 - val_loss: 0.1436 - val_accuracy: 0.9499\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1482 - accuracy: 0.9448 - val_loss: 0.1373 - val_accuracy: 0.9486\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1447 - accuracy: 0.9457 - val_loss: 0.1312 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1418 - accuracy: 0.9478 - val_loss: 0.1337 - val_accuracy: 0.9519\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "===============================================================================================\n",
      "1 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[9, 8, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3490 - accuracy: 0.8450 - val_loss: 0.2593 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2593 - accuracy: 0.8924 - val_loss: 0.2159 - val_accuracy: 0.9108\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2306 - accuracy: 0.9065 - val_loss: 0.2035 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2129 - accuracy: 0.9144 - val_loss: 0.1852 - val_accuracy: 0.9241\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2013 - accuracy: 0.9193 - val_loss: 0.1765 - val_accuracy: 0.9288\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1898 - accuracy: 0.9248 - val_loss: 0.1816 - val_accuracy: 0.9251\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1810 - accuracy: 0.9301 - val_loss: 0.1694 - val_accuracy: 0.9327\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1736 - accuracy: 0.9316 - val_loss: 0.1550 - val_accuracy: 0.9400\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1675 - accuracy: 0.9341 - val_loss: 0.1648 - val_accuracy: 0.9332\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1625 - accuracy: 0.9363 - val_loss: 0.1641 - val_accuracy: 0.9337\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[3, 7, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4545 - accuracy: 0.7786 - val_loss: 0.3885 - val_accuracy: 0.8159\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3803 - accuracy: 0.8256 - val_loss: 0.4092 - val_accuracy: 0.8162\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3536 - accuracy: 0.8406 - val_loss: 0.3283 - val_accuracy: 0.8525\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3362 - accuracy: 0.8502 - val_loss: 0.3144 - val_accuracy: 0.8631\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3246 - accuracy: 0.8569 - val_loss: 0.3158 - val_accuracy: 0.8555\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3151 - accuracy: 0.8607 - val_loss: 0.3006 - val_accuracy: 0.8659\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.3017 - accuracy: 0.8664 - val_loss: 0.2952 - val_accuracy: 0.8687\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2970 - accuracy: 0.8700 - val_loss: 0.2816 - val_accuracy: 0.8770\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2899 - accuracy: 0.8738 - val_loss: 0.2818 - val_accuracy: 0.8770\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2846 - accuracy: 0.8779 - val_loss: 0.2758 - val_accuracy: 0.8809\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "406/782 [==============>...............] - ETA: 1s - loss: 0.2637 - accuracy: 0.9047"
     ]
    }
   ],
   "source": [
    "class_accuracy = []\n",
    "first_predict_list = []\n",
    "first_TP_FP_TN_FN = []\n",
    "second_predict_list = []\n",
    "second_TP_FP_TN_FN = []\n",
    "third_predict_list = []\n",
    "third_TP_FP_TN_FN = []\n",
    "model_result_predict = []\n",
    "\n",
    "for i in range(0, class_length):\n",
    "    print(i, \"번째 클래스\")\n",
    "    \n",
    "    # model 1 -> 가장 유사한 클래스끼리 묶은 라벨\n",
    "    print(\"[model1] : 가장 유사한 클래스끼리 묶은 라벨\")\n",
    "    (x_train, y_train), (x_test, y_test) = getCifar10Data()\n",
    "    temp = getTopN(similar_wrong_predict_count[i], 2, i)\n",
    "    # 현재 클래스 index 추가 \n",
    "    temp.append(i)\n",
    "    print(temp)\n",
    "    (y_train, y_test) = reLabel(y_train, y_test, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model1 = makeModel()\n",
    "    model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model1.fit(x_train, y_train, epochs= 10, batch_size = 64, validation_data=(x_test, y_test))\n",
    "    \n",
    "    first_predict = model1.predict(x_test)\n",
    "    first_predict_list.append(first_predict)\n",
    "    first_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, first_predict, i))\n",
    "    \n",
    "    # model 2 -> 가장 유사하지않은 클래스끼리 묶은 라벨\n",
    "    print(\"[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\")\n",
    "    (x_train2, y_train2), (x_test2, y_test2) = getCifar10Data()\n",
    "    temp = getBottomN(similar_wrong_predict_count[i], 3, i)\n",
    "    print(temp)\n",
    "\n",
    "    (y_train2, y_test2) = reLabel(y_train2, y_test2, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model2 = makeModel()\n",
    "    model2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model2.fit(x_train2, y_train2, epochs= 10, batch_size = 64, validation_data=(x_test2, y_test2))\n",
    "    \n",
    "    second_predict = model2.predict(x_test2)\n",
    "    second_predict_list.append(second_predict)\n",
    "    second_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, second_predict, i))\n",
    "    \n",
    "    # model 3 -> 클래스 하나만 True로 라벨링한 모델\n",
    "    (x_train3, y_train3), (x_test3, y_test3) = getCifar10Data()\n",
    "    (y_train3, y_test3) = reLabel(y_train3, y_test3, i, i, i)\n",
    "    \n",
    "    model3 = makeModel()\n",
    "    model3.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model3.fit(x_train3, y_train3, epochs= 10, batch_size = 64, validation_data=(x_test3, y_test3))\n",
    "    third_predict = model3.predict(x_test3)\n",
    "    third_predict_list.append(third_predict)\n",
    "    \n",
    "#     # model 3 ->  0~9 multi class claasifacation 모델\n",
    "#     (x_train3, y_train3), (x_test3, y_test3) = getCifar10Data()\n",
    "    \n",
    "#     model3 = makeModel()\n",
    "#     model3.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "#     model3.fit(x_train3, y_train3, epochs= 10, batch_size = 64, validation_data=(x_test3, y_test3))\n",
    "\n",
    "#     third_predict = model3.predict(x_test3)\n",
    "#     third_predict_list.append(third_predict)\n",
    "    \n",
    "    third_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, third_predict, i))\n",
    "\n",
    "    # 모델의 TP FP TN FN\n",
    "    model_result_predict.append(get_result_model_TP_FP_TN_FN(first_predict, second_predict, third_predict, original_y_test, i))\n",
    "\n",
    "    # 첫번째 모델에서 True 두번째 모델에서 False가 나온 모델\n",
    "#     class_accuracy.append(getRealTrueRatio(first_predict, second_predict, original_y_test,i))  \n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.shape(third_predict_list))\n",
    "true_list = []\n",
    "false_list = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(i, \"번째 클래스\")\n",
    "    for j in range(0,10000):\n",
    "        for k in range(0,2):\n",
    "            if k == 0:\n",
    "                true_list.append(third_predict_list[i][j][k])\n",
    "            else:\n",
    "                false_list.append(third_predict_list[i][j][k])\n",
    "    print(np.mean(true_list))\n",
    "    print(np.mean(false_list))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 :  0\n",
      "첫번째 모델에서 TP:  846\n",
      "첫번째 모델에서 FP:  1658\n",
      "첫번째 모델에서 TN:  7342\n",
      "첫번째 모델에서 FN:  154\n",
      "두번째 모델에서 TP:  23\n",
      "두번째 모델에서 FP:  2978\n",
      "두번째 모델에서 TN:  6022\n",
      "두번째 모델에서 FN:  977\n",
      "세번째 모델에서 TP:  577\n",
      "세번째 모델에서 FP:  66\n",
      "세번째 모델에서 TN:  8934\n",
      "세번째 모델에서 FN:  423\n",
      "모델 결과 TP:  554\n",
      "모델 결과 FP:  56\n",
      "모델 결과 TN:  8944\n",
      "모델 결과 FN:  446\n",
      "precision:  0.9081967213114754\n",
      "accuracy:  0.9498\n",
      "\n",
      "클래스 :  1\n",
      "첫번째 모델에서 TP:  876\n",
      "첫번째 모델에서 FP:  1683\n",
      "첫번째 모델에서 TN:  7317\n",
      "첫번째 모델에서 FN:  124\n",
      "두번째 모델에서 TP:  14\n",
      "두번째 모델에서 FP:  2526\n",
      "두번째 모델에서 TN:  6474\n",
      "두번째 모델에서 FN:  986\n",
      "세번째 모델에서 TP:  675\n",
      "세번째 모델에서 FP:  35\n",
      "세번째 모델에서 TN:  8965\n",
      "세번째 모델에서 FN:  325\n",
      "모델 결과 TP:  651\n",
      "모델 결과 FP:  30\n",
      "모델 결과 TN:  8970\n",
      "모델 결과 FN:  349\n",
      "precision:  0.9559471365638766\n",
      "accuracy:  0.9621\n",
      "\n",
      "클래스 :  2\n",
      "첫번째 모델에서 TP:  721\n",
      "첫번째 모델에서 FP:  2355\n",
      "첫번째 모델에서 TN:  6645\n",
      "첫번째 모델에서 FN:  279\n",
      "두번째 모델에서 TP:  34\n",
      "두번째 모델에서 FP:  3099\n",
      "두번째 모델에서 TN:  5901\n",
      "두번째 모델에서 FN:  966\n",
      "세번째 모델에서 TP:  460\n",
      "세번째 모델에서 FP:  174\n",
      "세번째 모델에서 TN:  8826\n",
      "세번째 모델에서 FN:  540\n",
      "모델 결과 TP:  402\n",
      "모델 결과 FP:  117\n",
      "모델 결과 TN:  8883\n",
      "모델 결과 FN:  598\n",
      "precision:  0.7745664739884393\n",
      "accuracy:  0.9285\n",
      "\n",
      "클래스 :  3\n",
      "첫번째 모델에서 TP:  793\n",
      "첫번째 모델에서 FP:  2310\n",
      "첫번째 모델에서 TN:  6690\n",
      "첫번째 모델에서 FN:  207\n",
      "두번째 모델에서 TP:  10\n",
      "두번째 모델에서 FP:  2171\n",
      "두번째 모델에서 TN:  6829\n",
      "두번째 모델에서 FN:  990\n",
      "세번째 모델에서 TP:  234\n",
      "세번째 모델에서 FP:  92\n",
      "세번째 모델에서 TN:  8908\n",
      "세번째 모델에서 FN:  766\n",
      "모델 결과 TP:  226\n",
      "모델 결과 FP:  86\n",
      "모델 결과 TN:  8914\n",
      "모델 결과 FN:  774\n",
      "precision:  0.7243589743589743\n",
      "accuracy:  0.914\n",
      "\n",
      "클래스 :  4\n",
      "첫번째 모델에서 TP:  755\n",
      "첫번째 모델에서 FP:  2196\n",
      "첫번째 모델에서 TN:  6804\n",
      "첫번째 모델에서 FN:  245\n",
      "두번째 모델에서 TP:  8\n",
      "두번째 모델에서 FP:  2190\n",
      "두번째 모델에서 TN:  6810\n",
      "두번째 모델에서 FN:  992\n",
      "세번째 모델에서 TP:  443\n",
      "세번째 모델에서 FP:  147\n",
      "세번째 모델에서 TN:  8853\n",
      "세번째 모델에서 FN:  557\n",
      "모델 결과 TP:  401\n",
      "모델 결과 FP:  110\n",
      "모델 결과 TN:  8890\n",
      "모델 결과 FN:  599\n",
      "precision:  0.7847358121330724\n",
      "accuracy:  0.9291\n",
      "\n",
      "클래스 :  5\n",
      "첫번째 모델에서 TP:  879\n",
      "첫번째 모델에서 FP:  2398\n",
      "첫번째 모델에서 TN:  6602\n",
      "첫번째 모델에서 FN:  121\n",
      "두번째 모델에서 TP:  10\n",
      "두번째 모델에서 FP:  2802\n",
      "두번째 모델에서 TN:  6198\n",
      "두번째 모델에서 FN:  990\n",
      "세번째 모델에서 TP:  400\n",
      "세번째 모델에서 FP:  64\n",
      "세번째 모델에서 TN:  8936\n",
      "세번째 모델에서 FN:  600\n",
      "모델 결과 TP:  393\n",
      "모델 결과 FP:  57\n",
      "모델 결과 TN:  8943\n",
      "모델 결과 FN:  607\n",
      "precision:  0.8733333333333333\n",
      "accuracy:  0.9336\n",
      "\n",
      "클래스 :  6\n",
      "첫번째 모델에서 TP:  893\n",
      "첫번째 모델에서 FP:  1962\n",
      "첫번째 모델에서 TN:  7038\n",
      "첫번째 모델에서 FN:  107\n",
      "두번째 모델에서 TP:  10\n",
      "두번째 모델에서 FP:  2705\n",
      "두번째 모델에서 TN:  6295\n",
      "두번째 모델에서 FN:  990\n",
      "세번째 모델에서 TP:  685\n",
      "세번째 모델에서 FP:  134\n",
      "세번째 모델에서 TN:  8866\n",
      "세번째 모델에서 FN:  315\n",
      "모델 결과 TP:  672\n",
      "모델 결과 FP:  117\n",
      "모델 결과 TN:  8883\n",
      "모델 결과 FN:  328\n",
      "precision:  0.8517110266159695\n",
      "accuracy:  0.9555\n",
      "\n",
      "클래스 :  7\n",
      "첫번째 모델에서 TP:  800\n",
      "첫번째 모델에서 FP:  1447\n",
      "첫번째 모델에서 TN:  7553\n",
      "첫번째 모델에서 FN:  200\n",
      "두번째 모델에서 TP:  6\n",
      "두번째 모델에서 FP:  2784\n",
      "두번째 모델에서 TN:  6216\n",
      "두번째 모델에서 FN:  994\n",
      "세번째 모델에서 TP:  666\n",
      "세번째 모델에서 FP:  82\n",
      "세번째 모델에서 TN:  8918\n",
      "세번째 모델에서 FN:  334\n",
      "모델 결과 TP:  616\n",
      "모델 결과 FP:  71\n",
      "모델 결과 TN:  8929\n",
      "모델 결과 FN:  384\n",
      "precision:  0.8966521106259098\n",
      "accuracy:  0.9545\n",
      "\n",
      "클래스 :  8\n",
      "첫번째 모델에서 TP:  725\n",
      "첫번째 모델에서 FP:  1416\n",
      "첫번째 모델에서 TN:  7584\n",
      "첫번째 모델에서 FN:  275\n",
      "두번째 모델에서 TP:  16\n",
      "두번째 모델에서 FP:  2862\n",
      "두번째 모델에서 TN:  6138\n",
      "두번째 모델에서 FN:  984\n",
      "세번째 모델에서 TP:  702\n",
      "세번째 모델에서 FP:  98\n",
      "세번째 모델에서 TN:  8902\n",
      "세번째 모델에서 FN:  298\n",
      "모델 결과 TP:  599\n",
      "모델 결과 FP:  62\n",
      "모델 결과 TN:  8938\n",
      "모델 결과 FN:  401\n",
      "precision:  0.9062027231467473\n",
      "accuracy:  0.9537\n",
      "\n",
      "클래스 :  9\n",
      "첫번째 모델에서 TP:  749\n",
      "첫번째 모델에서 FP:  1461\n",
      "첫번째 모델에서 TN:  7539\n",
      "첫번째 모델에서 FN:  251\n",
      "두번째 모델에서 TP:  6\n",
      "두번째 모델에서 FP:  2245\n",
      "두번째 모델에서 TN:  6755\n",
      "두번째 모델에서 FN:  994\n",
      "세번째 모델에서 TP:  689\n",
      "세번째 모델에서 FP:  67\n",
      "세번째 모델에서 TN:  8933\n",
      "세번째 모델에서 FN:  311\n",
      "모델 결과 TP:  603\n",
      "모델 결과 FP:  44\n",
      "모델 결과 TN:  8956\n",
      "모델 결과 FN:  397\n",
      "precision:  0.9319938176197836\n",
      "accuracy:  0.9559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"클래스 : \",i)\n",
    "    print(\"첫번째 모델에서 TP: \", len(first_TP_FP_TN_FN[i][0]))\n",
    "    print(\"첫번째 모델에서 FP: \", len(first_TP_FP_TN_FN[i][1]))\n",
    "    print(\"첫번째 모델에서 TN: \", len(first_TP_FP_TN_FN[i][2]))\n",
    "    print(\"첫번째 모델에서 FN: \", len(first_TP_FP_TN_FN[i][3]))\n",
    "\n",
    "    print(\"두번째 모델에서 TP: \", len(second_TP_FP_TN_FN[i][0]))\n",
    "    print(\"두번째 모델에서 FP: \", len(second_TP_FP_TN_FN[i][1]))\n",
    "    print(\"두번째 모델에서 TN: \", len(second_TP_FP_TN_FN[i][2]))\n",
    "    print(\"두번째 모델에서 FN: \", len(second_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"세번째 모델에서 TP: \", len(third_TP_FP_TN_FN[i][0])) \n",
    "    print(\"세번째 모델에서 FP: \", len(third_TP_FP_TN_FN[i][1]))\n",
    "    print(\"세번째 모델에서 TN: \", len(third_TP_FP_TN_FN[i][2]))\n",
    "    print(\"세번째 모델에서 FN: \", len(third_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"모델 결과 TP: \", len(model_result_predict[i][0]))\n",
    "    print(\"모델 결과 FP: \", len(model_result_predict[i][1]))\n",
    "    print(\"모델 결과 TN: \", len(model_result_predict[i][2]))\n",
    "    print(\"모델 결과 FN: \", len(model_result_predict[i][3]))\n",
    "    \n",
    "    # precision = TP / (TP + FP)\n",
    "    print(\"precision: \", (len(model_result_predict[i][0]) / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]))))\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy: \", ((len(model_result_predict[i][0]) + len(model_result_predict[i][2]))\n",
    "                               / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3]))))\n",
    "    print(\"\")\n",
    "\n",
    "    #     print(\"true-false를 통과한 개수 : \", 1000 - (len(first_false[i]) + len(second_true[i])) )\n",
    "#     print(\"precision: \", len(first_TP_TN[i][0])/(len(first_TP_TN[i][0]) + len(second_FP_FN[i][0])))\n",
    "#     print(\"accuracy: \", (len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]))\n",
    "#           /len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]) + len(second_FP_FN[0][i]) + len(second_FP_FN[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO; multi class classification 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
