{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEWkBMJpNvd_",
    "outputId": "e010c54f-38c1-4abd-c7e4-d29e7e531432"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(original_x_train, original_y_train), (original_x_test, original_y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DG5AhMOLjbeb"
   },
   "outputs": [],
   "source": [
    "original_x_train = original_x_train / 255.0\n",
    "original_x_test = original_x_test / 255.0\n",
    "\n",
    "original_y_train = keras.utils.to_categorical(original_y_train)\n",
    "original_y_test = keras.utils.to_categorical(original_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJRl4tKVolc",
    "outputId": "6acbf001-2b2a-4654-f644-3bacf4a641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 5ms/step - loss: 1.8084 - accuracy: 0.3252 - val_loss: 1.4337 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.4709 - accuracy: 0.4677 - val_loss: 1.2748 - val_accuracy: 0.5473\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.3467 - accuracy: 0.5232 - val_loss: 1.1373 - val_accuracy: 0.5927\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2643 - accuracy: 0.5520 - val_loss: 1.0916 - val_accuracy: 0.6192\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2028 - accuracy: 0.5807 - val_loss: 1.0457 - val_accuracy: 0.6397\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1479 - accuracy: 0.5986 - val_loss: 1.0854 - val_accuracy: 0.6234\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1165 - accuracy: 0.6100 - val_loss: 0.9505 - val_accuracy: 0.6743\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0854 - accuracy: 0.6225 - val_loss: 0.9564 - val_accuracy: 0.6614\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0562 - accuracy: 0.6339 - val_loss: 0.9185 - val_accuracy: 0.6851\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0293 - accuracy: 0.6417 - val_loss: 0.8959 - val_accuracy: 0.6860\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.Flatten())\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Dense(64, activation='relu'))\n",
    "original_model.add(layers.Dropout(0.5))\n",
    "original_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_0 = original_model.fit(original_x_train, original_y_train, epochs= 10, batch_size= 64, validation_data=(original_x_test, original_y_test))\n",
    "# loss: 0.9075 - accuracy: 0.6951 - val_loss: 0.8743 - val_accuracy: 0.7026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvzfjR4SWu6i",
    "outputId": "a168ca0a-a8f4-4c05-8e59-18fa0d285a26",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "[0, 19, 67, 13, 16, 5, 13, 11, 105, 15]\n",
      "[25, 0, 2, 11, 6, 0, 24, 4, 40, 36]\n",
      "[80, 6, 0, 67, 120, 66, 125, 39, 12, 4]\n",
      "[14, 7, 82, 0, 63, 185, 153, 31, 16, 5]\n",
      "[19, 2, 63, 57, 0, 22, 124, 80, 9, 1]\n",
      "[11, 2, 68, 171, 53, 0, 55, 57, 4, 3]\n",
      "[3, 3, 33, 39, 38, 8, 0, 6, 6, 2]\n",
      "[21, 3, 28, 31, 79, 74, 18, 0, 1, 3]\n",
      "[67, 15, 12, 20, 7, 3, 15, 4, 0, 11]\n",
      "[47, 120, 9, 11, 11, 8, 30, 18, 48, 0]\n"
     ]
    }
   ],
   "source": [
    "# 잘못예측한 데이터 찾는 코드\n",
    "# original_label, predict_label\n",
    "wrong_predict = []\n",
    "wrong_predict_cnt = 0\n",
    "class_length = 10\n",
    "\n",
    "model_predict = original_model.predict(original_x_test)\n",
    "\n",
    "for i in range(len(original_y_test)):\n",
    "  predict_idx, original_idx = 0, 0\n",
    "  for j in range(1,10):\n",
    "    if model_predict[i][j] > model_predict[i][predict_idx]:\n",
    "      predict_idx = j\n",
    "    if original_y_test[i][j] > original_y_test[i][original_idx]:\n",
    "      original_idx = j\n",
    "\n",
    "  if predict_idx != original_idx:\n",
    "    wrong_predict.append([original_idx, predict_idx])\n",
    "\n",
    "similar_wrong_predict_count = [[0 for j in range(class_length)] for i in range(class_length)]\n",
    "for i in range(len(wrong_predict)):\n",
    "  similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] = similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] + 1 \n",
    "\n",
    "for i in range(class_length):\n",
    "  print(similar_wrong_predict_count[i])\n",
    "\n",
    "# result\n",
    "# [0, 27, 28, 8, 5, 1, 7, 8, 59, 34]\n",
    "# [16, 0, 0, 6, 1, 3, 3, 1, 18, 51]\n",
    "# [101, 9, 0, 36, 93, 69, 60, 29, 18, 14]\n",
    "# [45, 22, 73, 0, 58, 196, 88, 38, 28, 30]\n",
    "# [40, 4, 71, 39, 0, 26, 66, 94, 11, 3]\n",
    "# [20, 7, 47, 146, 48, 0, 24, 65, 10, 11]\n",
    "# [12, 7, 48, 41, 33, 17, 0, 7, 13, 10]\n",
    "# [23, 2, 32, 23, 36, 50, 5, 0, 4, 15]\n",
    "# [78, 39, 4, 5, 3, 4, 4, 5, 0, 19]\n",
    "# [31, 128, 5, 6, 4, 3, 3, 10, 21, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PXIQquThxGkf"
   },
   "outputs": [],
   "source": [
    "# 가장 큰 값 top 3의 index를 가져와야 함 (cur_idx 제외)\n",
    "def getTopN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  top_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(top_idx) == n:\n",
    "      break;\n",
    "    max_num = -1\n",
    "    max_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if max_num < tmp[j]:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                max_num = tmp[j]\n",
    "                max_idx = j\n",
    "    \n",
    "    if max_idx != -1:\n",
    "      top_idx.append(max_idx)\n",
    "      visited.append(max_idx)\n",
    "  return top_idx\n",
    "\n",
    "# 가장 작은 값 bottom 3의 index를 가져와야 함  (cur_idx 제외)\n",
    "def getBottomN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  bottom_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(bottom_idx) == n:\n",
    "      break;\n",
    "    min_num = 1e9\n",
    "    min_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if tmp[j] < min_num:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                min_num = tmp[j]\n",
    "                min_idx = j\n",
    "    \n",
    "    if min_idx != -1:\n",
    "      bottom_idx.append(min_idx)\n",
    "      visited.append(min_idx)\n",
    "  return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xw4-dk8EBhqV"
   },
   "outputs": [],
   "source": [
    "# cifar10 데이터 가져오는 함수\n",
    "def getCifar10Data():\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train / 255.0\n",
    "  x_test = x_test / 255.0\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# a, b, c로 다시 라벨링\n",
    "def reLabel(y_train, y_test, a, b, c):\n",
    "  for i in range(len(y_train)):\n",
    "    if y_train[i] == a or y_train[i] == b or y_train[i] == c:\n",
    "      y_train[i] = 1\n",
    "    else:\n",
    "      y_train[i] = 0    \n",
    "  \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == a or y_test[i] == b or y_test[i] == c:\n",
    "      y_test[i] = 1\n",
    "    else:\n",
    "      y_test[i] = 0\n",
    "  \n",
    "  return y_train, y_test\n",
    "\n",
    "(model1_x_train, model1_y_train), (model1_x_test, model1_y_test) = getCifar10Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4bb4bjAnNxa3"
   },
   "outputs": [],
   "source": [
    "# model 만드는 함수 \n",
    "def makeModel():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bxau2L_U9toH"
   },
   "outputs": [],
   "source": [
    "# # 모델의 결과가 true인 predict index 반환함수\n",
    "# def get_TP_FP(y_test, predict, target_idx):\n",
    "#     TP = []\n",
    "#     FP = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 1:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TP.append(i)\n",
    "#             else:\n",
    "#                 FP.append(i)\n",
    "#     return TP, FP\n",
    "\n",
    "# # 모델의 결과가 false인 predict index 반환함수\n",
    "# def get_TN_FN(y_test, predict, target_idx):\n",
    "#     TN = []\n",
    "#     FN = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 0:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TN.append(i)\n",
    "#             else:\n",
    "#                 FN.append(i)\n",
    "#     return TN, FN\n",
    "\n",
    "def get_TP_FP_TN_FN(y_test, predict, target_idx):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "                break\n",
    "        # True로 나왔을 때\n",
    "        if predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        # False로 나왔을 때\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "            \n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_model_TP_FP_TN_FN(first_predict, second_predict, third_predict, y_test, target_idx):\n",
    "    TP, FP, TN, FN = [],[],[],[]\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "        if first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 0 and third_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        else:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "    return TP, FP, TN, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MmmbZyZwFa-",
    "outputId": "6e61ca8b-9629-45f9-d032-a2e072f6c2ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 2, 0]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4714 - accuracy: 0.7904 - val_loss: 0.3881 - val_accuracy: 0.8365\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3744 - accuracy: 0.8444 - val_loss: 0.3341 - val_accuracy: 0.8621\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3406 - accuracy: 0.8595 - val_loss: 0.3172 - val_accuracy: 0.8656\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3166 - accuracy: 0.8708 - val_loss: 0.2899 - val_accuracy: 0.8792\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3034 - accuracy: 0.8762 - val_loss: 0.2771 - val_accuracy: 0.8830\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2873 - accuracy: 0.8834 - val_loss: 0.2774 - val_accuracy: 0.8862\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2748 - accuracy: 0.8896 - val_loss: 0.2938 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2653 - accuracy: 0.8922 - val_loss: 0.2668 - val_accuracy: 0.8887\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2568 - accuracy: 0.8969 - val_loss: 0.2648 - val_accuracy: 0.8881\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2485 - accuracy: 0.8996 - val_loss: 0.2575 - val_accuracy: 0.8955\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.4683 - accuracy: 0.7682 - val_loss: 0.4101 - val_accuracy: 0.8172\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3731 - accuracy: 0.8314 - val_loss: 0.3387 - val_accuracy: 0.8464\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3417 - accuracy: 0.8487 - val_loss: 0.3210 - val_accuracy: 0.8578\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3219 - accuracy: 0.8608 - val_loss: 0.2986 - val_accuracy: 0.8684\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3032 - accuracy: 0.8687 - val_loss: 0.2970 - val_accuracy: 0.8745\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2883 - accuracy: 0.8763 - val_loss: 0.3220 - val_accuracy: 0.8607\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2780 - accuracy: 0.8810 - val_loss: 0.2939 - val_accuracy: 0.8722\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2668 - accuracy: 0.8873 - val_loss: 0.2748 - val_accuracy: 0.8851\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2543 - accuracy: 0.8926 - val_loss: 0.2728 - val_accuracy: 0.8836\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2480 - accuracy: 0.8964 - val_loss: 0.2625 - val_accuracy: 0.8930\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2708 - accuracy: 0.9012 - val_loss: 0.2137 - val_accuracy: 0.9157\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2239 - accuracy: 0.9128 - val_loss: 0.2078 - val_accuracy: 0.9178\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1971 - accuracy: 0.9258 - val_loss: 0.1847 - val_accuracy: 0.9256\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1748 - accuracy: 0.9345 - val_loss: 0.1526 - val_accuracy: 0.9423\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1583 - accuracy: 0.9425 - val_loss: 0.1471 - val_accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1476 - accuracy: 0.9453 - val_loss: 0.1407 - val_accuracy: 0.9490\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1415 - accuracy: 0.9486 - val_loss: 0.1448 - val_accuracy: 0.9469\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1346 - accuracy: 0.9510 - val_loss: 0.1330 - val_accuracy: 0.9514\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1266 - accuracy: 0.9535 - val_loss: 0.1275 - val_accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1216 - accuracy: 0.9561 - val_loss: 0.1184 - val_accuracy: 0.9586\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "1 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[8, 9, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3633 - accuracy: 0.8371 - val_loss: 0.2706 - val_accuracy: 0.8893\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2593 - accuracy: 0.8936 - val_loss: 0.3328 - val_accuracy: 0.8552\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2239 - accuracy: 0.9096 - val_loss: 0.1969 - val_accuracy: 0.9173\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1936 - accuracy: 0.9245 - val_loss: 0.1780 - val_accuracy: 0.9286\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1698 - accuracy: 0.9349 - val_loss: 0.1799 - val_accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9411 - val_loss: 0.1495 - val_accuracy: 0.9385\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1443 - accuracy: 0.9453 - val_loss: 0.1615 - val_accuracy: 0.9383\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1360 - accuracy: 0.9480 - val_loss: 0.1382 - val_accuracy: 0.9496\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1251 - accuracy: 0.9537 - val_loss: 0.1299 - val_accuracy: 0.9528\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1182 - accuracy: 0.9552 - val_loss: 0.1290 - val_accuracy: 0.9502\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 2, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5111 - accuracy: 0.7326 - val_loss: 0.4463 - val_accuracy: 0.7727\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4429 - accuracy: 0.7834 - val_loss: 0.4114 - val_accuracy: 0.8021\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4163 - accuracy: 0.7995 - val_loss: 0.4209 - val_accuracy: 0.7994\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3968 - accuracy: 0.8119 - val_loss: 0.3806 - val_accuracy: 0.8172\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3828 - accuracy: 0.8207 - val_loss: 0.3690 - val_accuracy: 0.8223\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3670 - accuracy: 0.8289 - val_loss: 0.3856 - val_accuracy: 0.8231\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3560 - accuracy: 0.8360 - val_loss: 0.3473 - val_accuracy: 0.8424\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3419 - accuracy: 0.8430 - val_loss: 0.3230 - val_accuracy: 0.8578\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3305 - accuracy: 0.8499 - val_loss: 0.3224 - val_accuracy: 0.8543\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3213 - accuracy: 0.8565 - val_loss: 0.3370 - val_accuracy: 0.8472\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2344 - accuracy: 0.9092 - val_loss: 0.1757 - val_accuracy: 0.9277\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1586 - accuracy: 0.9411 - val_loss: 0.1395 - val_accuracy: 0.9472\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1285 - accuracy: 0.9535 - val_loss: 0.1093 - val_accuracy: 0.9623\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1111 - accuracy: 0.9603 - val_loss: 0.0982 - val_accuracy: 0.9657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0983 - accuracy: 0.9651 - val_loss: 0.0906 - val_accuracy: 0.9691\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0908 - accuracy: 0.9689 - val_loss: 0.0949 - val_accuracy: 0.9679\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0821 - accuracy: 0.9712 - val_loss: 0.0943 - val_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0773 - accuracy: 0.9731 - val_loss: 0.0782 - val_accuracy: 0.9721\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0728 - accuracy: 0.9741 - val_loss: 0.0972 - val_accuracy: 0.9674\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0704 - accuracy: 0.9752 - val_loss: 0.0813 - val_accuracy: 0.9724\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "2 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[6, 4, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4777 - accuracy: 0.7730 - val_loss: 0.4020 - val_accuracy: 0.8121\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4122 - accuracy: 0.8095 - val_loss: 0.4048 - val_accuracy: 0.8126\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3802 - accuracy: 0.8276 - val_loss: 0.3564 - val_accuracy: 0.8384\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3619 - accuracy: 0.8390 - val_loss: 0.3278 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3422 - accuracy: 0.8481 - val_loss: 0.3248 - val_accuracy: 0.8609\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3267 - accuracy: 0.8577 - val_loss: 0.3355 - val_accuracy: 0.8498\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3168 - accuracy: 0.8625 - val_loss: 0.3179 - val_accuracy: 0.8659\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3021 - accuracy: 0.8693 - val_loss: 0.3247 - val_accuracy: 0.8570\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2926 - accuracy: 0.8736 - val_loss: 0.3042 - val_accuracy: 0.8687\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2868 - accuracy: 0.8753 - val_loss: 0.2985 - val_accuracy: 0.8697\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3786 - accuracy: 0.8247 - val_loss: 0.2906 - val_accuracy: 0.8784\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2633 - accuracy: 0.8919 - val_loss: 0.2636 - val_accuracy: 0.8865\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2192 - accuracy: 0.9146 - val_loss: 0.2269 - val_accuracy: 0.9091\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1904 - accuracy: 0.9261 - val_loss: 0.1633 - val_accuracy: 0.9338\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1668 - accuracy: 0.9369 - val_loss: 0.1963 - val_accuracy: 0.9124\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1514 - accuracy: 0.9421 - val_loss: 0.1506 - val_accuracy: 0.9389\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1395 - accuracy: 0.9474 - val_loss: 0.1439 - val_accuracy: 0.9488\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1299 - accuracy: 0.9504 - val_loss: 0.1308 - val_accuracy: 0.9492\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1223 - accuracy: 0.9537 - val_loss: 0.1232 - val_accuracy: 0.9527\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1131 - accuracy: 0.9583 - val_loss: 0.1375 - val_accuracy: 0.9486\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3142 - accuracy: 0.8980 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2668 - accuracy: 0.9017 - val_loss: 0.2817 - val_accuracy: 0.9078\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2462 - accuracy: 0.9074 - val_loss: 0.2517 - val_accuracy: 0.9091\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2288 - accuracy: 0.9134 - val_loss: 0.2160 - val_accuracy: 0.9209\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2153 - accuracy: 0.9186 - val_loss: 0.2129 - val_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2073 - accuracy: 0.9213 - val_loss: 0.2050 - val_accuracy: 0.9256\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1985 - accuracy: 0.9258 - val_loss: 0.1956 - val_accuracy: 0.9256\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1894 - accuracy: 0.9290 - val_loss: 0.1927 - val_accuracy: 0.9281\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1841 - accuracy: 0.9305 - val_loss: 0.1889 - val_accuracy: 0.9285\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1777 - accuracy: 0.9334 - val_loss: 0.1898 - val_accuracy: 0.9320\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "3 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[5, 6, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4789 - accuracy: 0.7529 - val_loss: 0.3836 - val_accuracy: 0.8146\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3808 - accuracy: 0.8251 - val_loss: 0.3785 - val_accuracy: 0.8195\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3456 - accuracy: 0.8449 - val_loss: 0.3243 - val_accuracy: 0.8510\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3221 - accuracy: 0.8588 - val_loss: 0.3032 - val_accuracy: 0.8655\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3072 - accuracy: 0.8662 - val_loss: 0.3175 - val_accuracy: 0.8577\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2898 - accuracy: 0.8754 - val_loss: 0.2911 - val_accuracy: 0.8733\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2742 - accuracy: 0.8814 - val_loss: 0.2909 - val_accuracy: 0.8728\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2668 - accuracy: 0.8850 - val_loss: 0.2853 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2592 - accuracy: 0.8906 - val_loss: 0.2912 - val_accuracy: 0.8799\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2493 - accuracy: 0.8936 - val_loss: 0.2850 - val_accuracy: 0.8767\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 0]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4356 - accuracy: 0.7905 - val_loss: 0.3294 - val_accuracy: 0.8449\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3278 - accuracy: 0.8538 - val_loss: 0.2706 - val_accuracy: 0.8785\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2756 - accuracy: 0.8858 - val_loss: 0.2530 - val_accuracy: 0.8893\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2407 - accuracy: 0.9015 - val_loss: 0.2096 - val_accuracy: 0.9138\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2200 - accuracy: 0.9109 - val_loss: 0.1952 - val_accuracy: 0.9213\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2040 - accuracy: 0.9185 - val_loss: 0.1918 - val_accuracy: 0.9230\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1955 - accuracy: 0.9228 - val_loss: 0.1781 - val_accuracy: 0.9273\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1813 - accuracy: 0.9285 - val_loss: 0.1787 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1718 - accuracy: 0.9331 - val_loss: 0.1709 - val_accuracy: 0.9297\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1666 - accuracy: 0.9353 - val_loss: 0.1610 - val_accuracy: 0.9375\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3073 - accuracy: 0.8987 - val_loss: 0.2800 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2729 - accuracy: 0.8998 - val_loss: 0.2609 - val_accuracy: 0.9002\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2611 - accuracy: 0.9003 - val_loss: 0.2634 - val_accuracy: 0.9010\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2525 - accuracy: 0.9001 - val_loss: 0.2459 - val_accuracy: 0.9004\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2435 - accuracy: 0.9009 - val_loss: 0.2443 - val_accuracy: 0.9039\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2402 - accuracy: 0.9028 - val_loss: 0.2363 - val_accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2322 - accuracy: 0.9052 - val_loss: 0.2332 - val_accuracy: 0.9082\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2251 - accuracy: 0.9068 - val_loss: 0.2206 - val_accuracy: 0.9121\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2227 - accuracy: 0.9094 - val_loss: 0.2280 - val_accuracy: 0.9088\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2165 - accuracy: 0.9110 - val_loss: 0.2147 - val_accuracy: 0.9158\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "4 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[6, 7, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4870 - accuracy: 0.7569 - val_loss: 0.4377 - val_accuracy: 0.8047\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4133 - accuracy: 0.8095 - val_loss: 0.3637 - val_accuracy: 0.8411\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3689 - accuracy: 0.8378 - val_loss: 0.3565 - val_accuracy: 0.8353\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3402 - accuracy: 0.8514 - val_loss: 0.3203 - val_accuracy: 0.8585\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3189 - accuracy: 0.8615 - val_loss: 0.3072 - val_accuracy: 0.8630\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3057 - accuracy: 0.8673 - val_loss: 0.2881 - val_accuracy: 0.8771\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2913 - accuracy: 0.8740 - val_loss: 0.2893 - val_accuracy: 0.8733\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2834 - accuracy: 0.8769 - val_loss: 0.2748 - val_accuracy: 0.8825\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2757 - accuracy: 0.8832 - val_loss: 0.2973 - val_accuracy: 0.8739\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2664 - accuracy: 0.8866 - val_loss: 0.2656 - val_accuracy: 0.8833\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3723 - accuracy: 0.8319 - val_loss: 0.2814 - val_accuracy: 0.8811\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2661 - accuracy: 0.8908 - val_loss: 0.2146 - val_accuracy: 0.9107\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2271 - accuracy: 0.9082 - val_loss: 0.1923 - val_accuracy: 0.9169\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1961 - accuracy: 0.9233 - val_loss: 0.1919 - val_accuracy: 0.9249\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1677 - accuracy: 0.9359 - val_loss: 0.1573 - val_accuracy: 0.9378\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1549 - accuracy: 0.9411 - val_loss: 0.1718 - val_accuracy: 0.9317\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1440 - accuracy: 0.9457 - val_loss: 0.1329 - val_accuracy: 0.9486\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1330 - accuracy: 0.9499 - val_loss: 0.1464 - val_accuracy: 0.9480\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1283 - accuracy: 0.9508 - val_loss: 0.1495 - val_accuracy: 0.9426\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1180 - accuracy: 0.9553 - val_loss: 0.1182 - val_accuracy: 0.9539\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2936 - accuracy: 0.8997 - val_loss: 0.2731 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2658 - accuracy: 0.9012 - val_loss: 0.2490 - val_accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2434 - accuracy: 0.9067 - val_loss: 0.2313 - val_accuracy: 0.9089\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2222 - accuracy: 0.9138 - val_loss: 0.2201 - val_accuracy: 0.9138\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2038 - accuracy: 0.9212 - val_loss: 0.2010 - val_accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1931 - accuracy: 0.9261 - val_loss: 0.1831 - val_accuracy: 0.9263\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1801 - accuracy: 0.9317 - val_loss: 0.1679 - val_accuracy: 0.9348\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1671 - accuracy: 0.9361 - val_loss: 0.1610 - val_accuracy: 0.9357\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1609 - accuracy: 0.9388 - val_loss: 0.1613 - val_accuracy: 0.9367\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9420 - val_loss: 0.1530 - val_accuracy: 0.9379\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "===============================================================================================\n",
      "5 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 2, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4811 - accuracy: 0.7543 - val_loss: 0.4033 - val_accuracy: 0.8169\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3969 - accuracy: 0.8172 - val_loss: 0.4464 - val_accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3683 - accuracy: 0.8324 - val_loss: 0.3505 - val_accuracy: 0.8406\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3512 - accuracy: 0.8435 - val_loss: 0.3454 - val_accuracy: 0.8400\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3366 - accuracy: 0.8499 - val_loss: 0.3225 - val_accuracy: 0.8557\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3265 - accuracy: 0.8571 - val_loss: 0.3236 - val_accuracy: 0.8572\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3160 - accuracy: 0.8622 - val_loss: 0.3199 - val_accuracy: 0.8652\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3033 - accuracy: 0.8680 - val_loss: 0.3169 - val_accuracy: 0.8611\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2952 - accuracy: 0.8707 - val_loss: 0.3045 - val_accuracy: 0.8657\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2902 - accuracy: 0.8741 - val_loss: 0.2943 - val_accuracy: 0.8698\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 9, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3703 - accuracy: 0.8329 - val_loss: 0.2602 - val_accuracy: 0.8882\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2546 - accuracy: 0.8960 - val_loss: 0.2019 - val_accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2157 - accuracy: 0.9149 - val_loss: 0.1997 - val_accuracy: 0.9148\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1819 - accuracy: 0.9289 - val_loss: 0.2050 - val_accuracy: 0.9144\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1603 - accuracy: 0.9392 - val_loss: 0.1518 - val_accuracy: 0.9421\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1491 - accuracy: 0.9434 - val_loss: 0.1379 - val_accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1382 - accuracy: 0.9476 - val_loss: 0.1287 - val_accuracy: 0.9503\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1286 - accuracy: 0.9509 - val_loss: 0.1367 - val_accuracy: 0.9458\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1217 - accuracy: 0.9545 - val_loss: 0.1264 - val_accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1161 - accuracy: 0.9562 - val_loss: 0.1271 - val_accuracy: 0.9509\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2830 - accuracy: 0.8993 - val_loss: 0.2560 - val_accuracy: 0.9008\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2370 - accuracy: 0.9095 - val_loss: 0.2274 - val_accuracy: 0.9095\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2175 - accuracy: 0.9180 - val_loss: 0.2116 - val_accuracy: 0.9166\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2002 - accuracy: 0.9248 - val_loss: 0.1832 - val_accuracy: 0.9282\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1868 - accuracy: 0.9301 - val_loss: 0.1922 - val_accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1826 - accuracy: 0.9324 - val_loss: 0.1744 - val_accuracy: 0.9364\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1712 - accuracy: 0.9372 - val_loss: 0.1951 - val_accuracy: 0.9256\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1674 - accuracy: 0.9368 - val_loss: 0.1636 - val_accuracy: 0.9390\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1621 - accuracy: 0.9393 - val_loss: 0.1572 - val_accuracy: 0.9411\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1530 - accuracy: 0.9420 - val_loss: 0.1892 - val_accuracy: 0.9321\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "6 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 4, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4877 - accuracy: 0.7581 - val_loss: 0.4250 - val_accuracy: 0.7956\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4349 - accuracy: 0.7931 - val_loss: 0.4155 - val_accuracy: 0.8122\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4079 - accuracy: 0.8092 - val_loss: 0.3760 - val_accuracy: 0.8295\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3799 - accuracy: 0.8236 - val_loss: 0.3523 - val_accuracy: 0.8396\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3637 - accuracy: 0.8354 - val_loss: 0.3592 - val_accuracy: 0.8370\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3497 - accuracy: 0.8424 - val_loss: 0.3476 - val_accuracy: 0.8483\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3381 - accuracy: 0.8478 - val_loss: 0.3688 - val_accuracy: 0.8360\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3249 - accuracy: 0.8552 - val_loss: 0.3537 - val_accuracy: 0.8447\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3159 - accuracy: 0.8603 - val_loss: 0.3307 - val_accuracy: 0.8525\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3057 - accuracy: 0.8648 - val_loss: 0.3116 - val_accuracy: 0.8612\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[9, 0, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4192 - accuracy: 0.7991 - val_loss: 0.3295 - val_accuracy: 0.8469\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3116 - accuracy: 0.8642 - val_loss: 0.2534 - val_accuracy: 0.8895\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2636 - accuracy: 0.8915 - val_loss: 0.2799 - val_accuracy: 0.8832\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2377 - accuracy: 0.9047 - val_loss: 0.2091 - val_accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2093 - accuracy: 0.9159 - val_loss: 0.1918 - val_accuracy: 0.9205\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1981 - accuracy: 0.9226 - val_loss: 0.1940 - val_accuracy: 0.9221\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1858 - accuracy: 0.9276 - val_loss: 0.1798 - val_accuracy: 0.9285\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1765 - accuracy: 0.9306 - val_loss: 0.1766 - val_accuracy: 0.9293\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1650 - accuracy: 0.9350 - val_loss: 0.1734 - val_accuracy: 0.9275\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1596 - accuracy: 0.9380 - val_loss: 0.1696 - val_accuracy: 0.9307\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2627 - accuracy: 0.9007 - val_loss: 0.2230 - val_accuracy: 0.9133\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2062 - accuracy: 0.9238 - val_loss: 0.2011 - val_accuracy: 0.9294\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1680 - accuracy: 0.9381 - val_loss: 0.1422 - val_accuracy: 0.9449\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1557 - accuracy: 0.9428 - val_loss: 0.1579 - val_accuracy: 0.9397\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1480 - accuracy: 0.9456 - val_loss: 0.1701 - val_accuracy: 0.9446\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1396 - accuracy: 0.9489 - val_loss: 0.1337 - val_accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1315 - accuracy: 0.9515 - val_loss: 0.1691 - val_accuracy: 0.9408\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1303 - accuracy: 0.9519 - val_loss: 0.1215 - val_accuracy: 0.9553\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1213 - accuracy: 0.9546 - val_loss: 0.1213 - val_accuracy: 0.9560\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1174 - accuracy: 0.9569 - val_loss: 0.1196 - val_accuracy: 0.9534\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "7 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 5, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4956 - accuracy: 0.7474 - val_loss: 0.4072 - val_accuracy: 0.7996\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4048 - accuracy: 0.8098 - val_loss: 0.3844 - val_accuracy: 0.8070\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3679 - accuracy: 0.8306 - val_loss: 0.3434 - val_accuracy: 0.8406\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3338 - accuracy: 0.8484 - val_loss: 0.3125 - val_accuracy: 0.8511\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3153 - accuracy: 0.8579 - val_loss: 0.2973 - val_accuracy: 0.8659\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2990 - accuracy: 0.8661 - val_loss: 0.2864 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2883 - accuracy: 0.8730 - val_loss: 0.2767 - val_accuracy: 0.8766\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2740 - accuracy: 0.8787 - val_loss: 0.2611 - val_accuracy: 0.8843\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2666 - accuracy: 0.8821 - val_loss: 0.2575 - val_accuracy: 0.8853\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2546 - accuracy: 0.8891 - val_loss: 0.2735 - val_accuracy: 0.8804\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[8, 1, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.3609 - accuracy: 0.8371 - val_loss: 0.2815 - val_accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2612 - accuracy: 0.8927 - val_loss: 0.2220 - val_accuracy: 0.9106\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2253 - accuracy: 0.9110 - val_loss: 0.1906 - val_accuracy: 0.9234\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1941 - accuracy: 0.9242 - val_loss: 0.1791 - val_accuracy: 0.9264\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1695 - accuracy: 0.9358 - val_loss: 0.1511 - val_accuracy: 0.9417\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1562 - accuracy: 0.9400 - val_loss: 0.1663 - val_accuracy: 0.9367\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1448 - accuracy: 0.9453 - val_loss: 0.1383 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1349 - accuracy: 0.9500 - val_loss: 0.1373 - val_accuracy: 0.9471\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1275 - accuracy: 0.9526 - val_loss: 0.1264 - val_accuracy: 0.9527\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1170 - accuracy: 0.9554 - val_loss: 0.1364 - val_accuracy: 0.9472\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2801 - accuracy: 0.9066 - val_loss: 0.2080 - val_accuracy: 0.9290\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2009 - accuracy: 0.9308 - val_loss: 0.1667 - val_accuracy: 0.9398\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1707 - accuracy: 0.9394 - val_loss: 0.1568 - val_accuracy: 0.9451\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9452 - val_loss: 0.1461 - val_accuracy: 0.9495\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1428 - accuracy: 0.9508 - val_loss: 0.1461 - val_accuracy: 0.9482\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1299 - accuracy: 0.9540 - val_loss: 0.1339 - val_accuracy: 0.9545\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1240 - accuracy: 0.9558 - val_loss: 0.1306 - val_accuracy: 0.9553\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1172 - accuracy: 0.9586 - val_loss: 0.1239 - val_accuracy: 0.9549\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1102 - accuracy: 0.9600 - val_loss: 0.1177 - val_accuracy: 0.9554\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 0.1105 - val_accuracy: 0.9587\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "8 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[0, 3, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5222 - accuracy: 0.7531 - val_loss: 0.4374 - val_accuracy: 0.8026\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4337 - accuracy: 0.8088 - val_loss: 0.3884 - val_accuracy: 0.8295\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3984 - accuracy: 0.8247 - val_loss: 0.3997 - val_accuracy: 0.8314\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3779 - accuracy: 0.8344 - val_loss: 0.3554 - val_accuracy: 0.8403\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3597 - accuracy: 0.8425 - val_loss: 0.3444 - val_accuracy: 0.8511\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3466 - accuracy: 0.8476 - val_loss: 0.3466 - val_accuracy: 0.8421\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3324 - accuracy: 0.8569 - val_loss: 0.3301 - val_accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3219 - accuracy: 0.8615 - val_loss: 0.3154 - val_accuracy: 0.8619\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3096 - accuracy: 0.8674 - val_loss: 0.3122 - val_accuracy: 0.8637\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3028 - accuracy: 0.8700 - val_loss: 0.3121 - val_accuracy: 0.8637\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4987 - accuracy: 0.7403 - val_loss: 0.4051 - val_accuracy: 0.7913\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4073 - accuracy: 0.8079 - val_loss: 0.3531 - val_accuracy: 0.8324\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3653 - accuracy: 0.8316 - val_loss: 0.3452 - val_accuracy: 0.8314\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3396 - accuracy: 0.8461 - val_loss: 0.3202 - val_accuracy: 0.8540\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3262 - accuracy: 0.8534 - val_loss: 0.2998 - val_accuracy: 0.8573\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3096 - accuracy: 0.8588 - val_loss: 0.2951 - val_accuracy: 0.8601\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2999 - accuracy: 0.8639 - val_loss: 0.2913 - val_accuracy: 0.8651\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2926 - accuracy: 0.8693 - val_loss: 0.3019 - val_accuracy: 0.8609\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2793 - accuracy: 0.8754 - val_loss: 0.2716 - val_accuracy: 0.8752\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2713 - accuracy: 0.8793 - val_loss: 0.2820 - val_accuracy: 0.8707\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2360 - accuracy: 0.9110 - val_loss: 0.1811 - val_accuracy: 0.9280\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1653 - accuracy: 0.9385 - val_loss: 0.1557 - val_accuracy: 0.9401\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1413 - accuracy: 0.9494 - val_loss: 0.1205 - val_accuracy: 0.9551\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1231 - accuracy: 0.9563 - val_loss: 0.1085 - val_accuracy: 0.9604\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1135 - accuracy: 0.9590 - val_loss: 0.1098 - val_accuracy: 0.9610\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1031 - accuracy: 0.9629 - val_loss: 0.0925 - val_accuracy: 0.9655\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0956 - accuracy: 0.9658 - val_loss: 0.0992 - val_accuracy: 0.9644\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0910 - accuracy: 0.9668 - val_loss: 0.0976 - val_accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0848 - accuracy: 0.9700 - val_loss: 0.0902 - val_accuracy: 0.9660\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0809 - accuracy: 0.9709 - val_loss: 0.1012 - val_accuracy: 0.9684\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "9 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[1, 8, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3630 - accuracy: 0.8369 - val_loss: 0.2594 - val_accuracy: 0.8902\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2610 - accuracy: 0.8943 - val_loss: 0.2686 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2255 - accuracy: 0.9103 - val_loss: 0.1875 - val_accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1985 - accuracy: 0.9234 - val_loss: 0.1713 - val_accuracy: 0.9332\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1764 - accuracy: 0.9324 - val_loss: 0.1558 - val_accuracy: 0.9404\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1589 - accuracy: 0.9392 - val_loss: 0.1900 - val_accuracy: 0.9300\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1470 - accuracy: 0.9425 - val_loss: 0.1503 - val_accuracy: 0.9412\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1384 - accuracy: 0.9477 - val_loss: 0.1483 - val_accuracy: 0.9436\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1289 - accuracy: 0.9514 - val_loss: 0.1366 - val_accuracy: 0.9461\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1220 - accuracy: 0.9541 - val_loss: 0.1473 - val_accuracy: 0.9441\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 2, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4994 - accuracy: 0.7442 - val_loss: 0.4131 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4111 - accuracy: 0.8069 - val_loss: 0.3934 - val_accuracy: 0.8142\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3761 - accuracy: 0.8287 - val_loss: 0.3901 - val_accuracy: 0.8119\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3601 - accuracy: 0.8396 - val_loss: 0.3344 - val_accuracy: 0.8493\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3444 - accuracy: 0.8471 - val_loss: 0.3381 - val_accuracy: 0.8498\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3309 - accuracy: 0.8528 - val_loss: 0.3304 - val_accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3197 - accuracy: 0.8606 - val_loss: 0.3215 - val_accuracy: 0.8539\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3075 - accuracy: 0.8671 - val_loss: 0.3119 - val_accuracy: 0.8586\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2996 - accuracy: 0.8708 - val_loss: 0.3040 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2893 - accuracy: 0.8751 - val_loss: 0.3103 - val_accuracy: 0.8661\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.2757 - accuracy: 0.8991 - val_loss: 0.2182 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2065 - accuracy: 0.9175 - val_loss: 0.1709 - val_accuracy: 0.9336\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1647 - accuracy: 0.9370 - val_loss: 0.1503 - val_accuracy: 0.9425\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1421 - accuracy: 0.9473 - val_loss: 0.1578 - val_accuracy: 0.9359\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1287 - accuracy: 0.9529 - val_loss: 0.1139 - val_accuracy: 0.9605\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1137 - accuracy: 0.9598 - val_loss: 0.1023 - val_accuracy: 0.9673\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1078 - accuracy: 0.9607 - val_loss: 0.1040 - val_accuracy: 0.9608\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1010 - accuracy: 0.9643 - val_loss: 0.1006 - val_accuracy: 0.9660\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.0883 - val_accuracy: 0.9677\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0919 - accuracy: 0.9677 - val_loss: 0.0888 - val_accuracy: 0.9671\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 0~9 클래스 \n",
    "# 0클래스 결과값을 봤을 때, true-false모델을 통과한 0번 클래스가 772개인데 나머지 클래스들이 어디서 데이터가 누수됐는지 분석해보기\n",
    "\n",
    "class_accuracy = []\n",
    "first_TP_FP_TN_FN = []\n",
    "second_TP_FP_TN_FN = []\n",
    "third_TP_FP_TN_FN = []\n",
    "model_result_predict = []\n",
    "\n",
    "for i in range(0, class_length):\n",
    "    print(i, \"번째 클래스\")\n",
    "    # 첫번째 모델 -> 가장 유사한 클래스끼리 묶은 라벨\n",
    "    print(\"[model1] : 가장 유사한 클래스끼리 묶은 라벨\")\n",
    "    (x_train, y_train), (x_test, y_test) = getCifar10Data()\n",
    "    temp = getTopN(similar_wrong_predict_count[i], 2, i)\n",
    "    # 현재 클래스 index 추가 \n",
    "    temp.append(i)\n",
    "    print(temp)\n",
    "    (y_train, y_test) = reLabel(y_train, y_test, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model1 = makeModel()\n",
    "    model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model1.fit(x_train, y_train, epochs= 10, batch_size = 64, validation_data=(x_test, y_test))\n",
    "    first_predict = model1.predict(x_test)\n",
    "#     first_TP_FP.append(get_TP_FP(original_y_test, first_predict, i))\n",
    "#     first_TN_FN.append(get_TN_FN(original_y_test, first_predict, i))\n",
    "    first_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, first_predict, i))\n",
    "    \n",
    "    \n",
    "    # 두번째 모델 -> 가장 유사하지않은 클래스끼리 묶은 라벨\n",
    "    print(\"[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\")\n",
    "    (x_train2, y_train2), (x_test2, y_test2) = getCifar10Data()\n",
    "    temp = getBottomN(similar_wrong_predict_count[i], 3, i)\n",
    "    print(temp)\n",
    "\n",
    "    (y_train2, y_test2) = reLabel(y_train2, y_test2, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model2 = makeModel()\n",
    "    model2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model2.fit(x_train2, y_train2, epochs= 10, batch_size = 64, validation_data=(x_test2, y_test2))\n",
    "    second_predict = model2.predict(x_test2)\n",
    "#     second_TP_FP.append(get_TP_FP(original_y_test, second_predict, i))\n",
    "#     second_TN_FN.append(get_TN_FN(original_y_test, second_predict, i))\n",
    "    second_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, second_predict, i))\n",
    "    \n",
    "    # model 3\n",
    "    (x_train3, y_train3), (x_test3, y_test3) = getCifar10Data()\n",
    "    (y_train3, y_test3) = reLabel(y_train3, y_test3, i, i, i)\n",
    "    \n",
    "    model3 = makeModel()\n",
    "    model3.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model3.fit(x_train3, y_train3, epochs= 10, batch_size = 64, validation_data=(x_test3, y_test3))\n",
    "    third_predict = model3.predict(x_test3)\n",
    "    \n",
    "    third_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, third_predict, i))\n",
    "    \n",
    "    # 모델의 TP FP TN FN\n",
    "    model_result_predict.append(get_result_model_TP_FP_TN_FN(first_predict, second_predict, third_predict, original_y_test, i))\n",
    "    \n",
    "    # TODO: 마지막에 예를들어 클래스 0에 대해서 마지막에 클래스 0만 true로 리라벨링해서 한 번더 걸러주고 정학도 보기\n",
    "    \n",
    "    # 첫번째 모델에서 True 두번째 모델에서 False가 나온 모델\n",
    "#     class_accuracy.append(getRealTrueRatio(first_predict, second_predict, original_y_test,i))  \n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 :  0\n",
      "첫번째 모델에서 TP:  853\n",
      "첫번째 모델에서 FP:  1698\n",
      "첫번째 모델에서 TN:  7302\n",
      "첫번째 모델에서 FN:  147\n",
      "두번째 모델에서 TP:  35\n",
      "두번째 모델에서 FP:  3113\n",
      "두번째 모델에서 TN:  5887\n",
      "두번째 모델에서 FN:  965\n",
      "세번째 모델에서 TP:  691\n",
      "세번째 모델에서 FP:  105\n",
      "세번째 모델에서 TN:  8895\n",
      "세번째 모델에서 FN:  309\n",
      "모델 결과 TP:  658\n",
      "모델 결과 FP:  90\n",
      "모델 결과 TN:  8910\n",
      "모델 결과 FN:  342\n",
      "precision:  0.8796791443850267\n",
      "accuracy:  0.9568\n",
      "\n",
      "클래스 :  1\n",
      "첫번째 모델에서 TP:  965\n",
      "첫번째 모델에서 FP:  2161\n",
      "첫번째 모델에서 TN:  6839\n",
      "첫번째 모델에서 FN:  35\n",
      "두번째 모델에서 TP:  2\n",
      "두번째 모델에서 FP:  2026\n",
      "두번째 모델에서 TN:  6974\n",
      "두번째 모델에서 FN:  998\n",
      "세번째 모델에서 TP:  811\n",
      "세번째 모델에서 FP:  87\n",
      "세번째 모델에서 TN:  8913\n",
      "세번째 모델에서 FN:  189\n",
      "모델 결과 TP:  806\n",
      "모델 결과 FP:  80\n",
      "모델 결과 TN:  8920\n",
      "모델 결과 FN:  194\n",
      "precision:  0.909706546275395\n",
      "accuracy:  0.9726\n",
      "\n",
      "클래스 :  2\n",
      "첫번째 모델에서 TP:  636\n",
      "첫번째 모델에서 FP:  1907\n",
      "첫번째 모델에서 TN:  7093\n",
      "첫번째 모델에서 FN:  364\n",
      "두번째 모델에서 TP:  19\n",
      "두번째 모델에서 FP:  3005\n",
      "두번째 모델에서 TN:  5995\n",
      "두번째 모델에서 FN:  981\n",
      "세번째 모델에서 TP:  415\n",
      "세번째 모델에서 FP:  95\n",
      "세번째 모델에서 TN:  8905\n",
      "세번째 모델에서 FN:  585\n",
      "모델 결과 TP:  334\n",
      "모델 결과 FP:  59\n",
      "모델 결과 TN:  8941\n",
      "모델 결과 FN:  666\n",
      "precision:  0.8498727735368957\n",
      "accuracy:  0.9275\n",
      "\n",
      "클래스 :  3\n",
      "첫번째 모델에서 TP:  805\n",
      "첫번째 모델에서 FP:  2548\n",
      "첫번째 모델에서 TN:  6452\n",
      "첫번째 모델에서 FN:  195\n",
      "두번째 모델에서 TP:  34\n",
      "두번째 모델에서 FP:  2865\n",
      "두번째 모델에서 TN:  6135\n",
      "두번째 모델에서 FN:  966\n",
      "세번째 모델에서 TP:  247\n",
      "세번째 모델에서 FP:  89\n",
      "세번째 모델에서 TN:  8911\n",
      "세번째 모델에서 FN:  753\n",
      "모델 결과 TP:  236\n",
      "모델 결과 FP:  75\n",
      "모델 결과 TN:  8925\n",
      "모델 결과 FN:  764\n",
      "precision:  0.7588424437299035\n",
      "accuracy:  0.9161\n",
      "\n",
      "클래스 :  4\n",
      "첫번째 모델에서 TP:  770\n",
      "첫번째 모델에서 FP:  2021\n",
      "첫번째 모델에서 TN:  6979\n",
      "첫번째 모델에서 FN:  230\n",
      "두번째 모델에서 TP:  9\n",
      "두번째 모델에서 FP:  2924\n",
      "두번째 모델에서 TN:  6076\n",
      "두번째 모델에서 FN:  991\n",
      "세번째 모델에서 TP:  619\n",
      "세번째 모델에서 FP:  240\n",
      "세번째 모델에서 TN:  8760\n",
      "세번째 모델에서 FN:  381\n",
      "모델 결과 TP:  542\n",
      "모델 결과 FP:  147\n",
      "모델 결과 TN:  8853\n",
      "모델 결과 FN:  458\n",
      "precision:  0.7866473149492017\n",
      "accuracy:  0.9395\n",
      "\n",
      "클래스 :  5\n",
      "첫번째 모델에서 TP:  867\n",
      "첫번째 모델에서 FP:  2079\n",
      "첫번째 모델에서 TN:  6921\n",
      "첫번째 모델에서 FN:  133\n",
      "두번째 모델에서 TP:  32\n",
      "두번째 모델에서 FP:  3119\n",
      "두번째 모델에서 TN:  5881\n",
      "두번째 모델에서 FN:  968\n",
      "세번째 모델에서 TP:  369\n",
      "세번째 모델에서 FP:  48\n",
      "세번째 모델에서 TN:  8952\n",
      "세번째 모델에서 FN:  631\n",
      "모델 결과 TP:  353\n",
      "모델 결과 FP:  41\n",
      "모델 결과 TN:  8959\n",
      "모델 결과 FN:  647\n",
      "precision:  0.8959390862944162\n",
      "accuracy:  0.9312\n",
      "\n",
      "클래스 :  6\n",
      "첫번째 모델에서 TP:  836\n",
      "첫번째 모델에서 FP:  1640\n",
      "첫번째 모델에서 TN:  7360\n",
      "첫번째 모델에서 FN:  164\n",
      "두번째 모델에서 TP:  11\n",
      "두번째 모델에서 FP:  2798\n",
      "두번째 모델에서 TN:  6202\n",
      "두번째 모델에서 FN:  989\n",
      "세번째 모델에서 TP:  674\n",
      "세번째 모델에서 FP:  140\n",
      "세번째 모델에서 TN:  8860\n",
      "세번째 모델에서 FN:  326\n",
      "모델 결과 TP:  634\n",
      "모델 결과 FP:  108\n",
      "모델 결과 TN:  8892\n",
      "모델 결과 FN:  366\n",
      "precision:  0.8544474393530997\n",
      "accuracy:  0.9526\n",
      "\n",
      "클래스 :  7\n",
      "첫번째 모델에서 TP:  834\n",
      "첫번째 모델에서 FP:  1706\n",
      "첫번째 모델에서 TN:  7294\n",
      "첫번째 모델에서 FN:  166\n",
      "두번째 모델에서 TP:  5\n",
      "두번째 모델에서 FP:  2891\n",
      "두번째 모델에서 TN:  6109\n",
      "두번째 모델에서 FN:  995\n",
      "세번째 모델에서 TP:  711\n",
      "세번째 모델에서 FP:  124\n",
      "세번째 모델에서 TN:  8876\n",
      "세번째 모델에서 FN:  289\n",
      "모델 결과 TP:  658\n",
      "모델 결과 FP:  96\n",
      "모델 결과 TN:  8904\n",
      "모델 결과 FN:  342\n",
      "precision:  0.8726790450928382\n",
      "accuracy:  0.9562\n",
      "\n",
      "클래스 :  8\n",
      "첫번째 모델에서 TP:  875\n",
      "첫번째 모델에서 FP:  1392\n",
      "첫번째 모델에서 TN:  7608\n",
      "첫번째 모델에서 FN:  125\n",
      "두번째 모델에서 TP:  11\n",
      "두번째 모델에서 FP:  2756\n",
      "두번째 모델에서 TN:  6244\n",
      "두번째 모델에서 FN:  989\n",
      "세번째 모델에서 TP:  868\n",
      "세번째 모델에서 FP:  184\n",
      "세번째 모델에서 TN:  8816\n",
      "세번째 모델에서 FN:  132\n",
      "모델 결과 TP:  800\n",
      "모델 결과 FP:  132\n",
      "모델 결과 TN:  8868\n",
      "모델 결과 FN:  200\n",
      "precision:  0.8583690987124464\n",
      "accuracy:  0.9668\n",
      "\n",
      "클래스 :  9\n",
      "첫번째 모델에서 TP:  943\n",
      "첫번째 모델에서 FP:  2264\n",
      "첫번째 모델에서 TN:  6736\n",
      "첫번째 모델에서 FN:  57\n",
      "두번째 모델에서 TP:  33\n",
      "두번째 모델에서 FP:  3286\n",
      "두번째 모델에서 TN:  5714\n",
      "두번째 모델에서 FN:  967\n",
      "세번째 모델에서 TP:  844\n",
      "세번째 모델에서 FP:  173\n",
      "세번째 모델에서 TN:  8827\n",
      "세번째 모델에서 FN:  156\n",
      "모델 결과 TP:  807\n",
      "모델 결과 FP:  112\n",
      "모델 결과 TN:  8888\n",
      "모델 결과 FN:  193\n",
      "precision:  0.8781284004352558\n",
      "accuracy:  0.9695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"클래스 : \",i)\n",
    "    print(\"첫번째 모델에서 TP: \", len(first_TP_FP_TN_FN[i][0]))\n",
    "    print(\"첫번째 모델에서 FP: \", len(first_TP_FP_TN_FN[i][1]))\n",
    "    print(\"첫번째 모델에서 TN: \", len(first_TP_FP_TN_FN[i][2]))\n",
    "    print(\"첫번째 모델에서 FN: \", len(first_TP_FP_TN_FN[i][3]))\n",
    "\n",
    "    print(\"두번째 모델에서 TP: \", len(second_TP_FP_TN_FN[i][0]))\n",
    "    print(\"두번째 모델에서 FP: \", len(second_TP_FP_TN_FN[i][1]))\n",
    "    print(\"두번째 모델에서 TN: \", len(second_TP_FP_TN_FN[i][2]))\n",
    "    print(\"두번째 모델에서 FN: \", len(second_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"세번째 모델에서 TP: \", len(third_TP_FP_TN_FN[i][0]))\n",
    "    print(\"세번째 모델에서 FP: \", len(third_TP_FP_TN_FN[i][1]))\n",
    "    print(\"세번째 모델에서 TN: \", len(third_TP_FP_TN_FN[i][2]))\n",
    "    print(\"세번째 모델에서 FN: \", len(third_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"모델 결과 TP: \", len(model_result_predict[i][0]))\n",
    "    print(\"모델 결과 FP: \", len(model_result_predict[i][1]))\n",
    "    print(\"모델 결과 TN: \", len(model_result_predict[i][2]))\n",
    "    print(\"모델 결과 FN: \", len(model_result_predict[i][3]))\n",
    "    \n",
    "    # precision = TP / (TP + FP)\n",
    "    print(\"precision: \", (len(model_result_predict[i][0]) / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]))))\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy: \", ((len(model_result_predict[i][0]) + len(model_result_predict[i][2]))\n",
    "                               / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3]))))\n",
    "    print(\"\")\n",
    "\n",
    "    #     print(\"true-false를 통과한 개수 : \", 1000 - (len(first_false[i]) + len(second_true[i])) )\n",
    "#     print(\"precision: \", len(first_TP_TN[i][0])/(len(first_TP_TN[i][0]) + len(second_FP_FN[i][0])))\n",
    "#     print(\"accuracy: \", (len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]))\n",
    "#           /len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]) + len(second_FP_FN[0][i]) + len(second_FP_FN[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
