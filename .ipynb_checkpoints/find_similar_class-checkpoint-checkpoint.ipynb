{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEWkBMJpNvd_",
    "outputId": "e010c54f-38c1-4abd-c7e4-d29e7e531432"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(original_x_train, original_y_train), (original_x_test, original_y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "DG5AhMOLjbeb"
   },
   "outputs": [],
   "source": [
    "original_x_train = original_x_train / 255.0\n",
    "original_x_test = original_x_test / 255.0\n",
    "\n",
    "original_y_train = keras.utils.to_categorical(original_y_train)\n",
    "original_y_test = keras.utils.to_categorical(original_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJRl4tKVolc",
    "outputId": "6acbf001-2b2a-4654-f644-3bacf4a641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 5ms/step - loss: 1.8257 - accuracy: 0.3184 - val_loss: 1.4268 - val_accuracy: 0.4781\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.4529 - accuracy: 0.4763 - val_loss: 1.2333 - val_accuracy: 0.5552\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.3352 - accuracy: 0.5219 - val_loss: 1.2055 - val_accuracy: 0.5701\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2530 - accuracy: 0.5593 - val_loss: 1.0595 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1948 - accuracy: 0.5821 - val_loss: 1.0394 - val_accuracy: 0.6357\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1602 - accuracy: 0.5909 - val_loss: 1.0463 - val_accuracy: 0.6319\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1120 - accuracy: 0.6092 - val_loss: 0.9515 - val_accuracy: 0.6616\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0889 - accuracy: 0.6182 - val_loss: 0.9330 - val_accuracy: 0.6792\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0652 - accuracy: 0.6273 - val_loss: 0.9116 - val_accuracy: 0.6854\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.0308 - accuracy: 0.6414 - val_loss: 0.8988 - val_accuracy: 0.6860\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.MaxPooling2D((2, 2)))\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "original_model.add(layers.Flatten())\n",
    "original_model.add(layers.Dropout(0.25))\n",
    "\n",
    "original_model.add(layers.Dense(64, activation='relu'))\n",
    "original_model.add(layers.Dropout(0.5))\n",
    "original_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_0 = original_model.fit(original_x_train, original_y_train, epochs= 10, batch_size= 64, validation_data=(original_x_test, original_y_test))\n",
    "# loss: 0.9075 - accuracy: 0.6951 - val_loss: 0.8743 - val_accuracy: 0.7026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvzfjR4SWu6i",
    "outputId": "a168ca0a-a8f4-4c05-8e59-18fa0d285a26",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "[0, 21, 117, 20, 38, 8, 13, 16, 98, 61]\n",
      "[5, 0, 3, 12, 4, 3, 24, 3, 18, 120]\n",
      "[40, 8, 0, 85, 130, 56, 117, 29, 15, 12]\n",
      "[5, 4, 57, 0, 68, 177, 115, 33, 18, 19]\n",
      "[16, 2, 40, 78, 0, 21, 96, 89, 8, 5]\n",
      "[1, 1, 55, 250, 57, 0, 36, 46, 4, 8]\n",
      "[3, 1, 35, 65, 30, 8, 0, 4, 4, 4]\n",
      "[5, 0, 40, 61, 63, 70, 11, 0, 6, 14]\n",
      "[36, 29, 15, 34, 11, 1, 15, 1, 0, 39]\n",
      "[7, 48, 12, 24, 7, 8, 13, 4, 27, 0]\n"
     ]
    }
   ],
   "source": [
    "# 잘못예측한 데이터 찾는 코드\n",
    "# original_label, predict_label\n",
    "wrong_predict = []\n",
    "wrong_predict_cnt = 0\n",
    "class_length = 10\n",
    "\n",
    "model_predict = original_model.predict(original_x_test)\n",
    "\n",
    "for i in range(len(original_y_test)):\n",
    "  predict_idx, original_idx = 0, 0\n",
    "  for j in range(1,10):\n",
    "    if model_predict[i][j] > model_predict[i][predict_idx]:\n",
    "      predict_idx = j\n",
    "    if original_y_test[i][j] > original_y_test[i][original_idx]:\n",
    "      original_idx = j\n",
    "\n",
    "  if predict_idx != original_idx:\n",
    "    wrong_predict.append([original_idx, predict_idx])\n",
    "\n",
    "similar_wrong_predict_count = [[0 for j in range(class_length)] for i in range(class_length)]\n",
    "for i in range(len(wrong_predict)):\n",
    "  similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] = similar_wrong_predict_count[wrong_predict[i][0]][wrong_predict[i][1]] + 1 \n",
    "\n",
    "for i in range(class_length):\n",
    "  print(similar_wrong_predict_count[i])\n",
    "\n",
    "# result\n",
    "# [0, 27, 28, 8, 5, 1, 7, 8, 59, 34]\n",
    "# [16, 0, 0, 6, 1, 3, 3, 1, 18, 51]\n",
    "# [101, 9, 0, 36, 93, 69, 60, 29, 18, 14]\n",
    "# [45, 22, 73, 0, 58, 196, 88, 38, 28, 30]\n",
    "# [40, 4, 71, 39, 0, 26, 66, 94, 11, 3]\n",
    "# [20, 7, 47, 146, 48, 0, 24, 65, 10, 11]\n",
    "# [12, 7, 48, 41, 33, 17, 0, 7, 13, 10]\n",
    "# [23, 2, 32, 23, 36, 50, 5, 0, 4, 15]\n",
    "# [78, 39, 4, 5, 3, 4, 4, 5, 0, 19]\n",
    "# [31, 128, 5, 6, 4, 3, 3, 10, 21, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "PXIQquThxGkf"
   },
   "outputs": [],
   "source": [
    "# 가장 큰 값 top 3의 index를 가져와야 함 (cur_idx 제외)\n",
    "def getTopN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  top_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(top_idx) == n:\n",
    "      break;\n",
    "    max_num = -1\n",
    "    max_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if max_num < tmp[j]:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                max_num = tmp[j]\n",
    "                max_idx = j\n",
    "    \n",
    "    if max_idx != -1:\n",
    "      top_idx.append(max_idx)\n",
    "      visited.append(max_idx)\n",
    "  return top_idx\n",
    "\n",
    "# 가장 작은 값 bottom 3의 index를 가져와야 함  (cur_idx 제외)\n",
    "def getBottomN(target_list, n, cur_idx):\n",
    "  tmp = target_list.copy()\n",
    "  visited = []\n",
    "  bottom_idx = []\n",
    "  for i in range(0,10):\n",
    "    if len(bottom_idx) == n:\n",
    "      break;\n",
    "    min_num = 1e9\n",
    "    min_idx = -1\n",
    "    for j in range(0,10):\n",
    "        if tmp[j] < min_num:\n",
    "            if j == cur_idx:\n",
    "                continue\n",
    "            if j in visited:\n",
    "                continue\n",
    "            else:  \n",
    "                min_num = tmp[j]\n",
    "                min_idx = j\n",
    "    \n",
    "    if min_idx != -1:\n",
    "      bottom_idx.append(min_idx)\n",
    "      visited.append(min_idx)\n",
    "  return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "xw4-dk8EBhqV"
   },
   "outputs": [],
   "source": [
    "# cifar10 데이터 가져오는 함수\n",
    "def getCifar10Data():\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train / 255.0\n",
    "  x_test = x_test / 255.0\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# a, b, c로 다시 라벨링\n",
    "def reLabel(y_train, y_test, a, b, c):\n",
    "  for i in range(len(y_train)):\n",
    "    if y_train[i] == a or y_train[i] == b or y_train[i] == c:\n",
    "      y_train[i] = 1\n",
    "    else:\n",
    "      y_train[i] = 0    \n",
    "  \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == a or y_test[i] == b or y_test[i] == c:\n",
    "      y_test[i] = 1\n",
    "    else:\n",
    "      y_test[i] = 0\n",
    "  \n",
    "  return y_train, y_test\n",
    "\n",
    "(model1_x_train, model1_y_train), (model1_x_test, model1_y_test) = getCifar10Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "4bb4bjAnNxa3"
   },
   "outputs": [],
   "source": [
    "# model 만드는 함수 \n",
    "def makeModel():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Bxau2L_U9toH"
   },
   "outputs": [],
   "source": [
    "# # 모델의 결과가 true인 predict index 반환함수\n",
    "# def get_TP_FP(y_test, predict, target_idx):\n",
    "#     TP = []\n",
    "#     FP = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 1:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TP.append(i)\n",
    "#             else:\n",
    "#                 FP.append(i)\n",
    "#     return TP, FP\n",
    "\n",
    "# # 모델의 결과가 false인 predict index 반환함수\n",
    "# def get_TN_FN(y_test, predict, target_idx):\n",
    "#     TN = []\n",
    "#     FN = []\n",
    "#     for i in range(len(y_test)):\n",
    "#         if predict[i].argmax(axis = -1) == 0:\n",
    "#             idx = -1\n",
    "#             for j in range(10):\n",
    "#                 if y_test[i][j] == 1:\n",
    "#                     idx = j\n",
    "#                     break\n",
    "#             if idx == target_idx:\n",
    "#                 TN.append(i)\n",
    "#             else:\n",
    "#                 FN.append(i)\n",
    "#     return TN, FN\n",
    "\n",
    "def get_TP_FP_TN_FN(y_test, predict, target_idx):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "                break\n",
    "                \n",
    "        if predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        elif predict[i].argmax(axis = -1) == 0:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "            \n",
    "    return TN, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_model_TP_FP_TN_FN(first_predict, second_predict, y_test, target_idx):\n",
    "    TP, FP, TN, FN = [],[],[],[]\n",
    "    for i in range(len(y_test)):\n",
    "        idx = -1\n",
    "        for j in range(10):\n",
    "            if y_test[i][j] == 1:\n",
    "                idx = j\n",
    "        if first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 0:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        elif first_predict[i].argmax(axis = -1) == 0 and second_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "        elif first_predict[i].argmax(axis = -1) == 0 and second_predict[i].argmax(axis = -1) == 0:\n",
    "            if idx == target_idx:\n",
    "                TP.append(i)\n",
    "            else:\n",
    "                FP.append(i)\n",
    "        elif first_predict[i].argmax(axis = -1) == 1 and second_predict[i].argmax(axis = -1) == 1:\n",
    "            if idx == target_idx:\n",
    "                FN.append(i)\n",
    "            else:\n",
    "                TN.append(i)\n",
    "    return TP, FP, TN, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MmmbZyZwFa-",
    "outputId": "6e61ca8b-9629-45f9-d032-a2e072f6c2ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[2, 8, 0]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4642 - accuracy: 0.7937 - val_loss: 0.3812 - val_accuracy: 0.8374\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3768 - accuracy: 0.8439 - val_loss: 0.3322 - val_accuracy: 0.8589\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3467 - accuracy: 0.8572 - val_loss: 0.3155 - val_accuracy: 0.8681\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3237 - accuracy: 0.8676 - val_loss: 0.3161 - val_accuracy: 0.8708\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3064 - accuracy: 0.8751 - val_loss: 0.2912 - val_accuracy: 0.8813\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2877 - accuracy: 0.8833 - val_loss: 0.2847 - val_accuracy: 0.8825\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2766 - accuracy: 0.8896 - val_loss: 0.2832 - val_accuracy: 0.8827\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2695 - accuracy: 0.8906 - val_loss: 0.2725 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2576 - accuracy: 0.8966 - val_loss: 0.2568 - val_accuracy: 0.8921\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2485 - accuracy: 0.9001 - val_loss: 0.2650 - val_accuracy: 0.8896\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 6, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4886 - accuracy: 0.7352 - val_loss: 0.4206 - val_accuracy: 0.7835\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4270 - accuracy: 0.7875 - val_loss: 0.4008 - val_accuracy: 0.8047\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3978 - accuracy: 0.8070 - val_loss: 0.3624 - val_accuracy: 0.8302\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3762 - accuracy: 0.8215 - val_loss: 0.3510 - val_accuracy: 0.8335\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3575 - accuracy: 0.8331 - val_loss: 0.3419 - val_accuracy: 0.8354\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3451 - accuracy: 0.8392 - val_loss: 0.3274 - val_accuracy: 0.8448\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3277 - accuracy: 0.8486 - val_loss: 0.3277 - val_accuracy: 0.8464\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3158 - accuracy: 0.8561 - val_loss: 0.3246 - val_accuracy: 0.8427\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3067 - accuracy: 0.8612 - val_loss: 0.3068 - val_accuracy: 0.8582\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2956 - accuracy: 0.8669 - val_loss: 0.3003 - val_accuracy: 0.8588\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "1 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[9, 6, 1]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4620 - accuracy: 0.7855 - val_loss: 0.3322 - val_accuracy: 0.8604\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3255 - accuracy: 0.8655 - val_loss: 0.3092 - val_accuracy: 0.8589\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2840 - accuracy: 0.8846 - val_loss: 0.2585 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2612 - accuracy: 0.8961 - val_loss: 0.2363 - val_accuracy: 0.9058\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2423 - accuracy: 0.9043 - val_loss: 0.2378 - val_accuracy: 0.9032\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2254 - accuracy: 0.9105 - val_loss: 0.2071 - val_accuracy: 0.9176\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2182 - accuracy: 0.9122 - val_loss: 0.1972 - val_accuracy: 0.9209\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1993 - accuracy: 0.9230 - val_loss: 0.2404 - val_accuracy: 0.8966\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1914 - accuracy: 0.9235 - val_loss: 0.1898 - val_accuracy: 0.9235\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1877 - accuracy: 0.9267 - val_loss: 0.2143 - val_accuracy: 0.9092\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[2, 5, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5058 - accuracy: 0.7380 - val_loss: 0.4278 - val_accuracy: 0.7893\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4369 - accuracy: 0.7867 - val_loss: 0.4009 - val_accuracy: 0.8152\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4088 - accuracy: 0.8026 - val_loss: 0.3703 - val_accuracy: 0.8210\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3897 - accuracy: 0.8140 - val_loss: 0.3651 - val_accuracy: 0.8348\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3663 - accuracy: 0.8281 - val_loss: 0.3737 - val_accuracy: 0.8314\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3521 - accuracy: 0.8369 - val_loss: 0.3410 - val_accuracy: 0.8453\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3377 - accuracy: 0.8453 - val_loss: 0.3248 - val_accuracy: 0.8546\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3269 - accuracy: 0.8517 - val_loss: 0.3225 - val_accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3153 - accuracy: 0.8587 - val_loss: 0.3101 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3085 - accuracy: 0.8621 - val_loss: 0.3176 - val_accuracy: 0.8564\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "2 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[4, 6, 2]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4819 - accuracy: 0.7669 - val_loss: 0.4196 - val_accuracy: 0.8060\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4119 - accuracy: 0.8102 - val_loss: 0.3678 - val_accuracy: 0.8361\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3755 - accuracy: 0.8319 - val_loss: 0.3542 - val_accuracy: 0.8405\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3548 - accuracy: 0.8440 - val_loss: 0.3391 - val_accuracy: 0.8477\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3384 - accuracy: 0.8518 - val_loss: 0.3253 - val_accuracy: 0.8607\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3218 - accuracy: 0.8592 - val_loss: 0.3102 - val_accuracy: 0.8622\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3064 - accuracy: 0.8688 - val_loss: 0.3011 - val_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2942 - accuracy: 0.8743 - val_loss: 0.3048 - val_accuracy: 0.8697\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2824 - accuracy: 0.8801 - val_loss: 0.3104 - val_accuracy: 0.8639\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2718 - accuracy: 0.8858 - val_loss: 0.2908 - val_accuracy: 0.8724\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3496 - accuracy: 0.8421 - val_loss: 0.2602 - val_accuracy: 0.8943\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2578 - accuracy: 0.8948 - val_loss: 0.2256 - val_accuracy: 0.9076\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2169 - accuracy: 0.9144 - val_loss: 0.1862 - val_accuracy: 0.9245\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1892 - accuracy: 0.9254 - val_loss: 0.1589 - val_accuracy: 0.9365\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1667 - accuracy: 0.9355 - val_loss: 0.1451 - val_accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1510 - accuracy: 0.9424 - val_loss: 0.1419 - val_accuracy: 0.9455\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1379 - accuracy: 0.9479 - val_loss: 0.1275 - val_accuracy: 0.9519\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1327 - accuracy: 0.9494 - val_loss: 0.1287 - val_accuracy: 0.9495\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1231 - accuracy: 0.9536 - val_loss: 0.1261 - val_accuracy: 0.9521\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1181 - accuracy: 0.9549 - val_loss: 0.1558 - val_accuracy: 0.9407\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "3 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[5, 6, 3]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4566 - accuracy: 0.7667 - val_loss: 0.3911 - val_accuracy: 0.8148\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3750 - accuracy: 0.8307 - val_loss: 0.3381 - val_accuracy: 0.8472\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3413 - accuracy: 0.8499 - val_loss: 0.3252 - val_accuracy: 0.8548\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3202 - accuracy: 0.8590 - val_loss: 0.3026 - val_accuracy: 0.8664\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3017 - accuracy: 0.8686 - val_loss: 0.3044 - val_accuracy: 0.8648\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2889 - accuracy: 0.8772 - val_loss: 0.2852 - val_accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2789 - accuracy: 0.8799 - val_loss: 0.2744 - val_accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2669 - accuracy: 0.8863 - val_loss: 0.2981 - val_accuracy: 0.8717\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2593 - accuracy: 0.8911 - val_loss: 0.3089 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2490 - accuracy: 0.8945 - val_loss: 0.2538 - val_accuracy: 0.8926\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 0, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3762 - accuracy: 0.8345 - val_loss: 0.3292 - val_accuracy: 0.8528\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2931 - accuracy: 0.8790 - val_loss: 0.2622 - val_accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2611 - accuracy: 0.8932 - val_loss: 0.2423 - val_accuracy: 0.8987\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2424 - accuracy: 0.9023 - val_loss: 0.2263 - val_accuracy: 0.9100\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2247 - accuracy: 0.9087 - val_loss: 0.2635 - val_accuracy: 0.8919\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2103 - accuracy: 0.9163 - val_loss: 0.2108 - val_accuracy: 0.9145\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2014 - accuracy: 0.9212 - val_loss: 0.1914 - val_accuracy: 0.9242\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1905 - accuracy: 0.9247 - val_loss: 0.1896 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1851 - accuracy: 0.9278 - val_loss: 0.2022 - val_accuracy: 0.9204\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1774 - accuracy: 0.9306 - val_loss: 0.1836 - val_accuracy: 0.9281\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "4 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[6, 7, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4861 - accuracy: 0.7573 - val_loss: 0.4236 - val_accuracy: 0.7987\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4140 - accuracy: 0.8077 - val_loss: 0.3740 - val_accuracy: 0.8293\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3717 - accuracy: 0.8336 - val_loss: 0.3827 - val_accuracy: 0.8144\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3455 - accuracy: 0.8465 - val_loss: 0.3285 - val_accuracy: 0.8567\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3225 - accuracy: 0.8602 - val_loss: 0.3263 - val_accuracy: 0.8414\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3062 - accuracy: 0.8673 - val_loss: 0.2938 - val_accuracy: 0.8739\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2938 - accuracy: 0.8752 - val_loss: 0.2829 - val_accuracy: 0.8793\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2846 - accuracy: 0.8793 - val_loss: 0.2873 - val_accuracy: 0.8769\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2746 - accuracy: 0.8821 - val_loss: 0.2641 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2648 - accuracy: 0.8883 - val_loss: 0.2764 - val_accuracy: 0.8823\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 9, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3534 - accuracy: 0.8425 - val_loss: 0.2597 - val_accuracy: 0.8893\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2579 - accuracy: 0.8919 - val_loss: 0.2308 - val_accuracy: 0.9009\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2150 - accuracy: 0.9152 - val_loss: 0.1808 - val_accuracy: 0.9280\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1859 - accuracy: 0.9287 - val_loss: 0.1655 - val_accuracy: 0.9309\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1711 - accuracy: 0.9349 - val_loss: 0.1445 - val_accuracy: 0.9447\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1500 - accuracy: 0.9425 - val_loss: 0.1393 - val_accuracy: 0.9484\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1395 - accuracy: 0.9479 - val_loss: 0.1338 - val_accuracy: 0.9489\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1325 - accuracy: 0.9490 - val_loss: 0.1394 - val_accuracy: 0.9469\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1227 - accuracy: 0.9537 - val_loss: 0.1327 - val_accuracy: 0.9472\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1156 - accuracy: 0.9565 - val_loss: 0.1638 - val_accuracy: 0.9411\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "5 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 4, 5]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4932 - accuracy: 0.7479 - val_loss: 0.4334 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4351 - accuracy: 0.7866 - val_loss: 0.3991 - val_accuracy: 0.8053\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4102 - accuracy: 0.8024 - val_loss: 0.4254 - val_accuracy: 0.8108\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3940 - accuracy: 0.8119 - val_loss: 0.4067 - val_accuracy: 0.7949\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3767 - accuracy: 0.8229 - val_loss: 0.3845 - val_accuracy: 0.8048\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3630 - accuracy: 0.8319 - val_loss: 0.3516 - val_accuracy: 0.8350\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3473 - accuracy: 0.8422 - val_loss: 0.3611 - val_accuracy: 0.8326\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3337 - accuracy: 0.8486 - val_loss: 0.3496 - val_accuracy: 0.8445\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3239 - accuracy: 0.8549 - val_loss: 0.3207 - val_accuracy: 0.8597\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3092 - accuracy: 0.8622 - val_loss: 0.3502 - val_accuracy: 0.8423\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[0, 1, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3623 - accuracy: 0.8380 - val_loss: 0.2715 - val_accuracy: 0.8833\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2812 - accuracy: 0.8817 - val_loss: 0.2646 - val_accuracy: 0.8927\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2495 - accuracy: 0.9003 - val_loss: 0.2211 - val_accuracy: 0.9094\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2289 - accuracy: 0.9093 - val_loss: 0.2109 - val_accuracy: 0.9140\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2169 - accuracy: 0.9147 - val_loss: 0.1979 - val_accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2005 - accuracy: 0.9201 - val_loss: 0.1877 - val_accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1915 - accuracy: 0.9255 - val_loss: 0.1899 - val_accuracy: 0.9274\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1833 - accuracy: 0.9281 - val_loss: 0.1783 - val_accuracy: 0.9306\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1748 - accuracy: 0.9314 - val_loss: 0.1810 - val_accuracy: 0.9310\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1678 - accuracy: 0.9350 - val_loss: 0.1728 - val_accuracy: 0.9327\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "6 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[3, 2, 6]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5029 - accuracy: 0.7337 - val_loss: 0.4390 - val_accuracy: 0.7758\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4436 - accuracy: 0.7801 - val_loss: 0.4305 - val_accuracy: 0.7766\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4127 - accuracy: 0.8012 - val_loss: 0.3987 - val_accuracy: 0.8107\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3888 - accuracy: 0.8145 - val_loss: 0.3722 - val_accuracy: 0.8207\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3743 - accuracy: 0.8215 - val_loss: 0.3659 - val_accuracy: 0.8231\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3613 - accuracy: 0.8302 - val_loss: 0.3578 - val_accuracy: 0.8376\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3475 - accuracy: 0.8371 - val_loss: 0.3488 - val_accuracy: 0.8359\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3346 - accuracy: 0.8445 - val_loss: 0.3412 - val_accuracy: 0.8449\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3239 - accuracy: 0.8504 - val_loss: 0.3217 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3152 - accuracy: 0.8546 - val_loss: 0.3292 - val_accuracy: 0.8428\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 0, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5235 - accuracy: 0.7418 - val_loss: 0.4949 - val_accuracy: 0.7679\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4584 - accuracy: 0.7885 - val_loss: 0.4483 - val_accuracy: 0.7943\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4168 - accuracy: 0.8152 - val_loss: 0.3782 - val_accuracy: 0.8353\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3771 - accuracy: 0.8372 - val_loss: 0.3501 - val_accuracy: 0.8481\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3499 - accuracy: 0.8511 - val_loss: 0.3435 - val_accuracy: 0.8557\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3309 - accuracy: 0.8604 - val_loss: 0.3645 - val_accuracy: 0.8504\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3130 - accuracy: 0.8683 - val_loss: 0.3273 - val_accuracy: 0.8606\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2992 - accuracy: 0.8754 - val_loss: 0.3129 - val_accuracy: 0.8667\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2886 - accuracy: 0.8808 - val_loss: 0.3295 - val_accuracy: 0.8625\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2761 - accuracy: 0.8854 - val_loss: 0.3289 - val_accuracy: 0.8717\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "7 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[5, 4, 7]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4925 - accuracy: 0.7476 - val_loss: 0.4355 - val_accuracy: 0.7836\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4014 - accuracy: 0.8084 - val_loss: 0.3844 - val_accuracy: 0.8052\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3565 - accuracy: 0.8356 - val_loss: 0.3276 - val_accuracy: 0.8480\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3341 - accuracy: 0.8477 - val_loss: 0.3057 - val_accuracy: 0.8591\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3141 - accuracy: 0.8601 - val_loss: 0.2916 - val_accuracy: 0.8687\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3031 - accuracy: 0.8657 - val_loss: 0.2931 - val_accuracy: 0.8686\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2924 - accuracy: 0.8699 - val_loss: 0.2862 - val_accuracy: 0.8705\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2801 - accuracy: 0.8756 - val_loss: 0.2682 - val_accuracy: 0.8790\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2707 - accuracy: 0.8816 - val_loss: 0.2809 - val_accuracy: 0.8735\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2630 - accuracy: 0.8846 - val_loss: 0.2683 - val_accuracy: 0.8821\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[1, 0, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3737 - accuracy: 0.8313 - val_loss: 0.2994 - val_accuracy: 0.8686\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2875 - accuracy: 0.8802 - val_loss: 0.2518 - val_accuracy: 0.8962\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2544 - accuracy: 0.8975 - val_loss: 0.2995 - val_accuracy: 0.8853\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2394 - accuracy: 0.9052 - val_loss: 0.2487 - val_accuracy: 0.9044\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2231 - accuracy: 0.9104 - val_loss: 0.2199 - val_accuracy: 0.9198\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2128 - accuracy: 0.9159 - val_loss: 0.2353 - val_accuracy: 0.9079\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2009 - accuracy: 0.9208 - val_loss: 0.2092 - val_accuracy: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1937 - accuracy: 0.9245 - val_loss: 0.1857 - val_accuracy: 0.9259\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1823 - accuracy: 0.9291 - val_loss: 0.1892 - val_accuracy: 0.9288\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1741 - accuracy: 0.9313 - val_loss: 0.1845 - val_accuracy: 0.9288\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "===============================================================================================\n",
      "8 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[9, 0, 8]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4016 - accuracy: 0.8152 - val_loss: 0.3627 - val_accuracy: 0.8427\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3192 - accuracy: 0.8636 - val_loss: 0.3481 - val_accuracy: 0.8359\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2811 - accuracy: 0.8842 - val_loss: 0.2737 - val_accuracy: 0.8942\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2529 - accuracy: 0.8983 - val_loss: 0.2347 - val_accuracy: 0.9034\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2300 - accuracy: 0.9082 - val_loss: 0.2156 - val_accuracy: 0.9166\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2178 - accuracy: 0.9138 - val_loss: 0.1961 - val_accuracy: 0.9216\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2028 - accuracy: 0.9198 - val_loss: 0.2002 - val_accuracy: 0.9185\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1922 - accuracy: 0.9251 - val_loss: 0.1831 - val_accuracy: 0.9272\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1839 - accuracy: 0.9282 - val_loss: 0.1831 - val_accuracy: 0.9273\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1743 - accuracy: 0.9312 - val_loss: 0.1724 - val_accuracy: 0.9328\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[5, 7, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4767 - accuracy: 0.7565 - val_loss: 0.4181 - val_accuracy: 0.7991\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3947 - accuracy: 0.8178 - val_loss: 0.3762 - val_accuracy: 0.8155\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3546 - accuracy: 0.8385 - val_loss: 0.3240 - val_accuracy: 0.8531\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3314 - accuracy: 0.8505 - val_loss: 0.3032 - val_accuracy: 0.8609\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3095 - accuracy: 0.8620 - val_loss: 0.2885 - val_accuracy: 0.8650\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2968 - accuracy: 0.8673 - val_loss: 0.2803 - val_accuracy: 0.8707\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2846 - accuracy: 0.8728 - val_loss: 0.3080 - val_accuracy: 0.8623\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2731 - accuracy: 0.8789 - val_loss: 0.2605 - val_accuracy: 0.8817\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2607 - accuracy: 0.8837 - val_loss: 0.2601 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2569 - accuracy: 0.8880 - val_loss: 0.2600 - val_accuracy: 0.8834\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n",
      "9 번째 클래스\n",
      "[model1] : 가장 유사한 클래스끼리 묶은 라벨\n",
      "[1, 8, 9]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3571 - accuracy: 0.8410 - val_loss: 0.2560 - val_accuracy: 0.8918\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2674 - accuracy: 0.8908 - val_loss: 0.2210 - val_accuracy: 0.9085\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2215 - accuracy: 0.9124 - val_loss: 0.1831 - val_accuracy: 0.9256\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1901 - accuracy: 0.9265 - val_loss: 0.1584 - val_accuracy: 0.9371\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1658 - accuracy: 0.9361 - val_loss: 0.2039 - val_accuracy: 0.9199\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9414 - val_loss: 0.1512 - val_accuracy: 0.9407\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1410 - accuracy: 0.9466 - val_loss: 0.1420 - val_accuracy: 0.9453\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1331 - accuracy: 0.9494 - val_loss: 0.1463 - val_accuracy: 0.9460\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1228 - accuracy: 0.9535 - val_loss: 0.1392 - val_accuracy: 0.9468\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1160 - accuracy: 0.9557 - val_loss: 0.1441 - val_accuracy: 0.9467\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\n",
      "[7, 0, 4]\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5551 - accuracy: 0.7225 - val_loss: 0.5128 - val_accuracy: 0.7519\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4747 - accuracy: 0.7759 - val_loss: 0.4232 - val_accuracy: 0.8011\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4195 - accuracy: 0.8107 - val_loss: 0.3779 - val_accuracy: 0.8330\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3844 - accuracy: 0.8289 - val_loss: 0.3597 - val_accuracy: 0.8434\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3620 - accuracy: 0.8434 - val_loss: 0.3340 - val_accuracy: 0.8567\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3409 - accuracy: 0.8535 - val_loss: 0.3355 - val_accuracy: 0.8536\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3275 - accuracy: 0.8610 - val_loss: 0.3118 - val_accuracy: 0.8660\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3156 - accuracy: 0.8673 - val_loss: 0.3209 - val_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3035 - accuracy: 0.8722 - val_loss: 0.3135 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2956 - accuracy: 0.8748 - val_loss: 0.3080 - val_accuracy: 0.8643\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 0~9 클래스 \n",
    "# 0클래스 결과값을 봤을 때, true-false모델을 통과한 0번 클래스가 772개인데 나머지 클래스들이 어디서 데이터가 누수됐는지 분석해보기\n",
    "\n",
    "class_accuracy = []\n",
    "first_TP_FP_TN_FN = []\n",
    "second_TP_FP_TN_FN = []\n",
    "model_result_predict = []\n",
    "\n",
    "for i in range(0, class_length):\n",
    "    print(i, \"번째 클래스\")\n",
    "    # 첫번째 모델 -> 가장 유사한 클래스끼리 묶은 라벨\n",
    "    print(\"[model1] : 가장 유사한 클래스끼리 묶은 라벨\")\n",
    "    (x_train, y_train), (x_test, y_test) = getCifar10Data()\n",
    "    temp = getTopN(similar_wrong_predict_count[i], 2, i)\n",
    "    # 현재 클래스 index 추가 \n",
    "    temp.append(i)\n",
    "    print(temp)\n",
    "    (y_train, y_test) = reLabel(y_train, y_test, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model1 = makeModel()\n",
    "    model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model1.fit(x_train, y_train, epochs= 10, batch_size = 64, validation_data=(x_test, y_test))\n",
    "    first_predict = model1.predict(x_test)\n",
    "#     first_TP_FP.append(get_TP_FP(original_y_test, first_predict, i))\n",
    "#     first_TN_FN.append(get_TN_FN(original_y_test, first_predict, i))\n",
    "    first_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, first_predict, i))\n",
    "    \n",
    "    \n",
    "    # 두번째 모델 -> 가장 유사하지않은 클래스끼리 묶은 라벨\n",
    "    print(\"[model2] : 가장 유사하지않은 클래스끼리 묶은 라벨\")\n",
    "    (x_train2, y_train2), (x_test2, y_test2) = getCifar10Data()\n",
    "    temp = getBottomN(similar_wrong_predict_count[i], 3, i)\n",
    "    print(temp)\n",
    "\n",
    "    (y_train2, y_test2) = reLabel(y_train2, y_test2, temp[0], temp[1], temp[2])\n",
    "\n",
    "    model2 = makeModel()\n",
    "    model2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model2.fit(x_train2, y_train2, epochs= 10, batch_size = 64, validation_data=(x_test2, y_test2))\n",
    "    second_predict = model2.predict(x_test2)\n",
    "#     second_TP_FP.append(get_TP_FP(original_y_test, second_predict, i))\n",
    "#     second_TN_FN.append(get_TN_FN(original_y_test, second_predict, i))\n",
    "    second_TP_FP_TN_FN.append(get_TP_FP_TN_FN(original_y_test, second_predict, i))\n",
    "    \n",
    "    # 모델의 TP FP TN FN\n",
    "    model_result_predict.append(get_result_model_TP_FP_TN_FN(first_predict, second_predict, original_y_test, i))\n",
    "    \n",
    "    \n",
    "    # 첫번째 모델에서 True 두번째 모델에서 False가 나온 모델\n",
    "#     class_accuracy.append(getRealTrueRatio(first_predict, second_predict, original_y_test,i))  \n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 :  0\n",
      "첫번째 모델에서 TP:  6847\n",
      "첫번째 모델에서 FP:  2153\n",
      "첫번째 모델에서 TN:  6847\n",
      "첫번째 모델에서 FN:  113\n",
      "두번째 모델에서 TP:  6077\n",
      "두번째 모델에서 FP:  2923\n",
      "두번째 모델에서 TN:  6077\n",
      "두번째 모델에서 FN:  975\n",
      "모델 결과 TP:  975\n",
      "모델 결과 FP:  6077\n",
      "모델 결과 TN:  2923\n",
      "모델 결과 FN:  25\n",
      "precision:  0.13825865002836074\n",
      "accuracy:  0.3898\n",
      "\n",
      "클래스 :  1\n",
      "첫번째 모델에서 TP:  6698\n",
      "첫번째 모델에서 FP:  2302\n",
      "첫번째 모델에서 TN:  6698\n",
      "첫번째 모델에서 FN:  58\n",
      "두번째 모델에서 TP:  6748\n",
      "두번째 모델에서 FP:  2252\n",
      "두번째 모델에서 TN:  6748\n",
      "두번째 모델에서 FN:  994\n",
      "모델 결과 TP:  994\n",
      "모델 결과 FP:  6748\n",
      "모델 결과 TN:  2252\n",
      "모델 결과 FN:  6\n",
      "precision:  0.12839059674502712\n",
      "accuracy:  0.3246\n",
      "\n",
      "클래스 :  2\n",
      "첫번째 모델에서 TP:  6628\n",
      "첫번째 모델에서 FP:  2372\n",
      "첫번째 모델에서 TN:  6628\n",
      "첫번째 모델에서 FN:  266\n",
      "두번째 모델에서 TP:  6453\n",
      "두번째 모델에서 FP:  2547\n",
      "두번째 모델에서 TN:  6453\n",
      "두번째 모델에서 FN:  994\n",
      "모델 결과 TP:  994\n",
      "모델 결과 FP:  6453\n",
      "모델 결과 TN:  2547\n",
      "모델 결과 FN:  6\n",
      "precision:  0.13347656774540084\n",
      "accuracy:  0.3541\n",
      "\n",
      "클래스 :  3\n",
      "첫번째 모델에서 TP:  6714\n",
      "첫번째 모델에서 FP:  2286\n",
      "첫번째 모델에서 TN:  6714\n",
      "첫번째 모델에서 FN:  202\n",
      "두번째 모델에서 TP:  6253\n",
      "두번째 모델에서 FP:  2747\n",
      "두번째 모델에서 TN:  6253\n",
      "두번째 모델에서 FN:  968\n",
      "모델 결과 TP:  968\n",
      "모델 결과 FP:  6253\n",
      "모델 결과 TN:  2747\n",
      "모델 결과 FN:  32\n",
      "precision:  0.13405345520011078\n",
      "accuracy:  0.3715\n",
      "\n",
      "클래스 :  4\n",
      "첫번째 모델에서 TP:  6610\n",
      "첫번째 모델에서 FP:  2390\n",
      "첫번째 모델에서 TN:  6610\n",
      "첫번째 모델에서 FN:  157\n",
      "두번째 모델에서 TP:  5692\n",
      "두번째 모델에서 FP:  3308\n",
      "두번째 모델에서 TN:  5692\n",
      "두번째 모델에서 FN:  975\n",
      "모델 결과 TP:  975\n",
      "모델 결과 FP:  5692\n",
      "모델 결과 TN:  3308\n",
      "모델 결과 FN:  25\n",
      "precision:  0.1462426878656067\n",
      "accuracy:  0.4283\n",
      "\n",
      "클래스 :  5\n",
      "첫번째 모델에서 TP:  6229\n",
      "첫번째 모델에서 FP:  2771\n",
      "첫번째 모델에서 TN:  6229\n",
      "첫번째 모델에서 FN:  104\n",
      "두번째 모델에서 TP:  5992\n",
      "두번째 모델에서 FP:  3008\n",
      "두번째 모델에서 TN:  5992\n",
      "두번째 모델에서 FN:  983\n",
      "모델 결과 TP:  983\n",
      "모델 결과 FP:  5992\n",
      "모델 결과 TN:  3008\n",
      "모델 결과 FN:  17\n",
      "precision:  0.14093189964157707\n",
      "accuracy:  0.3991\n",
      "\n",
      "클래스 :  6\n",
      "첫번째 모델에서 TP:  7637\n",
      "첫번째 모델에서 FP:  1363\n",
      "첫번째 모델에서 TN:  7637\n",
      "첫번째 모델에서 FN:  165\n",
      "두번째 모델에서 TP:  6690\n",
      "두번째 모델에서 FP:  2310\n",
      "두번째 모델에서 TN:  6690\n",
      "두번째 모델에서 FN:  995\n",
      "모델 결과 TP:  995\n",
      "모델 결과 FP:  6690\n",
      "모델 결과 TN:  2310\n",
      "모델 결과 FN:  5\n",
      "precision:  0.12947299934938192\n",
      "accuracy:  0.3305\n",
      "\n",
      "클래스 :  7\n",
      "첫번째 모델에서 TP:  6653\n",
      "첫번째 모델에서 FP:  2347\n",
      "첫번째 모델에서 TN:  6653\n",
      "첫번째 모델에서 FN:  84\n",
      "두번째 모델에서 TP:  6166\n",
      "두번째 모델에서 FP:  2834\n",
      "두번째 모델에서 TN:  6166\n",
      "두번째 모델에서 FN:  992\n",
      "모델 결과 TP:  992\n",
      "모델 결과 FP:  6166\n",
      "모델 결과 TN:  2834\n",
      "모델 결과 FN:  8\n",
      "precision:  0.13858619726180496\n",
      "accuracy:  0.3826\n",
      "\n",
      "클래스 :  8\n",
      "첫번째 모델에서 TP:  6979\n",
      "첫번째 모델에서 FP:  2021\n",
      "첫번째 모델에서 TN:  6979\n",
      "첫번째 모델에서 FN:  97\n",
      "두번째 모델에서 TP:  6405\n",
      "두번째 모델에서 FP:  2595\n",
      "두번째 모델에서 TN:  6405\n",
      "두번째 모델에서 FN:  995\n",
      "모델 결과 TP:  995\n",
      "모델 결과 FP:  6405\n",
      "모델 결과 TN:  2595\n",
      "모델 결과 FN:  5\n",
      "precision:  0.13445945945945945\n",
      "accuracy:  0.359\n",
      "\n",
      "클래스 :  9\n",
      "첫번째 모델에서 TP:  7172\n",
      "첫번째 모델에서 FP:  1828\n",
      "첫번째 모델에서 TN:  7172\n",
      "첫번째 모델에서 FN:  121\n",
      "두번째 모델에서 TP:  6669\n",
      "두번째 모델에서 FP:  2331\n",
      "두번째 모델에서 TN:  6669\n",
      "두번째 모델에서 FN:  980\n",
      "모델 결과 TP:  980\n",
      "모델 결과 FP:  6669\n",
      "모델 결과 TN:  2331\n",
      "모델 결과 FN:  20\n",
      "precision:  0.12812132304876456\n",
      "accuracy:  0.3311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"클래스 : \",i)\n",
    "    print(\"첫번째 모델에서 TP: \", len(first_TP_FP_TN_FN[i][0]))\n",
    "    print(\"첫번째 모델에서 FP: \", len(first_TP_FP_TN_FN[i][1]))\n",
    "    print(\"첫번째 모델에서 TN: \", len(first_TP_FP_TN_FN[i][2]))\n",
    "    print(\"첫번째 모델에서 FN: \", len(first_TP_FP_TN_FN[i][3]))\n",
    "\n",
    "    print(\"두번째 모델에서 TP: \", len(second_TP_FP_TN_FN[i][0]))\n",
    "    print(\"두번째 모델에서 FP: \", len(second_TP_FP_TN_FN[i][1]))\n",
    "    print(\"두번째 모델에서 TN: \", len(second_TP_FP_TN_FN[i][2]))\n",
    "    print(\"두번째 모델에서 FN: \", len(second_TP_FP_TN_FN[i][3]))\n",
    "    \n",
    "    print(\"모델 결과 TP: \", len(model_result_predict[i][0]))\n",
    "    print(\"모델 결과 FP: \", len(model_result_predict[i][1]))\n",
    "    print(\"모델 결과 TN: \", len(model_result_predict[i][2]))\n",
    "    print(\"모델 결과 FN: \", len(model_result_predict[i][3]))\n",
    "    \n",
    "    # precision = TP / (TP + FP)\n",
    "    print(\"precision: \", (len(model_result_predict[i][0]) / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]))))\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy: \", ((len(model_result_predict[i][0]) + len(model_result_predict[i][2]))\n",
    "                               / (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3]))))\n",
    "    print(\"\")\n",
    "\n",
    "    #     print(\"true-false를 통과한 개수 : \", 1000 - (len(first_false[i]) + len(second_true[i])) )\n",
    "#     print(\"precision: \", len(first_TP_TN[i][0])/(len(first_TP_TN[i][0]) + len(second_FP_FN[i][0])))\n",
    "#     print(\"accuracy: \", (len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]))\n",
    "#           /len(first_TP_TN[0][i]) + len(first_TP_TN[1][i]) + len(second_FP_FN[0][i]) + len(second_FP_FN[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \",  (len(model_result_predict[i][0]) + len(model_result_predict[i][1]) + len(model_result_predict[i][2]) + len(model_result_predict[i][3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQT8RNBrdHY9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
